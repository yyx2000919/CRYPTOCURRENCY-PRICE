2022-08-01 16:49:32,966 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-01 16:49:32,968 - ERROR - Run Error
Traceback (most recent call last):
  File "C:\Users\zyb\AppData\Local\Temp\ipykernel_41772\3820446203.py", line 5, in main
    data_gainer = Data(config)
  File "C:\Users\zyb\AppData\Local\Temp\ipykernel_41772\2386411811.py", line 95, in __init__
    self.data, self.data_column_name = self.read_data()
  File "C:\Users\zyb\AppData\Local\Temp\ipykernel_41772\2386411811.py", line 112, in read_data
    init_data = pd.read_csv(self.config.train_data_path, usecols=self.config.feature_columns)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 610, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 462, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 819, in __init__
    self._engine = self._make_engine(self.engine)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 1050, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 1867, in __init__
    self._open_handles(src, kwds)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 1362, in _open_handles
    self.handles = get_handle(
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\common.py", line 642, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: './data/btc_data.csv'
2022-08-01 16:49:33,133 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-01 16:49:33,133 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-01 16:49:33,136 - ERROR - Run Error
Traceback (most recent call last):
  File "C:\Users\zyb\AppData\Local\Temp\ipykernel_41772\3820446203.py", line 5, in main
    data_gainer = Data(config)
  File "C:\Users\zyb\AppData\Local\Temp\ipykernel_41772\2386411811.py", line 95, in __init__
    self.data, self.data_column_name = self.read_data()
  File "C:\Users\zyb\AppData\Local\Temp\ipykernel_41772\2386411811.py", line 112, in read_data
    init_data = pd.read_csv(self.config.train_data_path, usecols=self.config.feature_columns)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 610, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 462, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 819, in __init__
    self._engine = self._make_engine(self.engine)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 1050, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 1867, in __init__
    self._open_handles(src, kwds)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 1362, in _open_handles
    self.handles = get_handle(
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\common.py", line 642, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: './data/btc_data.csv'
2022-08-01 16:49:33,136 - ERROR - Run Error
Traceback (most recent call last):
  File "C:\Users\zyb\AppData\Local\Temp\ipykernel_41772\3820446203.py", line 5, in main
    data_gainer = Data(config)
  File "C:\Users\zyb\AppData\Local\Temp\ipykernel_41772\2386411811.py", line 95, in __init__
    self.data, self.data_column_name = self.read_data()
  File "C:\Users\zyb\AppData\Local\Temp\ipykernel_41772\2386411811.py", line 112, in read_data
    init_data = pd.read_csv(self.config.train_data_path, usecols=self.config.feature_columns)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 610, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 462, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 819, in __init__
    self._engine = self._make_engine(self.engine)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 1050, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 1867, in __init__
    self._open_handles(src, kwds)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 1362, in _open_handles
    self.handles = get_handle(
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\common.py", line 642, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: './data/btc_data.csv'
2022-08-01 16:49:48,083 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-01 16:49:48,083 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-01 16:49:48,083 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-01 16:49:48,087 - ERROR - Run Error
Traceback (most recent call last):
  File "C:\Users\zyb\AppData\Local\Temp\ipykernel_41772\3820446203.py", line 5, in main
    data_gainer = Data(config)
  File "C:\Users\zyb\AppData\Local\Temp\ipykernel_41772\2386411811.py", line 95, in __init__
    self.data, self.data_column_name = self.read_data()
  File "C:\Users\zyb\AppData\Local\Temp\ipykernel_41772\2386411811.py", line 112, in read_data
    init_data = pd.read_csv(self.config.train_data_path, usecols=self.config.feature_columns)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 610, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 462, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 819, in __init__
    self._engine = self._make_engine(self.engine)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 1050, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 1867, in __init__
    self._open_handles(src, kwds)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 1362, in _open_handles
    self.handles = get_handle(
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\common.py", line 642, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: './data/btc_data.csv'
2022-08-01 16:49:48,087 - ERROR - Run Error
Traceback (most recent call last):
  File "C:\Users\zyb\AppData\Local\Temp\ipykernel_41772\3820446203.py", line 5, in main
    data_gainer = Data(config)
  File "C:\Users\zyb\AppData\Local\Temp\ipykernel_41772\2386411811.py", line 95, in __init__
    self.data, self.data_column_name = self.read_data()
  File "C:\Users\zyb\AppData\Local\Temp\ipykernel_41772\2386411811.py", line 112, in read_data
    init_data = pd.read_csv(self.config.train_data_path, usecols=self.config.feature_columns)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 610, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 462, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 819, in __init__
    self._engine = self._make_engine(self.engine)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 1050, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 1867, in __init__
    self._open_handles(src, kwds)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 1362, in _open_handles
    self.handles = get_handle(
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\common.py", line 642, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: './data/btc_data.csv'
2022-08-01 16:49:48,087 - ERROR - Run Error
Traceback (most recent call last):
  File "C:\Users\zyb\AppData\Local\Temp\ipykernel_41772\3820446203.py", line 5, in main
    data_gainer = Data(config)
  File "C:\Users\zyb\AppData\Local\Temp\ipykernel_41772\2386411811.py", line 95, in __init__
    self.data, self.data_column_name = self.read_data()
  File "C:\Users\zyb\AppData\Local\Temp\ipykernel_41772\2386411811.py", line 112, in read_data
    init_data = pd.read_csv(self.config.train_data_path, usecols=self.config.feature_columns)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 610, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 462, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 819, in __init__
    self._engine = self._make_engine(self.engine)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 1050, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 1867, in __init__
    self._open_handles(src, kwds)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 1362, in _open_handles
    self.handles = get_handle(
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\common.py", line 642, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: './data/btc_data.csv'
2022-08-01 16:50:38,641 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-01 16:50:38,643 - ERROR - Run Error
Traceback (most recent call last):
  File "C:\Users\zyb\AppData\Local\Temp\ipykernel_40792\3820446203.py", line 5, in main
    data_gainer = Data(config)
  File "C:\Users\zyb\AppData\Local\Temp\ipykernel_40792\2386411811.py", line 95, in __init__
    self.data, self.data_column_name = self.read_data()
  File "C:\Users\zyb\AppData\Local\Temp\ipykernel_40792\2386411811.py", line 112, in read_data
    init_data = pd.read_csv(self.config.train_data_path, usecols=self.config.feature_columns)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 610, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 462, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 819, in __init__
    self._engine = self._make_engine(self.engine)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 1050, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 1867, in __init__
    self._open_handles(src, kwds)
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\parsers.py", line 1362, in _open_handles
    self.handles = get_handle(
  File "C:\Users\zyb\anaconda3\envs\hydra\lib\site-packages\pandas\io\common.py", line 642, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: './data/btc_data.csv'
2022-08-01 16:51:36,647 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-01 16:51:36,647 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-01 16:51:49,994 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-01 16:51:49,994 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-01 16:51:49,994 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-01 16:51:50,775 - INFO - Epoch 0/20
2022-08-01 16:51:50,775 - INFO - Epoch 0/20
2022-08-01 16:51:50,775 - INFO - Epoch 0/20
2022-08-01 16:52:20,769 - INFO - The train loss is 0.599713. The valid loss is 0.051694.
2022-08-01 16:52:20,769 - INFO - The train loss is 0.599713. The valid loss is 0.051694.
2022-08-01 16:52:20,769 - INFO - The train loss is 0.599713. The valid loss is 0.051694.
2022-08-01 16:52:20,779 - INFO - Epoch 1/20
2022-08-01 16:52:20,779 - INFO - Epoch 1/20
2022-08-01 16:52:20,779 - INFO - Epoch 1/20
2022-08-01 16:52:44,803 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-01 16:52:44,803 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-01 16:52:44,803 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-01 16:52:44,803 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-01 16:52:45,051 - INFO - Epoch 0/20
2022-08-01 16:52:45,051 - INFO - Epoch 0/20
2022-08-01 16:52:45,051 - INFO - Epoch 0/20
2022-08-01 16:52:45,051 - INFO - Epoch 0/20
2022-08-01 16:53:03,391 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-01 16:53:03,627 - INFO - Epoch 0/20
2022-08-01 16:53:29,865 - INFO - The train loss is 0.697848. The valid loss is 0.066347.
2022-08-01 16:53:29,869 - INFO - Epoch 1/20
2022-08-01 16:53:59,216 - INFO - The train loss is 0.051537. The valid loss is 0.042451.
2022-08-01 16:53:59,220 - INFO - Epoch 2/20
2022-08-01 16:54:28,026 - INFO - The train loss is 0.043524. The valid loss is 0.037344.
2022-08-01 16:54:28,031 - INFO - Epoch 3/20
2022-08-01 16:54:58,666 - INFO - The train loss is 0.039474. The valid loss is 0.033871.
2022-08-01 16:54:58,675 - INFO - Epoch 4/20
2022-08-01 16:55:31,617 - INFO - The train loss is 0.036493. The valid loss is 0.031179.
2022-08-01 16:55:31,620 - INFO - Epoch 5/20
2022-08-01 16:55:56,594 - INFO - The train loss is 0.034119. The valid loss is 0.028953.
2022-08-01 16:55:56,598 - INFO - Epoch 6/20
2022-08-01 16:56:21,483 - INFO - The train loss is 0.032264. The valid loss is 0.027070.
2022-08-01 16:56:21,487 - INFO - Epoch 7/20
2022-08-01 16:56:48,091 - INFO - The train loss is 0.030556. The valid loss is 0.025438.
2022-08-01 16:56:48,095 - INFO - Epoch 8/20
2022-08-01 16:57:12,955 - INFO - The train loss is 0.029115. The valid loss is 0.024010.
2022-08-01 16:57:12,959 - INFO - Epoch 9/20
2022-08-01 16:57:37,606 - INFO - The train loss is 0.027830. The valid loss is 0.022750.
2022-08-01 16:57:37,609 - INFO - Epoch 10/20
2022-08-01 16:58:02,469 - INFO - The train loss is 0.026700. The valid loss is 0.021618.
2022-08-01 16:58:02,473 - INFO - Epoch 11/20
2022-08-01 16:58:27,450 - INFO - The train loss is 0.025755. The valid loss is 0.020605.
2022-08-01 16:58:27,453 - INFO - Epoch 12/20
2022-08-01 16:58:52,367 - INFO - The train loss is 0.024830. The valid loss is 0.019685.
2022-08-01 16:58:52,371 - INFO - Epoch 13/20
2022-08-01 16:59:17,349 - INFO - The train loss is 0.024012. The valid loss is 0.018851.
2022-08-01 16:59:17,352 - INFO - Epoch 14/20
2022-08-01 16:59:42,157 - INFO - The train loss is 0.023286. The valid loss is 0.018090.
2022-08-01 16:59:42,161 - INFO - Epoch 15/20
2022-08-01 17:00:07,649 - INFO - The train loss is 0.022566. The valid loss is 0.017391.
2022-08-01 17:00:07,653 - INFO - Epoch 16/20
2022-08-01 17:00:33,517 - INFO - The train loss is 0.021940. The valid loss is 0.016750.
2022-08-01 17:00:33,521 - INFO - Epoch 17/20
2022-08-01 17:00:59,189 - INFO - The train loss is 0.021391. The valid loss is 0.016158.
2022-08-01 17:00:59,192 - INFO - Epoch 18/20
2022-08-01 17:01:24,344 - INFO - The train loss is 0.020866. The valid loss is 0.015611.
2022-08-01 17:01:24,348 - INFO - Epoch 19/20
2022-08-01 17:01:49,368 - INFO - The train loss is 0.020353. The valid loss is 0.015100.
2022-08-01 17:01:50,710 - INFO - The mean squared error of btc ['midpoint'] is [0.0015724]
2022-08-01 17:01:50,716 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20170.45164934 20171.29437205 20173.77917622 20174.31392681
 20172.74574385]
2022-08-01 17:01:51,092 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-01 17:01:51,092 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-01 17:01:51,326 - INFO - Epoch 0/20
2022-08-01 17:01:51,326 - INFO - Epoch 0/20
2022-08-01 17:02:23,174 - INFO - The train loss is 0.037512. The valid loss is 0.002063.
2022-08-01 17:02:23,174 - INFO - The train loss is 0.037512. The valid loss is 0.002063.
2022-08-01 17:02:23,179 - INFO - Epoch 1/20
2022-08-01 17:02:23,179 - INFO - Epoch 1/20
2022-08-02 15:56:53,544 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 15:56:53,843 - INFO - Epoch 0/20
2022-08-02 15:57:22,936 - INFO - The train loss is 0.701157. The valid loss is 0.062943.
2022-08-02 15:57:22,942 - INFO - Epoch 1/20
2022-08-02 15:57:54,505 - INFO - The train loss is 0.049903. The valid loss is 0.042591.
2022-08-02 15:57:54,508 - INFO - Epoch 2/20
2022-08-02 15:58:27,007 - INFO - The train loss is 0.044320. The valid loss is 0.038690.
2022-08-02 15:58:27,012 - INFO - Epoch 3/20
2022-08-02 15:58:58,151 - INFO - The train loss is 0.040924. The valid loss is 0.035552.
2022-08-02 15:58:58,157 - INFO - Epoch 4/20
2022-08-02 15:59:30,325 - INFO - The train loss is 0.038135. The valid loss is 0.032957.
2022-08-02 15:59:30,330 - INFO - Epoch 5/20
2022-08-02 16:00:03,592 - INFO - The train loss is 0.035829. The valid loss is 0.030761.
2022-08-02 16:00:03,596 - INFO - Epoch 6/20
2022-08-02 16:00:33,736 - INFO - The train loss is 0.033870. The valid loss is 0.028878.
2022-08-02 16:00:33,739 - INFO - Epoch 7/20
2022-08-02 16:01:06,377 - INFO - The train loss is 0.032163. The valid loss is 0.027234.
2022-08-02 16:01:06,382 - INFO - Epoch 8/20
2022-08-02 16:01:38,929 - INFO - The train loss is 0.030700. The valid loss is 0.025789.
2022-08-02 16:01:38,934 - INFO - Epoch 9/20
2022-08-02 16:02:09,701 - INFO - The train loss is 0.029368. The valid loss is 0.024501.
2022-08-02 16:02:09,706 - INFO - Epoch 10/20
2022-08-02 16:02:44,586 - INFO - The train loss is 0.028213. The valid loss is 0.023347.
2022-08-02 16:02:44,592 - INFO - Epoch 11/20
2022-08-02 16:03:15,805 - INFO - The train loss is 0.027160. The valid loss is 0.022302.
2022-08-02 16:03:15,809 - INFO - Epoch 12/20
2022-08-02 16:03:45,871 - INFO - The train loss is 0.026265. The valid loss is 0.021355.
2022-08-02 16:03:45,876 - INFO - Epoch 13/20
2022-08-02 16:04:19,478 - INFO - The train loss is 0.025353. The valid loss is 0.020490.
2022-08-02 16:04:19,482 - INFO - Epoch 14/20
2022-08-02 16:04:52,258 - INFO - The train loss is 0.024553. The valid loss is 0.019694.
2022-08-02 16:04:52,263 - INFO - Epoch 15/20
2022-08-02 16:05:23,337 - INFO - The train loss is 0.023837. The valid loss is 0.018961.
2022-08-02 16:05:23,344 - INFO - Epoch 16/20
2022-08-02 16:05:56,736 - INFO - The train loss is 0.023121. The valid loss is 0.018284.
2022-08-02 16:05:56,740 - INFO - Epoch 17/20
2022-08-02 16:06:26,199 - INFO - The train loss is 0.022544. The valid loss is 0.017653.
2022-08-02 16:06:26,203 - INFO - Epoch 18/20
2022-08-02 16:06:58,989 - INFO - The train loss is 0.021953. The valid loss is 0.017070.
2022-08-02 16:06:58,995 - INFO - Epoch 19/20
2022-08-02 16:07:32,453 - INFO - The train loss is 0.021443. The valid loss is 0.016526.
2022-08-02 16:07:34,249 - INFO - The mean squared error of btc ['midpoint'] is [0.00180661]
2022-08-02 16:07:34,292 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20173.42425916 20171.26273508 20174.81800226 20174.80003074
 20175.66238968]
2022-08-02 16:07:34,537 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 16:07:34,537 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 16:07:34,785 - INFO - Epoch 0/20
2022-08-02 16:07:34,785 - INFO - Epoch 0/20
2022-08-02 16:08:08,494 - INFO - The train loss is 0.033472. The valid loss is 0.001685.
2022-08-02 16:08:08,494 - INFO - The train loss is 0.033472. The valid loss is 0.001685.
2022-08-02 16:08:08,500 - INFO - Epoch 1/20
2022-08-02 16:08:08,500 - INFO - Epoch 1/20
2022-08-02 16:08:43,004 - INFO - The train loss is 0.003102. The valid loss is 0.001072.
2022-08-02 16:08:43,004 - INFO - The train loss is 0.003102. The valid loss is 0.001072.
2022-08-02 16:08:43,010 - INFO - Epoch 2/20
2022-08-02 16:08:43,010 - INFO - Epoch 2/20
2022-08-02 16:09:16,489 - INFO - The train loss is 0.001802. The valid loss is 0.000966.
2022-08-02 16:09:16,489 - INFO - The train loss is 0.001802. The valid loss is 0.000966.
2022-08-02 16:09:16,495 - INFO - Epoch 3/20
2022-08-02 16:09:16,495 - INFO - Epoch 3/20
2022-08-02 16:09:50,722 - INFO - The train loss is 0.001517. The valid loss is 0.000826.
2022-08-02 16:09:50,722 - INFO - The train loss is 0.001517. The valid loss is 0.000826.
2022-08-02 16:09:50,727 - INFO - Epoch 4/20
2022-08-02 16:09:50,727 - INFO - Epoch 4/20
2022-08-02 16:10:24,515 - INFO - The train loss is 0.001361. The valid loss is 0.000773.
2022-08-02 16:10:24,515 - INFO - The train loss is 0.001361. The valid loss is 0.000773.
2022-08-02 16:10:24,520 - INFO - Epoch 5/20
2022-08-02 16:10:24,520 - INFO - Epoch 5/20
2022-08-02 16:10:58,821 - INFO - The train loss is 0.001295. The valid loss is 0.001402.
2022-08-02 16:10:58,821 - INFO - The train loss is 0.001295. The valid loss is 0.001402.
2022-08-02 16:10:58,823 - INFO - Epoch 6/20
2022-08-02 16:10:58,823 - INFO - Epoch 6/20
2022-08-02 16:11:31,452 - INFO - The train loss is 0.001271. The valid loss is 0.000827.
2022-08-02 16:11:31,452 - INFO - The train loss is 0.001271. The valid loss is 0.000827.
2022-08-02 16:11:31,454 - INFO - Epoch 7/20
2022-08-02 16:11:31,454 - INFO - Epoch 7/20
2022-08-02 16:12:04,626 - INFO - The train loss is 0.001235. The valid loss is 0.000887.
2022-08-02 16:12:04,626 - INFO - The train loss is 0.001235. The valid loss is 0.000887.
2022-08-02 16:12:04,628 - INFO - Epoch 8/20
2022-08-02 16:12:04,628 - INFO - Epoch 8/20
2022-08-02 16:12:36,890 - INFO - The train loss is 0.001182. The valid loss is 0.001349.
2022-08-02 16:12:36,890 - INFO - The train loss is 0.001182. The valid loss is 0.001349.
2022-08-02 16:12:36,892 - INFO - Epoch 9/20
2022-08-02 16:12:36,892 - INFO - Epoch 9/20
2022-08-02 16:13:09,349 - INFO - The train loss is 0.001179. The valid loss is 0.001379.
2022-08-02 16:13:09,349 - INFO - The train loss is 0.001179. The valid loss is 0.001379.
2022-08-02 16:13:09,352 - INFO -  The training stops early in epoch 9
2022-08-02 16:13:09,352 - INFO -  The training stops early in epoch 9
2022-08-02 16:13:11,233 - INFO - The mean squared error of btc ['midpoint'] is [0.00056317]
2022-08-02 16:13:11,233 - INFO - The mean squared error of btc ['midpoint'] is [0.00056317]
2022-08-02 16:13:11,268 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20166.75549554 20170.11093044 20169.34282391 20168.18087561
 20168.57661147]
2022-08-02 16:13:11,268 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20166.75549554 20170.11093044 20169.34282391 20168.18087561
 20168.57661147]
2022-08-02 16:14:59,575 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 16:14:59,575 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 16:14:59,575 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 16:14:59,855 - INFO - Epoch 0/20
2022-08-02 16:14:59,855 - INFO - Epoch 0/20
2022-08-02 16:14:59,855 - INFO - Epoch 0/20
2022-08-02 16:15:58,268 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 16:15:58,561 - INFO - Epoch 0/20
2022-08-02 16:16:28,718 - INFO - The train loss is 0.638407. The valid loss is 0.052987.
2022-08-02 16:16:28,722 - INFO - Epoch 1/20
2022-08-02 16:16:58,364 - INFO - The train loss is 0.050260. The valid loss is 0.043309.
2022-08-02 16:16:58,369 - INFO - Epoch 2/20
2022-08-02 16:17:32,237 - INFO - The train loss is 0.044672. The valid loss is 0.038854.
2022-08-02 16:17:32,241 - INFO - Epoch 3/20
2022-08-02 16:18:03,124 - INFO - The train loss is 0.040872. The valid loss is 0.035499.
2022-08-02 16:18:03,128 - INFO - Epoch 4/20
2022-08-02 16:18:33,605 - INFO - The train loss is 0.037922. The valid loss is 0.032813.
2022-08-02 16:18:33,609 - INFO - Epoch 5/20
2022-08-02 16:19:03,920 - INFO - The train loss is 0.035524. The valid loss is 0.030571.
2022-08-02 16:19:03,923 - INFO - Epoch 6/20
2022-08-02 16:19:34,221 - INFO - The train loss is 0.033539. The valid loss is 0.028658.
2022-08-02 16:19:34,225 - INFO - Epoch 7/20
2022-08-02 16:20:06,681 - INFO - The train loss is 0.031813. The valid loss is 0.026994.
2022-08-02 16:20:06,686 - INFO - Epoch 8/20
2022-08-02 16:20:42,039 - INFO - The train loss is 0.030317. The valid loss is 0.025519.
2022-08-02 16:20:42,044 - INFO - Epoch 9/20
2022-08-02 16:21:14,380 - INFO - The train loss is 0.029008. The valid loss is 0.024212.
2022-08-02 16:21:14,385 - INFO - Epoch 10/20
2022-08-02 16:21:46,421 - INFO - The train loss is 0.027786. The valid loss is 0.023040.
2022-08-02 16:21:46,427 - INFO - Epoch 11/20
2022-08-02 16:22:19,303 - INFO - The train loss is 0.026781. The valid loss is 0.021984.
2022-08-02 16:22:19,309 - INFO - Epoch 12/20
2022-08-02 16:22:48,018 - INFO - The train loss is 0.025802. The valid loss is 0.021022.
2022-08-02 16:22:48,022 - INFO - Epoch 13/20
2022-08-02 16:23:17,577 - INFO - The train loss is 0.024936. The valid loss is 0.020146.
2022-08-02 16:23:17,583 - INFO - Epoch 14/20
2022-08-02 16:23:45,697 - INFO - The train loss is 0.024185. The valid loss is 0.019344.
2022-08-02 16:23:45,701 - INFO - Epoch 15/20
2022-08-02 16:24:13,229 - INFO - The train loss is 0.023452. The valid loss is 0.018602.
2022-08-02 16:24:13,233 - INFO - Epoch 16/20
2022-08-02 16:24:40,769 - INFO - The train loss is 0.022780. The valid loss is 0.017920.
2022-08-02 16:24:40,773 - INFO - Epoch 17/20
2022-08-02 16:25:08,949 - INFO - The train loss is 0.022168. The valid loss is 0.017292.
2022-08-02 16:25:08,953 - INFO - Epoch 18/20
2022-08-02 16:25:36,570 - INFO - The train loss is 0.021593. The valid loss is 0.016701.
2022-08-02 16:25:36,574 - INFO - Epoch 19/20
2022-08-02 16:26:04,288 - INFO - The train loss is 0.021054. The valid loss is 0.016155.
2022-08-02 16:26:06,067 - INFO - The mean squared error of btc ['midpoint'] is [0.00168088]
2022-08-02 16:26:06,099 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20172.03397866 20172.80814474 20171.4180936  20174.8288488
 20174.60010967]
2022-08-02 16:26:06,398 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 16:26:06,398 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 16:26:06,658 - INFO - Epoch 0/20
2022-08-02 16:26:06,658 - INFO - Epoch 0/20
2022-08-02 16:26:35,636 - INFO - The train loss is 0.036733. The valid loss is 0.002115.
2022-08-02 16:26:35,636 - INFO - The train loss is 0.036733. The valid loss is 0.002115.
2022-08-02 16:26:35,641 - INFO - Epoch 1/20
2022-08-02 16:26:35,641 - INFO - Epoch 1/20
2022-08-02 16:27:03,935 - INFO - The train loss is 0.003147. The valid loss is 0.000904.
2022-08-02 16:27:03,935 - INFO - The train loss is 0.003147. The valid loss is 0.000904.
2022-08-02 16:27:03,941 - INFO - Epoch 2/20
2022-08-02 16:27:03,941 - INFO - Epoch 2/20
2022-08-02 16:27:32,164 - INFO - The train loss is 0.001815. The valid loss is 0.000830.
2022-08-02 16:27:32,164 - INFO - The train loss is 0.001815. The valid loss is 0.000830.
2022-08-02 16:27:32,168 - INFO - Epoch 3/20
2022-08-02 16:27:32,168 - INFO - Epoch 3/20
2022-08-02 16:28:00,592 - INFO - The train loss is 0.001526. The valid loss is 0.001163.
2022-08-02 16:28:00,592 - INFO - The train loss is 0.001526. The valid loss is 0.001163.
2022-08-02 16:28:00,593 - INFO - Epoch 4/20
2022-08-02 16:28:00,593 - INFO - Epoch 4/20
2022-08-02 16:28:28,848 - INFO - The train loss is 0.001386. The valid loss is 0.001355.
2022-08-02 16:28:28,848 - INFO - The train loss is 0.001386. The valid loss is 0.001355.
2022-08-02 16:28:28,851 - INFO - Epoch 5/20
2022-08-02 16:28:28,851 - INFO - Epoch 5/20
2022-08-02 16:28:57,179 - INFO - The train loss is 0.001310. The valid loss is 0.000862.
2022-08-02 16:28:57,179 - INFO - The train loss is 0.001310. The valid loss is 0.000862.
2022-08-02 16:28:57,181 - INFO - Epoch 6/20
2022-08-02 16:28:57,181 - INFO - Epoch 6/20
2022-08-02 16:29:25,464 - INFO - The train loss is 0.001296. The valid loss is 0.000747.
2022-08-02 16:29:25,464 - INFO - The train loss is 0.001296. The valid loss is 0.000747.
2022-08-02 16:29:25,471 - INFO - Epoch 7/20
2022-08-02 16:29:25,471 - INFO - Epoch 7/20
2022-08-02 16:29:53,879 - INFO - The train loss is 0.001213. The valid loss is 0.000830.
2022-08-02 16:29:53,879 - INFO - The train loss is 0.001213. The valid loss is 0.000830.
2022-08-02 16:29:53,882 - INFO - Epoch 8/20
2022-08-02 16:29:53,882 - INFO - Epoch 8/20
2022-08-02 16:30:24,401 - INFO - The train loss is 0.001231. The valid loss is 0.000753.
2022-08-02 16:30:24,401 - INFO - The train loss is 0.001231. The valid loss is 0.000753.
2022-08-02 16:30:24,404 - INFO - Epoch 9/20
2022-08-02 16:30:24,404 - INFO - Epoch 9/20
2022-08-02 16:30:53,672 - INFO - The train loss is 0.001167. The valid loss is 0.000862.
2022-08-02 16:30:53,672 - INFO - The train loss is 0.001167. The valid loss is 0.000862.
2022-08-02 16:30:53,674 - INFO - Epoch 10/20
2022-08-02 16:30:53,674 - INFO - Epoch 10/20
2022-08-02 16:31:25,696 - INFO - The train loss is 0.001193. The valid loss is 0.000749.
2022-08-02 16:31:25,696 - INFO - The train loss is 0.001193. The valid loss is 0.000749.
2022-08-02 16:31:25,698 - INFO - Epoch 11/20
2022-08-02 16:31:25,698 - INFO - Epoch 11/20
2022-08-02 16:31:58,667 - INFO - The train loss is 0.001139. The valid loss is 0.000750.
2022-08-02 16:31:58,667 - INFO - The train loss is 0.001139. The valid loss is 0.000750.
2022-08-02 16:31:58,669 - INFO -  The training stops early in epoch 11
2022-08-02 16:31:58,669 - INFO -  The training stops early in epoch 11
2022-08-02 16:32:00,559 - INFO - The mean squared error of btc ['midpoint'] is [0.0005445]
2022-08-02 16:32:00,559 - INFO - The mean squared error of btc ['midpoint'] is [0.0005445]
2022-08-02 16:32:00,586 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20166.70589446 20170.09211547 20169.04861343 20168.19660531
 20168.14587962]
2022-08-02 16:32:00,586 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20166.70589446 20170.09211547 20169.04861343 20168.19660531
 20168.14587962]
2022-08-02 16:32:01,074 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 16:32:01,074 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 16:32:01,074 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 16:32:01,372 - INFO - Epoch 0/20
2022-08-02 16:32:01,372 - INFO - Epoch 0/20
2022-08-02 16:32:01,372 - INFO - Epoch 0/20
2022-08-02 16:33:53,979 - INFO - The train loss is 0.101491. The valid loss is 0.017446.
2022-08-02 16:33:53,979 - INFO - The train loss is 0.101491. The valid loss is 0.017446.
2022-08-02 16:33:53,979 - INFO - The train loss is 0.101491. The valid loss is 0.017446.
2022-08-02 16:33:53,988 - INFO - Epoch 1/20
2022-08-02 16:33:53,988 - INFO - Epoch 1/20
2022-08-02 16:33:53,988 - INFO - Epoch 1/20
2022-08-02 16:35:56,663 - INFO - The train loss is 0.011158. The valid loss is 0.003808.
2022-08-02 16:35:56,663 - INFO - The train loss is 0.011158. The valid loss is 0.003808.
2022-08-02 16:35:56,663 - INFO - The train loss is 0.011158. The valid loss is 0.003808.
2022-08-02 16:35:56,675 - INFO - Epoch 2/20
2022-08-02 16:35:56,675 - INFO - Epoch 2/20
2022-08-02 16:35:56,675 - INFO - Epoch 2/20
2022-08-02 16:37:55,603 - INFO - The train loss is 0.002902. The valid loss is 0.000903.
2022-08-02 16:37:55,603 - INFO - The train loss is 0.002902. The valid loss is 0.000903.
2022-08-02 16:37:55,603 - INFO - The train loss is 0.002902. The valid loss is 0.000903.
2022-08-02 16:37:55,661 - INFO - Epoch 3/20
2022-08-02 16:37:55,661 - INFO - Epoch 3/20
2022-08-02 16:37:55,661 - INFO - Epoch 3/20
2022-08-02 16:40:36,192 - INFO - The train loss is 0.001570. The valid loss is 0.000945.
2022-08-02 16:40:36,192 - INFO - The train loss is 0.001570. The valid loss is 0.000945.
2022-08-02 16:40:36,192 - INFO - The train loss is 0.001570. The valid loss is 0.000945.
2022-08-02 16:40:36,196 - INFO - Epoch 4/20
2022-08-02 16:40:36,196 - INFO - Epoch 4/20
2022-08-02 16:40:36,196 - INFO - Epoch 4/20
2022-08-02 16:42:24,642 - INFO - The train loss is 0.001364. The valid loss is 0.000862.
2022-08-02 16:42:24,642 - INFO - The train loss is 0.001364. The valid loss is 0.000862.
2022-08-02 16:42:24,642 - INFO - The train loss is 0.001364. The valid loss is 0.000862.
2022-08-02 16:42:24,652 - INFO - Epoch 5/20
2022-08-02 16:42:24,652 - INFO - Epoch 5/20
2022-08-02 16:42:24,652 - INFO - Epoch 5/20
2022-08-02 16:43:56,348 - INFO - The train loss is 0.001262. The valid loss is 0.000903.
2022-08-02 16:43:56,348 - INFO - The train loss is 0.001262. The valid loss is 0.000903.
2022-08-02 16:43:56,348 - INFO - The train loss is 0.001262. The valid loss is 0.000903.
2022-08-02 16:43:56,350 - INFO - Epoch 6/20
2022-08-02 16:43:56,350 - INFO - Epoch 6/20
2022-08-02 16:43:56,350 - INFO - Epoch 6/20
2022-08-02 16:45:27,499 - INFO - The train loss is 0.001202. The valid loss is 0.000869.
2022-08-02 16:45:27,499 - INFO - The train loss is 0.001202. The valid loss is 0.000869.
2022-08-02 16:45:27,499 - INFO - The train loss is 0.001202. The valid loss is 0.000869.
2022-08-02 16:45:27,501 - INFO - Epoch 7/20
2022-08-02 16:45:27,501 - INFO - Epoch 7/20
2022-08-02 16:45:27,501 - INFO - Epoch 7/20
2022-08-02 16:46:59,847 - INFO - The train loss is 0.001140. The valid loss is 0.000923.
2022-08-02 16:46:59,847 - INFO - The train loss is 0.001140. The valid loss is 0.000923.
2022-08-02 16:46:59,847 - INFO - The train loss is 0.001140. The valid loss is 0.000923.
2022-08-02 16:46:59,850 - INFO - Epoch 8/20
2022-08-02 16:46:59,850 - INFO - Epoch 8/20
2022-08-02 16:46:59,850 - INFO - Epoch 8/20
2022-08-02 16:48:54,443 - INFO - The train loss is 0.001114. The valid loss is 0.000821.
2022-08-02 16:48:54,443 - INFO - The train loss is 0.001114. The valid loss is 0.000821.
2022-08-02 16:48:54,443 - INFO - The train loss is 0.001114. The valid loss is 0.000821.
2022-08-02 16:48:54,451 - INFO - Epoch 9/20
2022-08-02 16:48:54,451 - INFO - Epoch 9/20
2022-08-02 16:48:54,451 - INFO - Epoch 9/20
2022-08-02 16:50:46,039 - INFO - The train loss is 0.001080. The valid loss is 0.001000.
2022-08-02 16:50:46,039 - INFO - The train loss is 0.001080. The valid loss is 0.001000.
2022-08-02 16:50:46,039 - INFO - The train loss is 0.001080. The valid loss is 0.001000.
2022-08-02 16:50:46,041 - INFO - Epoch 10/20
2022-08-02 16:50:46,041 - INFO - Epoch 10/20
2022-08-02 16:50:46,041 - INFO - Epoch 10/20
2022-08-02 16:52:41,683 - INFO - The train loss is 0.001041. The valid loss is 0.000888.
2022-08-02 16:52:41,683 - INFO - The train loss is 0.001041. The valid loss is 0.000888.
2022-08-02 16:52:41,683 - INFO - The train loss is 0.001041. The valid loss is 0.000888.
2022-08-02 16:52:41,686 - INFO - Epoch 11/20
2022-08-02 16:52:41,686 - INFO - Epoch 11/20
2022-08-02 16:52:41,686 - INFO - Epoch 11/20
2022-08-02 16:54:33,416 - INFO - The train loss is 0.001026. The valid loss is 0.000874.
2022-08-02 16:54:33,416 - INFO - The train loss is 0.001026. The valid loss is 0.000874.
2022-08-02 16:54:33,416 - INFO - The train loss is 0.001026. The valid loss is 0.000874.
2022-08-02 16:54:33,419 - INFO - Epoch 12/20
2022-08-02 16:54:33,419 - INFO - Epoch 12/20
2022-08-02 16:54:33,419 - INFO - Epoch 12/20
2022-08-02 16:56:21,499 - INFO - The train loss is 0.001011. The valid loss is 0.000843.
2022-08-02 16:56:21,499 - INFO - The train loss is 0.001011. The valid loss is 0.000843.
2022-08-02 16:56:21,499 - INFO - The train loss is 0.001011. The valid loss is 0.000843.
2022-08-02 16:56:21,502 - INFO - Epoch 13/20
2022-08-02 16:56:21,502 - INFO - Epoch 13/20
2022-08-02 16:56:21,502 - INFO - Epoch 13/20
2022-08-02 16:58:11,658 - INFO - The train loss is 0.000976. The valid loss is 0.000854.
2022-08-02 16:58:11,658 - INFO - The train loss is 0.000976. The valid loss is 0.000854.
2022-08-02 16:58:11,658 - INFO - The train loss is 0.000976. The valid loss is 0.000854.
2022-08-02 16:58:11,660 - INFO -  The training stops early in epoch 13
2022-08-02 16:58:11,660 - INFO -  The training stops early in epoch 13
2022-08-02 16:58:11,660 - INFO -  The training stops early in epoch 13
2022-08-02 16:58:16,659 - INFO - The mean squared error of btc ['midpoint'] is [0.00057037]
2022-08-02 16:58:16,659 - INFO - The mean squared error of btc ['midpoint'] is [0.00057037]
2022-08-02 16:58:16,659 - INFO - The mean squared error of btc ['midpoint'] is [0.00057037]
2022-08-02 16:58:16,702 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20167.72176964 20169.1792602  20169.71558671 20168.7843826
 20168.65923308]
2022-08-02 16:58:16,702 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20167.72176964 20169.1792602  20169.71558671 20168.7843826
 20168.65923308]
2022-08-02 16:58:16,702 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20167.72176964 20169.1792602  20169.71558671 20168.7843826
 20168.65923308]
2022-08-02 16:58:17,051 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 16:58:17,051 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 16:58:17,051 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 16:58:17,051 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 16:58:17,376 - INFO - Epoch 0/20
2022-08-02 16:58:17,376 - INFO - Epoch 0/20
2022-08-02 16:58:17,376 - INFO - Epoch 0/20
2022-08-02 16:58:17,376 - INFO - Epoch 0/20
2022-08-02 17:00:04,646 - INFO - The train loss is 1.330651. The valid loss is 1.317418.
2022-08-02 17:00:04,646 - INFO - The train loss is 1.330651. The valid loss is 1.317418.
2022-08-02 17:00:04,646 - INFO - The train loss is 1.330651. The valid loss is 1.317418.
2022-08-02 17:00:04,646 - INFO - The train loss is 1.330651. The valid loss is 1.317418.
2022-08-02 17:00:04,657 - INFO - Epoch 1/20
2022-08-02 17:00:04,657 - INFO - Epoch 1/20
2022-08-02 17:00:04,657 - INFO - Epoch 1/20
2022-08-02 17:00:04,657 - INFO - Epoch 1/20
2022-08-02 17:01:50,637 - INFO - The train loss is 1.288936. The valid loss is 1.271734.
2022-08-02 17:01:50,637 - INFO - The train loss is 1.288936. The valid loss is 1.271734.
2022-08-02 17:01:50,637 - INFO - The train loss is 1.288936. The valid loss is 1.271734.
2022-08-02 17:01:50,637 - INFO - The train loss is 1.288936. The valid loss is 1.271734.
2022-08-02 17:01:50,646 - INFO - Epoch 2/20
2022-08-02 17:01:50,646 - INFO - Epoch 2/20
2022-08-02 17:01:50,646 - INFO - Epoch 2/20
2022-08-02 17:01:50,646 - INFO - Epoch 2/20
2022-08-02 17:03:35,513 - INFO - The train loss is 1.237383. The valid loss is 1.212540.
2022-08-02 17:03:35,513 - INFO - The train loss is 1.237383. The valid loss is 1.212540.
2022-08-02 17:03:35,513 - INFO - The train loss is 1.237383. The valid loss is 1.212540.
2022-08-02 17:03:35,513 - INFO - The train loss is 1.237383. The valid loss is 1.212540.
2022-08-02 17:03:35,524 - INFO - Epoch 3/20
2022-08-02 17:03:35,524 - INFO - Epoch 3/20
2022-08-02 17:03:35,524 - INFO - Epoch 3/20
2022-08-02 17:03:35,524 - INFO - Epoch 3/20
2022-08-02 17:05:20,505 - INFO - The train loss is 1.167920. The valid loss is 1.129986.
2022-08-02 17:05:20,505 - INFO - The train loss is 1.167920. The valid loss is 1.129986.
2022-08-02 17:05:20,505 - INFO - The train loss is 1.167920. The valid loss is 1.129986.
2022-08-02 17:05:20,505 - INFO - The train loss is 1.167920. The valid loss is 1.129986.
2022-08-02 17:05:20,516 - INFO - Epoch 4/20
2022-08-02 17:05:20,516 - INFO - Epoch 4/20
2022-08-02 17:05:20,516 - INFO - Epoch 4/20
2022-08-02 17:05:20,516 - INFO - Epoch 4/20
2022-08-02 17:07:11,524 - INFO - The train loss is 1.068458. The valid loss is 1.009318.
2022-08-02 17:07:11,524 - INFO - The train loss is 1.068458. The valid loss is 1.009318.
2022-08-02 17:07:11,524 - INFO - The train loss is 1.068458. The valid loss is 1.009318.
2022-08-02 17:07:11,524 - INFO - The train loss is 1.068458. The valid loss is 1.009318.
2022-08-02 17:07:11,534 - INFO - Epoch 5/20
2022-08-02 17:07:11,534 - INFO - Epoch 5/20
2022-08-02 17:07:11,534 - INFO - Epoch 5/20
2022-08-02 17:07:11,534 - INFO - Epoch 5/20
2022-08-02 17:08:41,647 - INFO - The train loss is 0.921680. The valid loss is 0.831208.
2022-08-02 17:08:41,647 - INFO - The train loss is 0.921680. The valid loss is 0.831208.
2022-08-02 17:08:41,647 - INFO - The train loss is 0.921680. The valid loss is 0.831208.
2022-08-02 17:08:41,647 - INFO - The train loss is 0.921680. The valid loss is 0.831208.
2022-08-02 17:08:41,655 - INFO - Epoch 6/20
2022-08-02 17:08:41,655 - INFO - Epoch 6/20
2022-08-02 17:08:41,655 - INFO - Epoch 6/20
2022-08-02 17:08:41,655 - INFO - Epoch 6/20
2022-08-02 17:10:11,394 - INFO - The train loss is 0.710972. The valid loss is 0.586030.
2022-08-02 17:10:11,394 - INFO - The train loss is 0.710972. The valid loss is 0.586030.
2022-08-02 17:10:11,394 - INFO - The train loss is 0.710972. The valid loss is 0.586030.
2022-08-02 17:10:11,394 - INFO - The train loss is 0.710972. The valid loss is 0.586030.
2022-08-02 17:10:11,401 - INFO - Epoch 7/20
2022-08-02 17:10:11,401 - INFO - Epoch 7/20
2022-08-02 17:10:11,401 - INFO - Epoch 7/20
2022-08-02 17:10:11,401 - INFO - Epoch 7/20
2022-08-02 17:11:41,383 - INFO - The train loss is 0.449561. The valid loss is 0.319847.
2022-08-02 17:11:41,383 - INFO - The train loss is 0.449561. The valid loss is 0.319847.
2022-08-02 17:11:41,383 - INFO - The train loss is 0.449561. The valid loss is 0.319847.
2022-08-02 17:11:41,383 - INFO - The train loss is 0.449561. The valid loss is 0.319847.
2022-08-02 17:11:41,391 - INFO - Epoch 8/20
2022-08-02 17:11:41,391 - INFO - Epoch 8/20
2022-08-02 17:11:41,391 - INFO - Epoch 8/20
2022-08-02 17:11:41,391 - INFO - Epoch 8/20
2022-08-02 17:13:11,294 - INFO - The train loss is 0.220247. The valid loss is 0.140975.
2022-08-02 17:13:11,294 - INFO - The train loss is 0.220247. The valid loss is 0.140975.
2022-08-02 17:13:11,294 - INFO - The train loss is 0.220247. The valid loss is 0.140975.
2022-08-02 17:13:11,294 - INFO - The train loss is 0.220247. The valid loss is 0.140975.
2022-08-02 17:13:11,301 - INFO - Epoch 9/20
2022-08-02 17:13:11,301 - INFO - Epoch 9/20
2022-08-02 17:13:11,301 - INFO - Epoch 9/20
2022-08-02 17:13:11,301 - INFO - Epoch 9/20
2022-08-02 17:14:40,349 - INFO - The train loss is 0.102882. The valid loss is 0.076454.
2022-08-02 17:14:40,349 - INFO - The train loss is 0.102882. The valid loss is 0.076454.
2022-08-02 17:14:40,349 - INFO - The train loss is 0.102882. The valid loss is 0.076454.
2022-08-02 17:14:40,349 - INFO - The train loss is 0.102882. The valid loss is 0.076454.
2022-08-02 17:14:40,356 - INFO - Epoch 10/20
2022-08-02 17:14:40,356 - INFO - Epoch 10/20
2022-08-02 17:14:40,356 - INFO - Epoch 10/20
2022-08-02 17:14:40,356 - INFO - Epoch 10/20
2022-08-02 17:16:09,832 - INFO - The train loss is 0.068690. The valid loss is 0.062346.
2022-08-02 17:16:09,832 - INFO - The train loss is 0.068690. The valid loss is 0.062346.
2022-08-02 17:16:09,832 - INFO - The train loss is 0.068690. The valid loss is 0.062346.
2022-08-02 17:16:09,832 - INFO - The train loss is 0.068690. The valid loss is 0.062346.
2022-08-02 17:16:09,840 - INFO - Epoch 11/20
2022-08-02 17:16:09,840 - INFO - Epoch 11/20
2022-08-02 17:16:09,840 - INFO - Epoch 11/20
2022-08-02 17:16:09,840 - INFO - Epoch 11/20
2022-08-02 17:17:39,559 - INFO - The train loss is 0.061774. The valid loss is 0.059617.
2022-08-02 17:17:39,559 - INFO - The train loss is 0.061774. The valid loss is 0.059617.
2022-08-02 17:17:39,559 - INFO - The train loss is 0.061774. The valid loss is 0.059617.
2022-08-02 17:17:39,559 - INFO - The train loss is 0.061774. The valid loss is 0.059617.
2022-08-02 17:17:39,568 - INFO - Epoch 12/20
2022-08-02 17:17:39,568 - INFO - Epoch 12/20
2022-08-02 17:17:39,568 - INFO - Epoch 12/20
2022-08-02 17:17:39,568 - INFO - Epoch 12/20
2022-08-02 17:19:10,510 - INFO - The train loss is 0.060223. The valid loss is 0.058708.
2022-08-02 17:19:10,510 - INFO - The train loss is 0.060223. The valid loss is 0.058708.
2022-08-02 17:19:10,510 - INFO - The train loss is 0.060223. The valid loss is 0.058708.
2022-08-02 17:19:10,510 - INFO - The train loss is 0.060223. The valid loss is 0.058708.
2022-08-02 17:19:10,520 - INFO - Epoch 13/20
2022-08-02 17:19:10,520 - INFO - Epoch 13/20
2022-08-02 17:19:10,520 - INFO - Epoch 13/20
2022-08-02 17:19:10,520 - INFO - Epoch 13/20
2022-08-02 17:20:41,785 - INFO - The train loss is 0.059451. The valid loss is 0.058058.
2022-08-02 17:20:41,785 - INFO - The train loss is 0.059451. The valid loss is 0.058058.
2022-08-02 17:20:41,785 - INFO - The train loss is 0.059451. The valid loss is 0.058058.
2022-08-02 17:20:41,785 - INFO - The train loss is 0.059451. The valid loss is 0.058058.
2022-08-02 17:20:41,800 - INFO - Epoch 14/20
2022-08-02 17:20:41,800 - INFO - Epoch 14/20
2022-08-02 17:20:41,800 - INFO - Epoch 14/20
2022-08-02 17:20:41,800 - INFO - Epoch 14/20
2022-08-02 17:22:13,826 - INFO - The train loss is 0.058804. The valid loss is 0.057456.
2022-08-02 17:22:13,826 - INFO - The train loss is 0.058804. The valid loss is 0.057456.
2022-08-02 17:22:13,826 - INFO - The train loss is 0.058804. The valid loss is 0.057456.
2022-08-02 17:22:13,826 - INFO - The train loss is 0.058804. The valid loss is 0.057456.
2022-08-02 17:22:13,833 - INFO - Epoch 15/20
2022-08-02 17:22:13,833 - INFO - Epoch 15/20
2022-08-02 17:22:13,833 - INFO - Epoch 15/20
2022-08-02 17:22:13,833 - INFO - Epoch 15/20
2022-08-02 17:23:44,915 - INFO - The train loss is 0.058247. The valid loss is 0.056872.
2022-08-02 17:23:44,915 - INFO - The train loss is 0.058247. The valid loss is 0.056872.
2022-08-02 17:23:44,915 - INFO - The train loss is 0.058247. The valid loss is 0.056872.
2022-08-02 17:23:44,915 - INFO - The train loss is 0.058247. The valid loss is 0.056872.
2022-08-02 17:23:44,923 - INFO - Epoch 16/20
2022-08-02 17:23:44,923 - INFO - Epoch 16/20
2022-08-02 17:23:44,923 - INFO - Epoch 16/20
2022-08-02 17:23:44,923 - INFO - Epoch 16/20
2022-08-02 17:25:16,361 - INFO - The train loss is 0.057624. The valid loss is 0.056305.
2022-08-02 17:25:16,361 - INFO - The train loss is 0.057624. The valid loss is 0.056305.
2022-08-02 17:25:16,361 - INFO - The train loss is 0.057624. The valid loss is 0.056305.
2022-08-02 17:25:16,361 - INFO - The train loss is 0.057624. The valid loss is 0.056305.
2022-08-02 17:25:16,370 - INFO - Epoch 17/20
2022-08-02 17:25:16,370 - INFO - Epoch 17/20
2022-08-02 17:25:16,370 - INFO - Epoch 17/20
2022-08-02 17:25:16,370 - INFO - Epoch 17/20
2022-08-02 17:26:46,189 - INFO - The train loss is 0.057105. The valid loss is 0.055755.
2022-08-02 17:26:46,189 - INFO - The train loss is 0.057105. The valid loss is 0.055755.
2022-08-02 17:26:46,189 - INFO - The train loss is 0.057105. The valid loss is 0.055755.
2022-08-02 17:26:46,189 - INFO - The train loss is 0.057105. The valid loss is 0.055755.
2022-08-02 17:26:46,197 - INFO - Epoch 18/20
2022-08-02 17:26:46,197 - INFO - Epoch 18/20
2022-08-02 17:26:46,197 - INFO - Epoch 18/20
2022-08-02 17:26:46,197 - INFO - Epoch 18/20
2022-08-02 17:28:18,457 - INFO - The train loss is 0.056540. The valid loss is 0.055218.
2022-08-02 17:28:18,457 - INFO - The train loss is 0.056540. The valid loss is 0.055218.
2022-08-02 17:28:18,457 - INFO - The train loss is 0.056540. The valid loss is 0.055218.
2022-08-02 17:28:18,457 - INFO - The train loss is 0.056540. The valid loss is 0.055218.
2022-08-02 17:28:18,466 - INFO - Epoch 19/20
2022-08-02 17:28:18,466 - INFO - Epoch 19/20
2022-08-02 17:28:18,466 - INFO - Epoch 19/20
2022-08-02 17:28:18,466 - INFO - Epoch 19/20
2022-08-02 17:29:49,161 - INFO - The train loss is 0.056008. The valid loss is 0.054696.
2022-08-02 17:29:49,161 - INFO - The train loss is 0.056008. The valid loss is 0.054696.
2022-08-02 17:29:49,161 - INFO - The train loss is 0.056008. The valid loss is 0.054696.
2022-08-02 17:29:49,161 - INFO - The train loss is 0.056008. The valid loss is 0.054696.
2022-08-02 17:29:52,989 - INFO - The mean squared error of btc ['midpoint'] is [0.00659546]
2022-08-02 17:29:52,989 - INFO - The mean squared error of btc ['midpoint'] is [0.00659546]
2022-08-02 17:29:52,989 - INFO - The mean squared error of btc ['midpoint'] is [0.00659546]
2022-08-02 17:29:52,989 - INFO - The mean squared error of btc ['midpoint'] is [0.00659546]
2022-08-02 17:29:53,019 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20183.31339385 20182.6421515  20182.47245423 20181.90529721
 20181.77857177]
2022-08-02 17:29:53,019 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20183.31339385 20182.6421515  20182.47245423 20181.90529721
 20181.77857177]
2022-08-02 17:29:53,019 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20183.31339385 20182.6421515  20182.47245423 20181.90529721
 20181.77857177]
2022-08-02 17:29:53,019 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20183.31339385 20182.6421515  20182.47245423 20181.90529721
 20181.77857177]
2022-08-02 17:29:53,281 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 17:29:53,281 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 17:29:53,281 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 17:29:53,281 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 17:29:53,281 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 17:29:53,509 - INFO - Epoch 0/20
2022-08-02 17:29:53,509 - INFO - Epoch 0/20
2022-08-02 17:29:53,509 - INFO - Epoch 0/20
2022-08-02 17:29:53,509 - INFO - Epoch 0/20
2022-08-02 17:29:53,509 - INFO - Epoch 0/20
2022-08-02 17:31:10,381 - INFO - The train loss is 1.163027. The valid loss is 0.939898.
2022-08-02 17:31:10,381 - INFO - The train loss is 1.163027. The valid loss is 0.939898.
2022-08-02 17:31:10,381 - INFO - The train loss is 1.163027. The valid loss is 0.939898.
2022-08-02 17:31:10,381 - INFO - The train loss is 1.163027. The valid loss is 0.939898.
2022-08-02 17:31:10,381 - INFO - The train loss is 1.163027. The valid loss is 0.939898.
2022-08-02 17:31:10,389 - INFO - Epoch 1/20
2022-08-02 17:31:10,389 - INFO - Epoch 1/20
2022-08-02 17:31:10,389 - INFO - Epoch 1/20
2022-08-02 17:31:10,389 - INFO - Epoch 1/20
2022-08-02 17:31:10,389 - INFO - Epoch 1/20
2022-08-02 17:32:26,236 - INFO - The train loss is 0.636712. The valid loss is 0.327974.
2022-08-02 17:32:26,236 - INFO - The train loss is 0.636712. The valid loss is 0.327974.
2022-08-02 17:32:26,236 - INFO - The train loss is 0.636712. The valid loss is 0.327974.
2022-08-02 17:32:26,236 - INFO - The train loss is 0.636712. The valid loss is 0.327974.
2022-08-02 17:32:26,236 - INFO - The train loss is 0.636712. The valid loss is 0.327974.
2022-08-02 17:32:26,245 - INFO - Epoch 2/20
2022-08-02 17:32:26,245 - INFO - Epoch 2/20
2022-08-02 17:32:26,245 - INFO - Epoch 2/20
2022-08-02 17:32:26,245 - INFO - Epoch 2/20
2022-08-02 17:32:26,245 - INFO - Epoch 2/20
2022-08-02 17:33:42,376 - INFO - The train loss is 0.147842. The valid loss is 0.052179.
2022-08-02 17:33:42,376 - INFO - The train loss is 0.147842. The valid loss is 0.052179.
2022-08-02 17:33:42,376 - INFO - The train loss is 0.147842. The valid loss is 0.052179.
2022-08-02 17:33:42,376 - INFO - The train loss is 0.147842. The valid loss is 0.052179.
2022-08-02 17:33:42,376 - INFO - The train loss is 0.147842. The valid loss is 0.052179.
2022-08-02 17:33:42,386 - INFO - Epoch 3/20
2022-08-02 17:33:42,386 - INFO - Epoch 3/20
2022-08-02 17:33:42,386 - INFO - Epoch 3/20
2022-08-02 17:33:42,386 - INFO - Epoch 3/20
2022-08-02 17:33:42,386 - INFO - Epoch 3/20
2022-08-02 17:34:58,362 - INFO - The train loss is 0.041785. The valid loss is 0.035742.
2022-08-02 17:34:58,362 - INFO - The train loss is 0.041785. The valid loss is 0.035742.
2022-08-02 17:34:58,362 - INFO - The train loss is 0.041785. The valid loss is 0.035742.
2022-08-02 17:34:58,362 - INFO - The train loss is 0.041785. The valid loss is 0.035742.
2022-08-02 17:34:58,362 - INFO - The train loss is 0.041785. The valid loss is 0.035742.
2022-08-02 17:34:58,369 - INFO - Epoch 4/20
2022-08-02 17:34:58,369 - INFO - Epoch 4/20
2022-08-02 17:34:58,369 - INFO - Epoch 4/20
2022-08-02 17:34:58,369 - INFO - Epoch 4/20
2022-08-02 17:34:58,369 - INFO - Epoch 4/20
2022-08-02 17:36:14,859 - INFO - The train loss is 0.037211. The valid loss is 0.035079.
2022-08-02 17:36:14,859 - INFO - The train loss is 0.037211. The valid loss is 0.035079.
2022-08-02 17:36:14,859 - INFO - The train loss is 0.037211. The valid loss is 0.035079.
2022-08-02 17:36:14,859 - INFO - The train loss is 0.037211. The valid loss is 0.035079.
2022-08-02 17:36:14,859 - INFO - The train loss is 0.037211. The valid loss is 0.035079.
2022-08-02 17:36:14,867 - INFO - Epoch 5/20
2022-08-02 17:36:14,867 - INFO - Epoch 5/20
2022-08-02 17:36:14,867 - INFO - Epoch 5/20
2022-08-02 17:36:14,867 - INFO - Epoch 5/20
2022-08-02 17:36:14,867 - INFO - Epoch 5/20
2022-08-02 17:37:31,567 - INFO - The train loss is 0.036735. The valid loss is 0.034713.
2022-08-02 17:37:31,567 - INFO - The train loss is 0.036735. The valid loss is 0.034713.
2022-08-02 17:37:31,567 - INFO - The train loss is 0.036735. The valid loss is 0.034713.
2022-08-02 17:37:31,567 - INFO - The train loss is 0.036735. The valid loss is 0.034713.
2022-08-02 17:37:31,567 - INFO - The train loss is 0.036735. The valid loss is 0.034713.
2022-08-02 17:37:31,575 - INFO - Epoch 6/20
2022-08-02 17:37:31,575 - INFO - Epoch 6/20
2022-08-02 17:37:31,575 - INFO - Epoch 6/20
2022-08-02 17:37:31,575 - INFO - Epoch 6/20
2022-08-02 17:37:31,575 - INFO - Epoch 6/20
2022-08-02 17:38:47,867 - INFO - The train loss is 0.036366. The valid loss is 0.034385.
2022-08-02 17:38:47,867 - INFO - The train loss is 0.036366. The valid loss is 0.034385.
2022-08-02 17:38:47,867 - INFO - The train loss is 0.036366. The valid loss is 0.034385.
2022-08-02 17:38:47,867 - INFO - The train loss is 0.036366. The valid loss is 0.034385.
2022-08-02 17:38:47,867 - INFO - The train loss is 0.036366. The valid loss is 0.034385.
2022-08-02 17:38:47,875 - INFO - Epoch 7/20
2022-08-02 17:38:47,875 - INFO - Epoch 7/20
2022-08-02 17:38:47,875 - INFO - Epoch 7/20
2022-08-02 17:38:47,875 - INFO - Epoch 7/20
2022-08-02 17:38:47,875 - INFO - Epoch 7/20
2022-08-02 17:40:05,279 - INFO - The train loss is 0.036080. The valid loss is 0.034083.
2022-08-02 17:40:05,279 - INFO - The train loss is 0.036080. The valid loss is 0.034083.
2022-08-02 17:40:05,279 - INFO - The train loss is 0.036080. The valid loss is 0.034083.
2022-08-02 17:40:05,279 - INFO - The train loss is 0.036080. The valid loss is 0.034083.
2022-08-02 17:40:05,279 - INFO - The train loss is 0.036080. The valid loss is 0.034083.
2022-08-02 17:40:05,288 - INFO - Epoch 8/20
2022-08-02 17:40:05,288 - INFO - Epoch 8/20
2022-08-02 17:40:05,288 - INFO - Epoch 8/20
2022-08-02 17:40:05,288 - INFO - Epoch 8/20
2022-08-02 17:40:05,288 - INFO - Epoch 8/20
2022-08-02 17:41:22,454 - INFO - The train loss is 0.035806. The valid loss is 0.033803.
2022-08-02 17:41:22,454 - INFO - The train loss is 0.035806. The valid loss is 0.033803.
2022-08-02 17:41:22,454 - INFO - The train loss is 0.035806. The valid loss is 0.033803.
2022-08-02 17:41:22,454 - INFO - The train loss is 0.035806. The valid loss is 0.033803.
2022-08-02 17:41:22,454 - INFO - The train loss is 0.035806. The valid loss is 0.033803.
2022-08-02 17:41:22,462 - INFO - Epoch 9/20
2022-08-02 17:41:22,462 - INFO - Epoch 9/20
2022-08-02 17:41:22,462 - INFO - Epoch 9/20
2022-08-02 17:41:22,462 - INFO - Epoch 9/20
2022-08-02 17:41:22,462 - INFO - Epoch 9/20
2022-08-02 17:42:39,049 - INFO - The train loss is 0.035531. The valid loss is 0.033538.
2022-08-02 17:42:39,049 - INFO - The train loss is 0.035531. The valid loss is 0.033538.
2022-08-02 17:42:39,049 - INFO - The train loss is 0.035531. The valid loss is 0.033538.
2022-08-02 17:42:39,049 - INFO - The train loss is 0.035531. The valid loss is 0.033538.
2022-08-02 17:42:39,049 - INFO - The train loss is 0.035531. The valid loss is 0.033538.
2022-08-02 17:42:39,059 - INFO - Epoch 10/20
2022-08-02 17:42:39,059 - INFO - Epoch 10/20
2022-08-02 17:42:39,059 - INFO - Epoch 10/20
2022-08-02 17:42:39,059 - INFO - Epoch 10/20
2022-08-02 17:42:39,059 - INFO - Epoch 10/20
2022-08-02 17:43:55,139 - INFO - The train loss is 0.035276. The valid loss is 0.033287.
2022-08-02 17:43:55,139 - INFO - The train loss is 0.035276. The valid loss is 0.033287.
2022-08-02 17:43:55,139 - INFO - The train loss is 0.035276. The valid loss is 0.033287.
2022-08-02 17:43:55,139 - INFO - The train loss is 0.035276. The valid loss is 0.033287.
2022-08-02 17:43:55,139 - INFO - The train loss is 0.035276. The valid loss is 0.033287.
2022-08-02 17:43:55,148 - INFO - Epoch 11/20
2022-08-02 17:43:55,148 - INFO - Epoch 11/20
2022-08-02 17:43:55,148 - INFO - Epoch 11/20
2022-08-02 17:43:55,148 - INFO - Epoch 11/20
2022-08-02 17:43:55,148 - INFO - Epoch 11/20
2022-08-02 17:45:11,316 - INFO - The train loss is 0.035038. The valid loss is 0.033043.
2022-08-02 17:45:11,316 - INFO - The train loss is 0.035038. The valid loss is 0.033043.
2022-08-02 17:45:11,316 - INFO - The train loss is 0.035038. The valid loss is 0.033043.
2022-08-02 17:45:11,316 - INFO - The train loss is 0.035038. The valid loss is 0.033043.
2022-08-02 17:45:11,316 - INFO - The train loss is 0.035038. The valid loss is 0.033043.
2022-08-02 17:45:11,326 - INFO - Epoch 12/20
2022-08-02 17:45:11,326 - INFO - Epoch 12/20
2022-08-02 17:45:11,326 - INFO - Epoch 12/20
2022-08-02 17:45:11,326 - INFO - Epoch 12/20
2022-08-02 17:45:11,326 - INFO - Epoch 12/20
2022-08-02 17:46:28,526 - INFO - The train loss is 0.034796. The valid loss is 0.032808.
2022-08-02 17:46:28,526 - INFO - The train loss is 0.034796. The valid loss is 0.032808.
2022-08-02 17:46:28,526 - INFO - The train loss is 0.034796. The valid loss is 0.032808.
2022-08-02 17:46:28,526 - INFO - The train loss is 0.034796. The valid loss is 0.032808.
2022-08-02 17:46:28,526 - INFO - The train loss is 0.034796. The valid loss is 0.032808.
2022-08-02 17:46:28,534 - INFO - Epoch 13/20
2022-08-02 17:46:28,534 - INFO - Epoch 13/20
2022-08-02 17:46:28,534 - INFO - Epoch 13/20
2022-08-02 17:46:28,534 - INFO - Epoch 13/20
2022-08-02 17:46:28,534 - INFO - Epoch 13/20
2022-08-02 17:47:45,301 - INFO - The train loss is 0.034565. The valid loss is 0.032579.
2022-08-02 17:47:45,301 - INFO - The train loss is 0.034565. The valid loss is 0.032579.
2022-08-02 17:47:45,301 - INFO - The train loss is 0.034565. The valid loss is 0.032579.
2022-08-02 17:47:45,301 - INFO - The train loss is 0.034565. The valid loss is 0.032579.
2022-08-02 17:47:45,301 - INFO - The train loss is 0.034565. The valid loss is 0.032579.
2022-08-02 17:47:45,310 - INFO - Epoch 14/20
2022-08-02 17:47:45,310 - INFO - Epoch 14/20
2022-08-02 17:47:45,310 - INFO - Epoch 14/20
2022-08-02 17:47:45,310 - INFO - Epoch 14/20
2022-08-02 17:47:45,310 - INFO - Epoch 14/20
2022-08-02 17:49:02,370 - INFO - The train loss is 0.034372. The valid loss is 0.032355.
2022-08-02 17:49:02,370 - INFO - The train loss is 0.034372. The valid loss is 0.032355.
2022-08-02 17:49:02,370 - INFO - The train loss is 0.034372. The valid loss is 0.032355.
2022-08-02 17:49:02,370 - INFO - The train loss is 0.034372. The valid loss is 0.032355.
2022-08-02 17:49:02,370 - INFO - The train loss is 0.034372. The valid loss is 0.032355.
2022-08-02 17:49:02,378 - INFO - Epoch 15/20
2022-08-02 17:49:02,378 - INFO - Epoch 15/20
2022-08-02 17:49:02,378 - INFO - Epoch 15/20
2022-08-02 17:49:02,378 - INFO - Epoch 15/20
2022-08-02 17:49:02,378 - INFO - Epoch 15/20
2022-08-02 17:50:21,922 - INFO - The train loss is 0.034122. The valid loss is 0.032136.
2022-08-02 17:50:21,922 - INFO - The train loss is 0.034122. The valid loss is 0.032136.
2022-08-02 17:50:21,922 - INFO - The train loss is 0.034122. The valid loss is 0.032136.
2022-08-02 17:50:21,922 - INFO - The train loss is 0.034122. The valid loss is 0.032136.
2022-08-02 17:50:21,922 - INFO - The train loss is 0.034122. The valid loss is 0.032136.
2022-08-02 17:50:21,929 - INFO - Epoch 16/20
2022-08-02 17:50:21,929 - INFO - Epoch 16/20
2022-08-02 17:50:21,929 - INFO - Epoch 16/20
2022-08-02 17:50:21,929 - INFO - Epoch 16/20
2022-08-02 17:50:21,929 - INFO - Epoch 16/20
2022-08-02 17:51:39,296 - INFO - The train loss is 0.033944. The valid loss is 0.031921.
2022-08-02 17:51:39,296 - INFO - The train loss is 0.033944. The valid loss is 0.031921.
2022-08-02 17:51:39,296 - INFO - The train loss is 0.033944. The valid loss is 0.031921.
2022-08-02 17:51:39,296 - INFO - The train loss is 0.033944. The valid loss is 0.031921.
2022-08-02 17:51:39,296 - INFO - The train loss is 0.033944. The valid loss is 0.031921.
2022-08-02 17:51:39,304 - INFO - Epoch 17/20
2022-08-02 17:51:39,304 - INFO - Epoch 17/20
2022-08-02 17:51:39,304 - INFO - Epoch 17/20
2022-08-02 17:51:39,304 - INFO - Epoch 17/20
2022-08-02 17:51:39,304 - INFO - Epoch 17/20
2022-08-02 17:52:57,463 - INFO - The train loss is 0.033702. The valid loss is 0.031709.
2022-08-02 17:52:57,463 - INFO - The train loss is 0.033702. The valid loss is 0.031709.
2022-08-02 17:52:57,463 - INFO - The train loss is 0.033702. The valid loss is 0.031709.
2022-08-02 17:52:57,463 - INFO - The train loss is 0.033702. The valid loss is 0.031709.
2022-08-02 17:52:57,463 - INFO - The train loss is 0.033702. The valid loss is 0.031709.
2022-08-02 17:52:57,472 - INFO - Epoch 18/20
2022-08-02 17:52:57,472 - INFO - Epoch 18/20
2022-08-02 17:52:57,472 - INFO - Epoch 18/20
2022-08-02 17:52:57,472 - INFO - Epoch 18/20
2022-08-02 17:52:57,472 - INFO - Epoch 18/20
2022-08-02 17:54:13,903 - INFO - The train loss is 0.033542. The valid loss is 0.031500.
2022-08-02 17:54:13,903 - INFO - The train loss is 0.033542. The valid loss is 0.031500.
2022-08-02 17:54:13,903 - INFO - The train loss is 0.033542. The valid loss is 0.031500.
2022-08-02 17:54:13,903 - INFO - The train loss is 0.033542. The valid loss is 0.031500.
2022-08-02 17:54:13,903 - INFO - The train loss is 0.033542. The valid loss is 0.031500.
2022-08-02 17:54:13,915 - INFO - Epoch 19/20
2022-08-02 17:54:13,915 - INFO - Epoch 19/20
2022-08-02 17:54:13,915 - INFO - Epoch 19/20
2022-08-02 17:54:13,915 - INFO - Epoch 19/20
2022-08-02 17:54:13,915 - INFO - Epoch 19/20
2022-08-02 17:55:30,444 - INFO - The train loss is 0.033308. The valid loss is 0.031295.
2022-08-02 17:55:30,444 - INFO - The train loss is 0.033308. The valid loss is 0.031295.
2022-08-02 17:55:30,444 - INFO - The train loss is 0.033308. The valid loss is 0.031295.
2022-08-02 17:55:30,444 - INFO - The train loss is 0.033308. The valid loss is 0.031295.
2022-08-02 17:55:30,444 - INFO - The train loss is 0.033308. The valid loss is 0.031295.
2022-08-02 17:55:34,456 - INFO - The mean squared error of btc ['midpoint'] is [0.00134968]
2022-08-02 17:55:34,456 - INFO - The mean squared error of btc ['midpoint'] is [0.00134968]
2022-08-02 17:55:34,456 - INFO - The mean squared error of btc ['midpoint'] is [0.00134968]
2022-08-02 17:55:34,456 - INFO - The mean squared error of btc ['midpoint'] is [0.00134968]
2022-08-02 17:55:34,456 - INFO - The mean squared error of btc ['midpoint'] is [0.00134968]
2022-08-02 17:55:34,482 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20174.34524563 20173.48233918 20173.59528079 20172.51262468
 20172.29344471]
2022-08-02 17:55:34,482 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20174.34524563 20173.48233918 20173.59528079 20172.51262468
 20172.29344471]
2022-08-02 17:55:34,482 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20174.34524563 20173.48233918 20173.59528079 20172.51262468
 20172.29344471]
2022-08-02 17:55:34,482 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20174.34524563 20173.48233918 20173.59528079 20172.51262468
 20172.29344471]
2022-08-02 17:55:34,482 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20174.34524563 20173.48233918 20173.59528079 20172.51262468
 20172.29344471]
2022-08-02 17:55:34,743 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 17:55:34,743 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 17:55:34,743 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 17:55:34,743 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 17:55:34,743 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 17:55:34,743 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-02 17:55:35,014 - INFO - Epoch 0/20
2022-08-02 17:55:35,014 - INFO - Epoch 0/20
2022-08-02 17:55:35,014 - INFO - Epoch 0/20
2022-08-02 17:55:35,014 - INFO - Epoch 0/20
2022-08-02 17:55:35,014 - INFO - Epoch 0/20
2022-08-02 17:55:35,014 - INFO - Epoch 0/20
2022-08-02 17:56:54,041 - INFO - The train loss is 0.062202. The valid loss is 0.008794.
2022-08-02 17:56:54,041 - INFO - The train loss is 0.062202. The valid loss is 0.008794.
2022-08-02 17:56:54,041 - INFO - The train loss is 0.062202. The valid loss is 0.008794.
2022-08-02 17:56:54,041 - INFO - The train loss is 0.062202. The valid loss is 0.008794.
2022-08-02 17:56:54,041 - INFO - The train loss is 0.062202. The valid loss is 0.008794.
2022-08-02 17:56:54,041 - INFO - The train loss is 0.062202. The valid loss is 0.008794.
2022-08-02 17:56:54,051 - INFO - Epoch 1/20
2022-08-02 17:56:54,051 - INFO - Epoch 1/20
2022-08-02 17:56:54,051 - INFO - Epoch 1/20
2022-08-02 17:56:54,051 - INFO - Epoch 1/20
2022-08-02 17:56:54,051 - INFO - Epoch 1/20
2022-08-02 17:56:54,051 - INFO - Epoch 1/20
2022-08-02 17:58:12,034 - INFO - The train loss is 0.006073. The valid loss is 0.001133.
2022-08-02 17:58:12,034 - INFO - The train loss is 0.006073. The valid loss is 0.001133.
2022-08-02 17:58:12,034 - INFO - The train loss is 0.006073. The valid loss is 0.001133.
2022-08-02 17:58:12,034 - INFO - The train loss is 0.006073. The valid loss is 0.001133.
2022-08-02 17:58:12,034 - INFO - The train loss is 0.006073. The valid loss is 0.001133.
2022-08-02 17:58:12,034 - INFO - The train loss is 0.006073. The valid loss is 0.001133.
2022-08-02 17:58:12,044 - INFO - Epoch 2/20
2022-08-02 17:58:12,044 - INFO - Epoch 2/20
2022-08-02 17:58:12,044 - INFO - Epoch 2/20
2022-08-02 17:58:12,044 - INFO - Epoch 2/20
2022-08-02 17:58:12,044 - INFO - Epoch 2/20
2022-08-02 17:58:12,044 - INFO - Epoch 2/20
2022-08-02 17:59:30,602 - INFO - The train loss is 0.001856. The valid loss is 0.000932.
2022-08-02 17:59:30,602 - INFO - The train loss is 0.001856. The valid loss is 0.000932.
2022-08-02 17:59:30,602 - INFO - The train loss is 0.001856. The valid loss is 0.000932.
2022-08-02 17:59:30,602 - INFO - The train loss is 0.001856. The valid loss is 0.000932.
2022-08-02 17:59:30,602 - INFO - The train loss is 0.001856. The valid loss is 0.000932.
2022-08-02 17:59:30,602 - INFO - The train loss is 0.001856. The valid loss is 0.000932.
2022-08-02 17:59:30,612 - INFO - Epoch 3/20
2022-08-02 17:59:30,612 - INFO - Epoch 3/20
2022-08-02 17:59:30,612 - INFO - Epoch 3/20
2022-08-02 17:59:30,612 - INFO - Epoch 3/20
2022-08-02 17:59:30,612 - INFO - Epoch 3/20
2022-08-02 17:59:30,612 - INFO - Epoch 3/20
2022-08-02 18:00:49,031 - INFO - The train loss is 0.001418. The valid loss is 0.001008.
2022-08-02 18:00:49,031 - INFO - The train loss is 0.001418. The valid loss is 0.001008.
2022-08-02 18:00:49,031 - INFO - The train loss is 0.001418. The valid loss is 0.001008.
2022-08-02 18:00:49,031 - INFO - The train loss is 0.001418. The valid loss is 0.001008.
2022-08-02 18:00:49,031 - INFO - The train loss is 0.001418. The valid loss is 0.001008.
2022-08-02 18:00:49,031 - INFO - The train loss is 0.001418. The valid loss is 0.001008.
2022-08-02 18:00:49,037 - INFO - Epoch 4/20
2022-08-02 18:00:49,037 - INFO - Epoch 4/20
2022-08-02 18:00:49,037 - INFO - Epoch 4/20
2022-08-02 18:00:49,037 - INFO - Epoch 4/20
2022-08-02 18:00:49,037 - INFO - Epoch 4/20
2022-08-02 18:00:49,037 - INFO - Epoch 4/20
2022-08-02 18:02:07,389 - INFO - The train loss is 0.001317. The valid loss is 0.000835.
2022-08-02 18:02:07,389 - INFO - The train loss is 0.001317. The valid loss is 0.000835.
2022-08-02 18:02:07,389 - INFO - The train loss is 0.001317. The valid loss is 0.000835.
2022-08-02 18:02:07,389 - INFO - The train loss is 0.001317. The valid loss is 0.000835.
2022-08-02 18:02:07,389 - INFO - The train loss is 0.001317. The valid loss is 0.000835.
2022-08-02 18:02:07,389 - INFO - The train loss is 0.001317. The valid loss is 0.000835.
2022-08-02 18:02:07,399 - INFO - Epoch 5/20
2022-08-02 18:02:07,399 - INFO - Epoch 5/20
2022-08-02 18:02:07,399 - INFO - Epoch 5/20
2022-08-02 18:02:07,399 - INFO - Epoch 5/20
2022-08-02 18:02:07,399 - INFO - Epoch 5/20
2022-08-02 18:02:07,399 - INFO - Epoch 5/20
2022-08-02 18:03:26,414 - INFO - The train loss is 0.001260. The valid loss is 0.000841.
2022-08-02 18:03:26,414 - INFO - The train loss is 0.001260. The valid loss is 0.000841.
2022-08-02 18:03:26,414 - INFO - The train loss is 0.001260. The valid loss is 0.000841.
2022-08-02 18:03:26,414 - INFO - The train loss is 0.001260. The valid loss is 0.000841.
2022-08-02 18:03:26,414 - INFO - The train loss is 0.001260. The valid loss is 0.000841.
2022-08-02 18:03:26,414 - INFO - The train loss is 0.001260. The valid loss is 0.000841.
2022-08-02 18:03:26,420 - INFO - Epoch 6/20
2022-08-02 18:03:26,420 - INFO - Epoch 6/20
2022-08-02 18:03:26,420 - INFO - Epoch 6/20
2022-08-02 18:03:26,420 - INFO - Epoch 6/20
2022-08-02 18:03:26,420 - INFO - Epoch 6/20
2022-08-02 18:03:26,420 - INFO - Epoch 6/20
2022-08-02 18:04:45,968 - INFO - The train loss is 0.001211. The valid loss is 0.000867.
2022-08-02 18:04:45,968 - INFO - The train loss is 0.001211. The valid loss is 0.000867.
2022-08-02 18:04:45,968 - INFO - The train loss is 0.001211. The valid loss is 0.000867.
2022-08-02 18:04:45,968 - INFO - The train loss is 0.001211. The valid loss is 0.000867.
2022-08-02 18:04:45,968 - INFO - The train loss is 0.001211. The valid loss is 0.000867.
2022-08-02 18:04:45,968 - INFO - The train loss is 0.001211. The valid loss is 0.000867.
2022-08-02 18:04:45,974 - INFO - Epoch 7/20
2022-08-02 18:04:45,974 - INFO - Epoch 7/20
2022-08-02 18:04:45,974 - INFO - Epoch 7/20
2022-08-02 18:04:45,974 - INFO - Epoch 7/20
2022-08-02 18:04:45,974 - INFO - Epoch 7/20
2022-08-02 18:04:45,974 - INFO - Epoch 7/20
2022-08-02 18:06:06,021 - INFO - The train loss is 0.001177. The valid loss is 0.000916.
2022-08-02 18:06:06,021 - INFO - The train loss is 0.001177. The valid loss is 0.000916.
2022-08-02 18:06:06,021 - INFO - The train loss is 0.001177. The valid loss is 0.000916.
2022-08-02 18:06:06,021 - INFO - The train loss is 0.001177. The valid loss is 0.000916.
2022-08-02 18:06:06,021 - INFO - The train loss is 0.001177. The valid loss is 0.000916.
2022-08-02 18:06:06,021 - INFO - The train loss is 0.001177. The valid loss is 0.000916.
2022-08-02 18:06:06,026 - INFO - Epoch 8/20
2022-08-02 18:06:06,026 - INFO - Epoch 8/20
2022-08-02 18:06:06,026 - INFO - Epoch 8/20
2022-08-02 18:06:06,026 - INFO - Epoch 8/20
2022-08-02 18:06:06,026 - INFO - Epoch 8/20
2022-08-02 18:06:06,026 - INFO - Epoch 8/20
2022-08-02 18:07:26,086 - INFO - The train loss is 0.001154. The valid loss is 0.001065.
2022-08-02 18:07:26,086 - INFO - The train loss is 0.001154. The valid loss is 0.001065.
2022-08-02 18:07:26,086 - INFO - The train loss is 0.001154. The valid loss is 0.001065.
2022-08-02 18:07:26,086 - INFO - The train loss is 0.001154. The valid loss is 0.001065.
2022-08-02 18:07:26,086 - INFO - The train loss is 0.001154. The valid loss is 0.001065.
2022-08-02 18:07:26,086 - INFO - The train loss is 0.001154. The valid loss is 0.001065.
2022-08-02 18:07:26,092 - INFO - Epoch 9/20
2022-08-02 18:07:26,092 - INFO - Epoch 9/20
2022-08-02 18:07:26,092 - INFO - Epoch 9/20
2022-08-02 18:07:26,092 - INFO - Epoch 9/20
2022-08-02 18:07:26,092 - INFO - Epoch 9/20
2022-08-02 18:07:26,092 - INFO - Epoch 9/20
2022-08-02 18:08:45,844 - INFO - The train loss is 0.001133. The valid loss is 0.000832.
2022-08-02 18:08:45,844 - INFO - The train loss is 0.001133. The valid loss is 0.000832.
2022-08-02 18:08:45,844 - INFO - The train loss is 0.001133. The valid loss is 0.000832.
2022-08-02 18:08:45,844 - INFO - The train loss is 0.001133. The valid loss is 0.000832.
2022-08-02 18:08:45,844 - INFO - The train loss is 0.001133. The valid loss is 0.000832.
2022-08-02 18:08:45,844 - INFO - The train loss is 0.001133. The valid loss is 0.000832.
2022-08-02 18:08:45,852 - INFO - Epoch 10/20
2022-08-02 18:08:45,852 - INFO - Epoch 10/20
2022-08-02 18:08:45,852 - INFO - Epoch 10/20
2022-08-02 18:08:45,852 - INFO - Epoch 10/20
2022-08-02 18:08:45,852 - INFO - Epoch 10/20
2022-08-02 18:08:45,852 - INFO - Epoch 10/20
2022-08-02 18:10:07,315 - INFO - The train loss is 0.001104. The valid loss is 0.000998.
2022-08-02 18:10:07,315 - INFO - The train loss is 0.001104. The valid loss is 0.000998.
2022-08-02 18:10:07,315 - INFO - The train loss is 0.001104. The valid loss is 0.000998.
2022-08-02 18:10:07,315 - INFO - The train loss is 0.001104. The valid loss is 0.000998.
2022-08-02 18:10:07,315 - INFO - The train loss is 0.001104. The valid loss is 0.000998.
2022-08-02 18:10:07,315 - INFO - The train loss is 0.001104. The valid loss is 0.000998.
2022-08-02 18:10:07,320 - INFO - Epoch 11/20
2022-08-02 18:10:07,320 - INFO - Epoch 11/20
2022-08-02 18:10:07,320 - INFO - Epoch 11/20
2022-08-02 18:10:07,320 - INFO - Epoch 11/20
2022-08-02 18:10:07,320 - INFO - Epoch 11/20
2022-08-02 18:10:07,320 - INFO - Epoch 11/20
2022-08-02 18:11:27,664 - INFO - The train loss is 0.001076. The valid loss is 0.000860.
2022-08-02 18:11:27,664 - INFO - The train loss is 0.001076. The valid loss is 0.000860.
2022-08-02 18:11:27,664 - INFO - The train loss is 0.001076. The valid loss is 0.000860.
2022-08-02 18:11:27,664 - INFO - The train loss is 0.001076. The valid loss is 0.000860.
2022-08-02 18:11:27,664 - INFO - The train loss is 0.001076. The valid loss is 0.000860.
2022-08-02 18:11:27,664 - INFO - The train loss is 0.001076. The valid loss is 0.000860.
2022-08-02 18:11:27,670 - INFO - Epoch 12/20
2022-08-02 18:11:27,670 - INFO - Epoch 12/20
2022-08-02 18:11:27,670 - INFO - Epoch 12/20
2022-08-02 18:11:27,670 - INFO - Epoch 12/20
2022-08-02 18:11:27,670 - INFO - Epoch 12/20
2022-08-02 18:11:27,670 - INFO - Epoch 12/20
2022-08-02 18:12:47,061 - INFO - The train loss is 0.001057. The valid loss is 0.001070.
2022-08-02 18:12:47,061 - INFO - The train loss is 0.001057. The valid loss is 0.001070.
2022-08-02 18:12:47,061 - INFO - The train loss is 0.001057. The valid loss is 0.001070.
2022-08-02 18:12:47,061 - INFO - The train loss is 0.001057. The valid loss is 0.001070.
2022-08-02 18:12:47,061 - INFO - The train loss is 0.001057. The valid loss is 0.001070.
2022-08-02 18:12:47,061 - INFO - The train loss is 0.001057. The valid loss is 0.001070.
2022-08-02 18:12:47,068 - INFO - Epoch 13/20
2022-08-02 18:12:47,068 - INFO - Epoch 13/20
2022-08-02 18:12:47,068 - INFO - Epoch 13/20
2022-08-02 18:12:47,068 - INFO - Epoch 13/20
2022-08-02 18:12:47,068 - INFO - Epoch 13/20
2022-08-02 18:12:47,068 - INFO - Epoch 13/20
2022-08-02 18:14:07,012 - INFO - The train loss is 0.001040. The valid loss is 0.000956.
2022-08-02 18:14:07,012 - INFO - The train loss is 0.001040. The valid loss is 0.000956.
2022-08-02 18:14:07,012 - INFO - The train loss is 0.001040. The valid loss is 0.000956.
2022-08-02 18:14:07,012 - INFO - The train loss is 0.001040. The valid loss is 0.000956.
2022-08-02 18:14:07,012 - INFO - The train loss is 0.001040. The valid loss is 0.000956.
2022-08-02 18:14:07,012 - INFO - The train loss is 0.001040. The valid loss is 0.000956.
2022-08-02 18:14:07,017 - INFO - Epoch 14/20
2022-08-02 18:14:07,017 - INFO - Epoch 14/20
2022-08-02 18:14:07,017 - INFO - Epoch 14/20
2022-08-02 18:14:07,017 - INFO - Epoch 14/20
2022-08-02 18:14:07,017 - INFO - Epoch 14/20
2022-08-02 18:14:07,017 - INFO - Epoch 14/20
2022-08-02 18:15:26,884 - INFO - The train loss is 0.001015. The valid loss is 0.000925.
2022-08-02 18:15:26,884 - INFO - The train loss is 0.001015. The valid loss is 0.000925.
2022-08-02 18:15:26,884 - INFO - The train loss is 0.001015. The valid loss is 0.000925.
2022-08-02 18:15:26,884 - INFO - The train loss is 0.001015. The valid loss is 0.000925.
2022-08-02 18:15:26,884 - INFO - The train loss is 0.001015. The valid loss is 0.000925.
2022-08-02 18:15:26,884 - INFO - The train loss is 0.001015. The valid loss is 0.000925.
2022-08-02 18:15:26,889 - INFO -  The training stops early in epoch 14
2022-08-02 18:15:26,889 - INFO -  The training stops early in epoch 14
2022-08-02 18:15:26,889 - INFO -  The training stops early in epoch 14
2022-08-02 18:15:26,889 - INFO -  The training stops early in epoch 14
2022-08-02 18:15:26,889 - INFO -  The training stops early in epoch 14
2022-08-02 18:15:26,889 - INFO -  The training stops early in epoch 14
2022-08-02 18:15:30,882 - INFO - The mean squared error of btc ['midpoint'] is [0.00059322]
2022-08-02 18:15:30,882 - INFO - The mean squared error of btc ['midpoint'] is [0.00059322]
2022-08-02 18:15:30,882 - INFO - The mean squared error of btc ['midpoint'] is [0.00059322]
2022-08-02 18:15:30,882 - INFO - The mean squared error of btc ['midpoint'] is [0.00059322]
2022-08-02 18:15:30,882 - INFO - The mean squared error of btc ['midpoint'] is [0.00059322]
2022-08-02 18:15:30,882 - INFO - The mean squared error of btc ['midpoint'] is [0.00059322]
2022-08-02 18:15:30,908 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20167.54059695 20168.56641602 20168.85138549 20168.201925
 20167.96359712]
2022-08-02 18:15:30,908 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20167.54059695 20168.56641602 20168.85138549 20168.201925
 20167.96359712]
2022-08-02 18:15:30,908 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20167.54059695 20168.56641602 20168.85138549 20168.201925
 20167.96359712]
2022-08-02 18:15:30,908 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20167.54059695 20168.56641602 20168.85138549 20168.201925
 20167.96359712]
2022-08-02 18:15:30,908 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20167.54059695 20168.56641602 20168.85138549 20168.201925
 20167.96359712]
2022-08-02 18:15:30,908 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20167.54059695 20168.56641602 20168.85138549 20168.201925
 20167.96359712]
2022-08-11 14:49:50,916 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-11 14:49:51,272 - INFO - Epoch 0/20
2022-08-11 14:50:17,110 - INFO - The train loss is 0.714282. The valid loss is 0.058412.
2022-08-11 14:50:17,117 - INFO - Epoch 1/20
2022-08-11 14:50:42,305 - INFO - The train loss is 0.051450. The valid loss is 0.044116.
2022-08-11 14:50:42,403 - INFO - Epoch 2/20
2022-08-11 14:51:14,356 - INFO - The train loss is 0.045603. The valid loss is 0.039570.
2022-08-11 14:51:14,364 - INFO - Epoch 3/20
2022-08-11 14:51:45,581 - INFO - The train loss is 0.041697. The valid loss is 0.036039.
2022-08-11 14:51:45,595 - INFO - Epoch 4/20
2022-08-11 14:52:09,565 - INFO - The train loss is 0.038549. The valid loss is 0.033169.
2022-08-11 14:52:09,565 - INFO - Epoch 5/20
2022-08-11 14:52:36,445 - INFO - The train loss is 0.036040. The valid loss is 0.030777.
2022-08-11 14:52:36,448 - INFO - Epoch 6/20
2022-08-11 14:53:03,248 - INFO - The train loss is 0.033870. The valid loss is 0.028741.
2022-08-11 14:53:03,264 - INFO - Epoch 7/20
2022-08-11 14:53:26,109 - INFO - The train loss is 0.032009. The valid loss is 0.026979.
2022-08-11 14:53:26,109 - INFO - Epoch 8/20
2022-08-11 14:53:51,674 - INFO - The train loss is 0.030436. The valid loss is 0.025435.
2022-08-11 14:53:51,678 - INFO - Epoch 9/20
2022-08-11 14:54:23,142 - INFO - The train loss is 0.029014. The valid loss is 0.024068.
2022-08-11 14:54:23,145 - INFO - Epoch 10/20
2022-08-11 14:54:50,921 - INFO - The train loss is 0.027778. The valid loss is 0.022851.
2022-08-11 14:54:50,923 - INFO - Epoch 11/20
2022-08-11 14:55:16,804 - INFO - The train loss is 0.026659. The valid loss is 0.021755.
2022-08-11 14:55:16,820 - INFO - Epoch 12/20
2022-08-11 14:55:40,541 - INFO - The train loss is 0.025650. The valid loss is 0.020765.
2022-08-11 14:55:40,544 - INFO - Epoch 13/20
2022-08-11 14:56:07,857 - INFO - The train loss is 0.024785. The valid loss is 0.019862.
2022-08-11 14:56:07,875 - INFO - Epoch 14/20
2022-08-11 14:56:31,562 - INFO - The train loss is 0.024005. The valid loss is 0.019036.
2022-08-11 14:56:31,578 - INFO - Epoch 15/20
2022-08-11 14:56:58,122 - INFO - The train loss is 0.023194. The valid loss is 0.018283.
2022-08-11 14:56:58,125 - INFO - Epoch 16/20
2022-08-11 14:57:22,622 - INFO - The train loss is 0.022524. The valid loss is 0.017586.
2022-08-11 14:57:22,637 - INFO - Epoch 17/20
2022-08-11 14:57:45,789 - INFO - The train loss is 0.021878. The valid loss is 0.016944.
2022-08-11 14:57:45,794 - INFO - Epoch 18/20
2022-08-11 14:58:08,920 - INFO - The train loss is 0.021305. The valid loss is 0.016349.
2022-08-11 14:58:08,920 - INFO - Epoch 19/20
2022-08-11 14:58:31,940 - INFO - The train loss is 0.020734. The valid loss is 0.015796.
2022-08-11 14:58:33,591 - INFO - The mean squared error of btc ['midpoint'] is [0.00167436]
2022-08-11 14:58:33,625 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20171.82721376 20171.77944756 20172.99465932 20172.63022749
 20173.63331026]
2022-08-11 14:58:34,095 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-11 14:58:34,095 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-11 14:58:34,334 - INFO - Epoch 0/20
2022-08-11 14:58:34,334 - INFO - Epoch 0/20
2022-08-11 14:58:58,008 - INFO - The train loss is 0.033970. The valid loss is 0.001834.
2022-08-11 14:58:58,008 - INFO - The train loss is 0.033970. The valid loss is 0.001834.
2022-08-11 14:58:58,008 - INFO - Epoch 1/20
2022-08-11 14:58:58,008 - INFO - Epoch 1/20
2022-08-11 14:59:21,611 - INFO - The train loss is 0.002993. The valid loss is 0.000902.
2022-08-11 14:59:21,611 - INFO - The train loss is 0.002993. The valid loss is 0.000902.
2022-08-11 14:59:21,617 - INFO - Epoch 2/20
2022-08-11 14:59:21,617 - INFO - Epoch 2/20
2022-08-11 14:59:44,971 - INFO - The train loss is 0.001831. The valid loss is 0.001439.
2022-08-11 14:59:44,971 - INFO - The train loss is 0.001831. The valid loss is 0.001439.
2022-08-11 14:59:44,987 - INFO - Epoch 3/20
2022-08-11 14:59:44,987 - INFO - Epoch 3/20
2022-08-11 15:00:08,895 - INFO - The train loss is 0.001565. The valid loss is 0.001221.
2022-08-11 15:00:08,895 - INFO - The train loss is 0.001565. The valid loss is 0.001221.
2022-08-11 15:00:08,911 - INFO - Epoch 4/20
2022-08-11 15:00:08,911 - INFO - Epoch 4/20
2022-08-11 15:00:32,537 - INFO - The train loss is 0.001422. The valid loss is 0.000974.
2022-08-11 15:00:32,537 - INFO - The train loss is 0.001422. The valid loss is 0.000974.
2022-08-11 15:00:32,537 - INFO - Epoch 5/20
2022-08-11 15:00:32,537 - INFO - Epoch 5/20
2022-08-11 15:00:56,573 - INFO - The train loss is 0.001354. The valid loss is 0.000812.
2022-08-11 15:00:56,573 - INFO - The train loss is 0.001354. The valid loss is 0.000812.
2022-08-11 15:00:56,589 - INFO - Epoch 6/20
2022-08-11 15:00:56,589 - INFO - Epoch 6/20
2022-08-11 15:01:21,340 - INFO - The train loss is 0.001260. The valid loss is 0.001388.
2022-08-11 15:01:21,340 - INFO - The train loss is 0.001260. The valid loss is 0.001388.
2022-08-11 15:01:21,340 - INFO - Epoch 7/20
2022-08-11 15:01:21,340 - INFO - Epoch 7/20
2022-08-11 15:01:45,116 - INFO - The train loss is 0.001263. The valid loss is 0.000827.
2022-08-11 15:01:45,116 - INFO - The train loss is 0.001263. The valid loss is 0.000827.
2022-08-11 15:01:45,116 - INFO - Epoch 8/20
2022-08-11 15:01:45,116 - INFO - Epoch 8/20
2022-08-11 15:02:09,295 - INFO - The train loss is 0.001213. The valid loss is 0.001319.
2022-08-11 15:02:09,295 - INFO - The train loss is 0.001213. The valid loss is 0.001319.
2022-08-11 15:02:09,295 - INFO - Epoch 9/20
2022-08-11 15:02:09,295 - INFO - Epoch 9/20
2022-08-11 15:02:36,747 - INFO - The train loss is 0.001188. The valid loss is 0.001262.
2022-08-11 15:02:36,747 - INFO - The train loss is 0.001188. The valid loss is 0.001262.
2022-08-11 15:02:36,749 - INFO - Epoch 10/20
2022-08-11 15:02:36,749 - INFO - Epoch 10/20
2022-08-11 15:03:08,773 - INFO - The train loss is 0.001166. The valid loss is 0.000964.
2022-08-11 15:03:08,773 - INFO - The train loss is 0.001166. The valid loss is 0.000964.
2022-08-11 15:03:08,773 - INFO -  The training stops early in epoch 10
2022-08-11 15:03:08,773 - INFO -  The training stops early in epoch 10
2022-08-11 15:03:10,658 - INFO - The mean squared error of btc ['midpoint'] is [0.00066463]
2022-08-11 15:03:10,658 - INFO - The mean squared error of btc ['midpoint'] is [0.00066463]
2022-08-11 15:03:10,672 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20165.15885708 20168.25599492 20167.70588457 20166.36070673
 20166.32099035]
2022-08-11 15:03:10,672 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20165.15885708 20168.25599492 20167.70588457 20166.36070673
 20166.32099035]
2022-08-11 15:03:11,126 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-11 15:03:11,126 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-11 15:03:11,126 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-11 15:03:11,351 - INFO - Epoch 0/20
2022-08-11 15:03:11,351 - INFO - Epoch 0/20
2022-08-11 15:03:11,351 - INFO - Epoch 0/20
2022-08-11 15:04:59,983 - INFO - The train loss is 0.107325. The valid loss is 0.019102.
2022-08-11 15:04:59,983 - INFO - The train loss is 0.107325. The valid loss is 0.019102.
2022-08-11 15:04:59,983 - INFO - The train loss is 0.107325. The valid loss is 0.019102.
2022-08-11 15:04:59,988 - INFO - Epoch 1/20
2022-08-11 15:04:59,988 - INFO - Epoch 1/20
2022-08-11 15:04:59,988 - INFO - Epoch 1/20
2022-08-11 15:06:48,195 - INFO - The train loss is 0.012439. The valid loss is 0.004734.
2022-08-11 15:06:48,195 - INFO - The train loss is 0.012439. The valid loss is 0.004734.
2022-08-11 15:06:48,195 - INFO - The train loss is 0.012439. The valid loss is 0.004734.
2022-08-11 15:06:48,300 - INFO - Epoch 2/20
2022-08-11 15:06:48,300 - INFO - Epoch 2/20
2022-08-11 15:06:48,300 - INFO - Epoch 2/20
2022-08-11 15:08:36,551 - INFO - The train loss is 0.003711. The valid loss is 0.001146.
2022-08-11 15:08:36,551 - INFO - The train loss is 0.003711. The valid loss is 0.001146.
2022-08-11 15:08:36,551 - INFO - The train loss is 0.003711. The valid loss is 0.001146.
2022-08-11 15:08:36,557 - INFO - Epoch 3/20
2022-08-11 15:08:36,557 - INFO - Epoch 3/20
2022-08-11 15:08:36,557 - INFO - Epoch 3/20
2022-08-11 15:10:19,337 - INFO - The train loss is 0.001809. The valid loss is 0.000925.
2022-08-11 15:10:19,337 - INFO - The train loss is 0.001809. The valid loss is 0.000925.
2022-08-11 15:10:19,337 - INFO - The train loss is 0.001809. The valid loss is 0.000925.
2022-08-11 15:10:19,337 - INFO - Epoch 4/20
2022-08-11 15:10:19,337 - INFO - Epoch 4/20
2022-08-11 15:10:19,337 - INFO - Epoch 4/20
2022-08-11 15:11:53,681 - INFO - The train loss is 0.001454. The valid loss is 0.000949.
2022-08-11 15:11:53,681 - INFO - The train loss is 0.001454. The valid loss is 0.000949.
2022-08-11 15:11:53,681 - INFO - The train loss is 0.001454. The valid loss is 0.000949.
2022-08-11 15:11:53,681 - INFO - Epoch 5/20
2022-08-11 15:11:53,681 - INFO - Epoch 5/20
2022-08-11 15:11:53,681 - INFO - Epoch 5/20
2022-08-11 15:13:38,873 - INFO - The train loss is 0.001326. The valid loss is 0.000988.
2022-08-11 15:13:38,873 - INFO - The train loss is 0.001326. The valid loss is 0.000988.
2022-08-11 15:13:38,873 - INFO - The train loss is 0.001326. The valid loss is 0.000988.
2022-08-11 15:13:38,873 - INFO - Epoch 6/20
2022-08-11 15:13:38,873 - INFO - Epoch 6/20
2022-08-11 15:13:38,873 - INFO - Epoch 6/20
2022-08-11 15:15:40,307 - INFO - The train loss is 0.001236. The valid loss is 0.000859.
2022-08-11 15:15:40,307 - INFO - The train loss is 0.001236. The valid loss is 0.000859.
2022-08-11 15:15:40,307 - INFO - The train loss is 0.001236. The valid loss is 0.000859.
2022-08-11 15:15:40,331 - INFO - Epoch 7/20
2022-08-11 15:15:40,331 - INFO - Epoch 7/20
2022-08-11 15:15:40,331 - INFO - Epoch 7/20
2022-08-11 15:17:25,565 - INFO - The train loss is 0.001192. The valid loss is 0.000982.
2022-08-11 15:17:25,565 - INFO - The train loss is 0.001192. The valid loss is 0.000982.
2022-08-11 15:17:25,565 - INFO - The train loss is 0.001192. The valid loss is 0.000982.
2022-08-11 15:17:25,565 - INFO - Epoch 8/20
2022-08-11 15:17:25,565 - INFO - Epoch 8/20
2022-08-11 15:17:25,565 - INFO - Epoch 8/20
2022-08-11 15:18:57,439 - INFO - The train loss is 0.001145. The valid loss is 0.000853.
2022-08-11 15:18:57,439 - INFO - The train loss is 0.001145. The valid loss is 0.000853.
2022-08-11 15:18:57,439 - INFO - The train loss is 0.001145. The valid loss is 0.000853.
2022-08-11 15:18:57,439 - INFO - Epoch 9/20
2022-08-11 15:18:57,439 - INFO - Epoch 9/20
2022-08-11 15:18:57,439 - INFO - Epoch 9/20
2022-08-11 15:20:35,434 - INFO - The train loss is 0.001117. The valid loss is 0.000817.
2022-08-11 15:20:35,434 - INFO - The train loss is 0.001117. The valid loss is 0.000817.
2022-08-11 15:20:35,434 - INFO - The train loss is 0.001117. The valid loss is 0.000817.
2022-08-11 15:20:35,476 - INFO - Epoch 10/20
2022-08-11 15:20:35,476 - INFO - Epoch 10/20
2022-08-11 15:20:35,476 - INFO - Epoch 10/20
2022-08-11 15:22:13,920 - INFO - The train loss is 0.001074. The valid loss is 0.000879.
2022-08-11 15:22:13,920 - INFO - The train loss is 0.001074. The valid loss is 0.000879.
2022-08-11 15:22:13,920 - INFO - The train loss is 0.001074. The valid loss is 0.000879.
2022-08-11 15:22:13,925 - INFO - Epoch 11/20
2022-08-11 15:22:13,925 - INFO - Epoch 11/20
2022-08-11 15:22:13,925 - INFO - Epoch 11/20
2022-08-11 15:23:46,770 - INFO - The train loss is 0.001042. The valid loss is 0.000892.
2022-08-11 15:23:46,770 - INFO - The train loss is 0.001042. The valid loss is 0.000892.
2022-08-11 15:23:46,770 - INFO - The train loss is 0.001042. The valid loss is 0.000892.
2022-08-11 15:23:46,770 - INFO - Epoch 12/20
2022-08-11 15:23:46,770 - INFO - Epoch 12/20
2022-08-11 15:23:46,770 - INFO - Epoch 12/20
2022-08-11 15:25:24,769 - INFO - The train loss is 0.001028. The valid loss is 0.000867.
2022-08-11 15:25:24,769 - INFO - The train loss is 0.001028. The valid loss is 0.000867.
2022-08-11 15:25:24,769 - INFO - The train loss is 0.001028. The valid loss is 0.000867.
2022-08-11 15:25:24,772 - INFO - Epoch 13/20
2022-08-11 15:25:24,772 - INFO - Epoch 13/20
2022-08-11 15:25:24,772 - INFO - Epoch 13/20
2022-08-11 15:27:12,992 - INFO - The train loss is 0.001004. The valid loss is 0.000864.
2022-08-11 15:27:12,992 - INFO - The train loss is 0.001004. The valid loss is 0.000864.
2022-08-11 15:27:12,992 - INFO - The train loss is 0.001004. The valid loss is 0.000864.
2022-08-11 15:27:12,992 - INFO - Epoch 14/20
2022-08-11 15:27:12,992 - INFO - Epoch 14/20
2022-08-11 15:27:12,992 - INFO - Epoch 14/20
2022-08-11 15:28:53,365 - INFO - The train loss is 0.000986. The valid loss is 0.000768.
2022-08-11 15:28:53,365 - INFO - The train loss is 0.000986. The valid loss is 0.000768.
2022-08-11 15:28:53,365 - INFO - The train loss is 0.000986. The valid loss is 0.000768.
2022-08-11 15:28:53,404 - INFO - Epoch 15/20
2022-08-11 15:28:53,404 - INFO - Epoch 15/20
2022-08-11 15:28:53,404 - INFO - Epoch 15/20
2022-08-11 15:30:37,536 - INFO - The train loss is 0.000966. The valid loss is 0.000943.
2022-08-11 15:30:37,536 - INFO - The train loss is 0.000966. The valid loss is 0.000943.
2022-08-11 15:30:37,536 - INFO - The train loss is 0.000966. The valid loss is 0.000943.
2022-08-11 15:30:37,569 - INFO - Epoch 16/20
2022-08-11 15:30:37,569 - INFO - Epoch 16/20
2022-08-11 15:30:37,569 - INFO - Epoch 16/20
2022-08-11 15:32:13,864 - INFO - The train loss is 0.000960. The valid loss is 0.000819.
2022-08-11 15:32:13,864 - INFO - The train loss is 0.000960. The valid loss is 0.000819.
2022-08-11 15:32:13,864 - INFO - The train loss is 0.000960. The valid loss is 0.000819.
2022-08-11 15:32:13,864 - INFO - Epoch 17/20
2022-08-11 15:32:13,864 - INFO - Epoch 17/20
2022-08-11 15:32:13,864 - INFO - Epoch 17/20
2022-08-11 15:34:01,245 - INFO - The train loss is 0.000946. The valid loss is 0.000827.
2022-08-11 15:34:01,245 - INFO - The train loss is 0.000946. The valid loss is 0.000827.
2022-08-11 15:34:01,245 - INFO - The train loss is 0.000946. The valid loss is 0.000827.
2022-08-11 15:34:01,248 - INFO - Epoch 18/20
2022-08-11 15:34:01,248 - INFO - Epoch 18/20
2022-08-11 15:34:01,248 - INFO - Epoch 18/20
2022-08-11 15:35:43,188 - INFO - The train loss is 0.000933. The valid loss is 0.000758.
2022-08-11 15:35:43,188 - INFO - The train loss is 0.000933. The valid loss is 0.000758.
2022-08-11 15:35:43,188 - INFO - The train loss is 0.000933. The valid loss is 0.000758.
2022-08-11 15:35:43,197 - INFO - Epoch 19/20
2022-08-11 15:35:43,197 - INFO - Epoch 19/20
2022-08-11 15:35:43,197 - INFO - Epoch 19/20
2022-08-11 15:37:23,794 - INFO - The train loss is 0.000911. The valid loss is 0.000937.
2022-08-11 15:37:23,794 - INFO - The train loss is 0.000911. The valid loss is 0.000937.
2022-08-11 15:37:23,794 - INFO - The train loss is 0.000911. The valid loss is 0.000937.
2022-08-11 15:37:27,912 - INFO - The mean squared error of btc ['midpoint'] is [0.00060952]
2022-08-11 15:37:27,912 - INFO - The mean squared error of btc ['midpoint'] is [0.00060952]
2022-08-11 15:37:27,912 - INFO - The mean squared error of btc ['midpoint'] is [0.00060952]
2022-08-11 15:37:27,937 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20165.51027454 20167.07472113 20167.41310944 20166.80476368
 20166.70110748]
2022-08-11 15:37:27,937 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20165.51027454 20167.07472113 20167.41310944 20166.80476368
 20166.70110748]
2022-08-11 15:37:27,937 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20165.51027454 20167.07472113 20167.41310944 20166.80476368
 20166.70110748]
2022-08-11 15:37:28,354 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-11 15:37:28,354 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-11 15:37:28,354 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-11 15:37:28,354 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-11 15:37:28,752 - INFO - Epoch 0/20
2022-08-11 15:37:28,752 - INFO - Epoch 0/20
2022-08-11 15:37:28,752 - INFO - Epoch 0/20
2022-08-11 15:37:28,752 - INFO - Epoch 0/20
2022-08-11 15:39:08,428 - INFO - The train loss is 1.359528. The valid loss is 1.347359.
2022-08-11 15:39:08,428 - INFO - The train loss is 1.359528. The valid loss is 1.347359.
2022-08-11 15:39:08,428 - INFO - The train loss is 1.359528. The valid loss is 1.347359.
2022-08-11 15:39:08,428 - INFO - The train loss is 1.359528. The valid loss is 1.347359.
2022-08-11 15:39:08,435 - INFO - Epoch 1/20
2022-08-11 15:39:08,435 - INFO - Epoch 1/20
2022-08-11 15:39:08,435 - INFO - Epoch 1/20
2022-08-11 15:39:08,435 - INFO - Epoch 1/20
2022-08-11 15:40:48,371 - INFO - The train loss is 1.320929. The valid loss is 1.309397.
2022-08-11 15:40:48,371 - INFO - The train loss is 1.320929. The valid loss is 1.309397.
2022-08-11 15:40:48,371 - INFO - The train loss is 1.320929. The valid loss is 1.309397.
2022-08-11 15:40:48,371 - INFO - The train loss is 1.320929. The valid loss is 1.309397.
2022-08-11 15:40:48,378 - INFO - Epoch 2/20
2022-08-11 15:40:48,378 - INFO - Epoch 2/20
2022-08-11 15:40:48,378 - INFO - Epoch 2/20
2022-08-11 15:40:48,378 - INFO - Epoch 2/20
2022-08-11 15:42:31,291 - INFO - The train loss is 1.282007. The valid loss is 1.267496.
2022-08-11 15:42:31,291 - INFO - The train loss is 1.282007. The valid loss is 1.267496.
2022-08-11 15:42:31,291 - INFO - The train loss is 1.282007. The valid loss is 1.267496.
2022-08-11 15:42:31,291 - INFO - The train loss is 1.282007. The valid loss is 1.267496.
2022-08-11 15:42:31,307 - INFO - Epoch 3/20
2022-08-11 15:42:31,307 - INFO - Epoch 3/20
2022-08-11 15:42:31,307 - INFO - Epoch 3/20
2022-08-11 15:42:31,307 - INFO - Epoch 3/20
2022-08-11 15:44:15,572 - INFO - The train loss is 1.235835. The valid loss is 1.215117.
2022-08-11 15:44:15,572 - INFO - The train loss is 1.235835. The valid loss is 1.215117.
2022-08-11 15:44:15,572 - INFO - The train loss is 1.235835. The valid loss is 1.215117.
2022-08-11 15:44:15,572 - INFO - The train loss is 1.235835. The valid loss is 1.215117.
2022-08-11 15:44:15,584 - INFO - Epoch 4/20
2022-08-11 15:44:15,584 - INFO - Epoch 4/20
2022-08-11 15:44:15,584 - INFO - Epoch 4/20
2022-08-11 15:44:15,584 - INFO - Epoch 4/20
2022-08-11 15:45:55,598 - INFO - The train loss is 1.175514. The valid loss is 1.144505.
2022-08-11 15:45:55,598 - INFO - The train loss is 1.175514. The valid loss is 1.144505.
2022-08-11 15:45:55,598 - INFO - The train loss is 1.175514. The valid loss is 1.144505.
2022-08-11 15:45:55,598 - INFO - The train loss is 1.175514. The valid loss is 1.144505.
2022-08-11 15:45:55,605 - INFO - Epoch 5/20
2022-08-11 15:45:55,605 - INFO - Epoch 5/20
2022-08-11 15:45:55,605 - INFO - Epoch 5/20
2022-08-11 15:45:55,605 - INFO - Epoch 5/20
2022-08-11 15:47:41,577 - INFO - The train loss is 1.091981. The valid loss is 1.044826.
2022-08-11 15:47:41,577 - INFO - The train loss is 1.091981. The valid loss is 1.044826.
2022-08-11 15:47:41,577 - INFO - The train loss is 1.091981. The valid loss is 1.044826.
2022-08-11 15:47:41,577 - INFO - The train loss is 1.091981. The valid loss is 1.044826.
2022-08-11 15:47:41,593 - INFO - Epoch 6/20
2022-08-11 15:47:41,593 - INFO - Epoch 6/20
2022-08-11 15:47:41,593 - INFO - Epoch 6/20
2022-08-11 15:47:41,593 - INFO - Epoch 6/20
2022-08-11 15:49:25,779 - INFO - The train loss is 0.972585. The valid loss is 0.901476.
2022-08-11 15:49:25,779 - INFO - The train loss is 0.972585. The valid loss is 0.901476.
2022-08-11 15:49:25,779 - INFO - The train loss is 0.972585. The valid loss is 0.901476.
2022-08-11 15:49:25,779 - INFO - The train loss is 0.972585. The valid loss is 0.901476.
2022-08-11 15:49:25,817 - INFO - Epoch 7/20
2022-08-11 15:49:25,817 - INFO - Epoch 7/20
2022-08-11 15:49:25,817 - INFO - Epoch 7/20
2022-08-11 15:49:25,817 - INFO - Epoch 7/20
2022-08-11 15:51:05,799 - INFO - The train loss is 0.802582. The valid loss is 0.701177.
2022-08-11 15:51:05,799 - INFO - The train loss is 0.802582. The valid loss is 0.701177.
2022-08-11 15:51:05,799 - INFO - The train loss is 0.802582. The valid loss is 0.701177.
2022-08-11 15:51:05,799 - INFO - The train loss is 0.802582. The valid loss is 0.701177.
2022-08-11 15:51:05,806 - INFO - Epoch 8/20
2022-08-11 15:51:05,806 - INFO - Epoch 8/20
2022-08-11 15:51:05,806 - INFO - Epoch 8/20
2022-08-11 15:51:05,806 - INFO - Epoch 8/20
2022-08-11 15:52:43,844 - INFO - The train loss is 0.577981. The valid loss is 0.455058.
2022-08-11 15:52:43,844 - INFO - The train loss is 0.577981. The valid loss is 0.455058.
2022-08-11 15:52:43,844 - INFO - The train loss is 0.577981. The valid loss is 0.455058.
2022-08-11 15:52:43,844 - INFO - The train loss is 0.577981. The valid loss is 0.455058.
2022-08-11 15:52:43,850 - INFO - Epoch 9/20
2022-08-11 15:52:43,850 - INFO - Epoch 9/20
2022-08-11 15:52:43,850 - INFO - Epoch 9/20
2022-08-11 15:52:43,850 - INFO - Epoch 9/20
2022-08-11 15:54:23,563 - INFO - The train loss is 0.337176. The valid loss is 0.232220.
2022-08-11 15:54:23,563 - INFO - The train loss is 0.337176. The valid loss is 0.232220.
2022-08-11 15:54:23,563 - INFO - The train loss is 0.337176. The valid loss is 0.232220.
2022-08-11 15:54:23,563 - INFO - The train loss is 0.337176. The valid loss is 0.232220.
2022-08-11 15:54:23,570 - INFO - Epoch 10/20
2022-08-11 15:54:23,570 - INFO - Epoch 10/20
2022-08-11 15:54:23,570 - INFO - Epoch 10/20
2022-08-11 15:54:23,570 - INFO - Epoch 10/20
2022-08-11 15:56:03,947 - INFO - The train loss is 0.162469. The valid loss is 0.109388.
2022-08-11 15:56:03,947 - INFO - The train loss is 0.162469. The valid loss is 0.109388.
2022-08-11 15:56:03,947 - INFO - The train loss is 0.162469. The valid loss is 0.109388.
2022-08-11 15:56:03,947 - INFO - The train loss is 0.162469. The valid loss is 0.109388.
2022-08-11 15:56:03,954 - INFO - Epoch 11/20
2022-08-11 15:56:03,954 - INFO - Epoch 11/20
2022-08-11 15:56:03,954 - INFO - Epoch 11/20
2022-08-11 15:56:03,954 - INFO - Epoch 11/20
2022-08-11 15:57:51,247 - INFO - The train loss is 0.086486. The valid loss is 0.069904.
2022-08-11 15:57:51,247 - INFO - The train loss is 0.086486. The valid loss is 0.069904.
2022-08-11 15:57:51,247 - INFO - The train loss is 0.086486. The valid loss is 0.069904.
2022-08-11 15:57:51,247 - INFO - The train loss is 0.086486. The valid loss is 0.069904.
2022-08-11 15:57:51,255 - INFO - Epoch 12/20
2022-08-11 15:57:51,255 - INFO - Epoch 12/20
2022-08-11 15:57:51,255 - INFO - Epoch 12/20
2022-08-11 15:57:51,255 - INFO - Epoch 12/20
2022-08-11 15:59:33,196 - INFO - The train loss is 0.065743. The valid loss is 0.061013.
2022-08-11 15:59:33,196 - INFO - The train loss is 0.065743. The valid loss is 0.061013.
2022-08-11 15:59:33,196 - INFO - The train loss is 0.065743. The valid loss is 0.061013.
2022-08-11 15:59:33,196 - INFO - The train loss is 0.065743. The valid loss is 0.061013.
2022-08-11 15:59:33,196 - INFO - Epoch 13/20
2022-08-11 15:59:33,196 - INFO - Epoch 13/20
2022-08-11 15:59:33,196 - INFO - Epoch 13/20
2022-08-11 15:59:33,196 - INFO - Epoch 13/20
2022-08-11 16:01:08,056 - INFO - The train loss is 0.061156. The valid loss is 0.058899.
2022-08-11 16:01:08,056 - INFO - The train loss is 0.061156. The valid loss is 0.058899.
2022-08-11 16:01:08,056 - INFO - The train loss is 0.061156. The valid loss is 0.058899.
2022-08-11 16:01:08,056 - INFO - The train loss is 0.061156. The valid loss is 0.058899.
2022-08-11 16:01:08,069 - INFO - Epoch 14/20
2022-08-11 16:01:08,069 - INFO - Epoch 14/20
2022-08-11 16:01:08,069 - INFO - Epoch 14/20
2022-08-11 16:01:08,069 - INFO - Epoch 14/20
2022-08-11 16:02:47,376 - INFO - The train loss is 0.059827. The valid loss is 0.057971.
2022-08-11 16:02:47,376 - INFO - The train loss is 0.059827. The valid loss is 0.057971.
2022-08-11 16:02:47,376 - INFO - The train loss is 0.059827. The valid loss is 0.057971.
2022-08-11 16:02:47,376 - INFO - The train loss is 0.059827. The valid loss is 0.057971.
2022-08-11 16:02:47,382 - INFO - Epoch 15/20
2022-08-11 16:02:47,382 - INFO - Epoch 15/20
2022-08-11 16:02:47,382 - INFO - Epoch 15/20
2022-08-11 16:02:47,382 - INFO - Epoch 15/20
2022-08-11 16:04:33,743 - INFO - The train loss is 0.058991. The valid loss is 0.057241.
2022-08-11 16:04:33,743 - INFO - The train loss is 0.058991. The valid loss is 0.057241.
2022-08-11 16:04:33,743 - INFO - The train loss is 0.058991. The valid loss is 0.057241.
2022-08-11 16:04:33,743 - INFO - The train loss is 0.058991. The valid loss is 0.057241.
2022-08-11 16:04:33,750 - INFO - Epoch 16/20
2022-08-11 16:04:33,750 - INFO - Epoch 16/20
2022-08-11 16:04:33,750 - INFO - Epoch 16/20
2022-08-11 16:04:33,750 - INFO - Epoch 16/20
2022-08-11 16:06:13,958 - INFO - The train loss is 0.058276. The valid loss is 0.056562.
2022-08-11 16:06:13,958 - INFO - The train loss is 0.058276. The valid loss is 0.056562.
2022-08-11 16:06:13,958 - INFO - The train loss is 0.058276. The valid loss is 0.056562.
2022-08-11 16:06:13,958 - INFO - The train loss is 0.058276. The valid loss is 0.056562.
2022-08-11 16:06:13,965 - INFO - Epoch 17/20
2022-08-11 16:06:13,965 - INFO - Epoch 17/20
2022-08-11 16:06:13,965 - INFO - Epoch 17/20
2022-08-11 16:06:13,965 - INFO - Epoch 17/20
2022-08-11 16:07:52,463 - INFO - The train loss is 0.057630. The valid loss is 0.055910.
2022-08-11 16:07:52,463 - INFO - The train loss is 0.057630. The valid loss is 0.055910.
2022-08-11 16:07:52,463 - INFO - The train loss is 0.057630. The valid loss is 0.055910.
2022-08-11 16:07:52,463 - INFO - The train loss is 0.057630. The valid loss is 0.055910.
2022-08-11 16:07:52,468 - INFO - Epoch 18/20
2022-08-11 16:07:52,468 - INFO - Epoch 18/20
2022-08-11 16:07:52,468 - INFO - Epoch 18/20
2022-08-11 16:07:52,468 - INFO - Epoch 18/20
2022-08-11 16:09:31,775 - INFO - The train loss is 0.056944. The valid loss is 0.055284.
2022-08-11 16:09:31,775 - INFO - The train loss is 0.056944. The valid loss is 0.055284.
2022-08-11 16:09:31,775 - INFO - The train loss is 0.056944. The valid loss is 0.055284.
2022-08-11 16:09:31,775 - INFO - The train loss is 0.056944. The valid loss is 0.055284.
2022-08-11 16:09:31,782 - INFO - Epoch 19/20
2022-08-11 16:09:31,782 - INFO - Epoch 19/20
2022-08-11 16:09:31,782 - INFO - Epoch 19/20
2022-08-11 16:09:31,782 - INFO - Epoch 19/20
2022-08-11 16:11:16,096 - INFO - The train loss is 0.056361. The valid loss is 0.054678.
2022-08-11 16:11:16,096 - INFO - The train loss is 0.056361. The valid loss is 0.054678.
2022-08-11 16:11:16,096 - INFO - The train loss is 0.056361. The valid loss is 0.054678.
2022-08-11 16:11:16,096 - INFO - The train loss is 0.056361. The valid loss is 0.054678.
2022-08-11 16:11:20,413 - INFO - The mean squared error of btc ['midpoint'] is [0.00795262]
2022-08-11 16:11:20,413 - INFO - The mean squared error of btc ['midpoint'] is [0.00795262]
2022-08-11 16:11:20,413 - INFO - The mean squared error of btc ['midpoint'] is [0.00795262]
2022-08-11 16:11:20,413 - INFO - The mean squared error of btc ['midpoint'] is [0.00795262]
2022-08-11 16:11:20,715 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20176.882492   20177.47349513 20176.98329969 20178.5779479
 20179.45067986]
2022-08-11 16:11:20,715 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20176.882492   20177.47349513 20176.98329969 20178.5779479
 20179.45067986]
2022-08-11 16:11:20,715 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20176.882492   20177.47349513 20176.98329969 20178.5779479
 20179.45067986]
2022-08-11 16:11:20,715 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20176.882492   20177.47349513 20176.98329969 20178.5779479
 20179.45067986]
2022-08-11 16:11:21,199 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-11 16:11:21,199 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-11 16:11:21,199 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-11 16:11:21,199 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-11 16:11:21,199 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-11 16:11:21,658 - INFO - Epoch 0/20
2022-08-11 16:11:21,658 - INFO - Epoch 0/20
2022-08-11 16:11:21,658 - INFO - Epoch 0/20
2022-08-11 16:11:21,658 - INFO - Epoch 0/20
2022-08-11 16:11:21,658 - INFO - Epoch 0/20
2022-08-11 16:12:50,325 - INFO - The train loss is 1.137499. The valid loss is 0.882792.
2022-08-11 16:12:50,325 - INFO - The train loss is 1.137499. The valid loss is 0.882792.
2022-08-11 16:12:50,325 - INFO - The train loss is 1.137499. The valid loss is 0.882792.
2022-08-11 16:12:50,325 - INFO - The train loss is 1.137499. The valid loss is 0.882792.
2022-08-11 16:12:50,325 - INFO - The train loss is 1.137499. The valid loss is 0.882792.
2022-08-11 16:12:50,388 - INFO - Epoch 1/20
2022-08-11 16:12:50,388 - INFO - Epoch 1/20
2022-08-11 16:12:50,388 - INFO - Epoch 1/20
2022-08-11 16:12:50,388 - INFO - Epoch 1/20
2022-08-11 16:12:50,388 - INFO - Epoch 1/20
2022-08-11 16:14:11,255 - INFO - The train loss is 0.558300. The valid loss is 0.251367.
2022-08-11 16:14:11,255 - INFO - The train loss is 0.558300. The valid loss is 0.251367.
2022-08-11 16:14:11,255 - INFO - The train loss is 0.558300. The valid loss is 0.251367.
2022-08-11 16:14:11,255 - INFO - The train loss is 0.558300. The valid loss is 0.251367.
2022-08-11 16:14:11,255 - INFO - The train loss is 0.558300. The valid loss is 0.251367.
2022-08-11 16:14:11,283 - INFO - Epoch 2/20
2022-08-11 16:14:11,283 - INFO - Epoch 2/20
2022-08-11 16:14:11,283 - INFO - Epoch 2/20
2022-08-11 16:14:11,283 - INFO - Epoch 2/20
2022-08-11 16:14:11,283 - INFO - Epoch 2/20
2022-08-11 16:15:26,110 - INFO - The train loss is 0.111381. The valid loss is 0.045148.
2022-08-11 16:15:26,110 - INFO - The train loss is 0.111381. The valid loss is 0.045148.
2022-08-11 16:15:26,110 - INFO - The train loss is 0.111381. The valid loss is 0.045148.
2022-08-11 16:15:26,110 - INFO - The train loss is 0.111381. The valid loss is 0.045148.
2022-08-11 16:15:26,110 - INFO - The train loss is 0.111381. The valid loss is 0.045148.
2022-08-11 16:15:26,117 - INFO - Epoch 3/20
2022-08-11 16:15:26,117 - INFO - Epoch 3/20
2022-08-11 16:15:26,117 - INFO - Epoch 3/20
2022-08-11 16:15:26,117 - INFO - Epoch 3/20
2022-08-11 16:15:26,117 - INFO - Epoch 3/20
2022-08-11 16:16:41,456 - INFO - The train loss is 0.040368. The valid loss is 0.036164.
2022-08-11 16:16:41,456 - INFO - The train loss is 0.040368. The valid loss is 0.036164.
2022-08-11 16:16:41,456 - INFO - The train loss is 0.040368. The valid loss is 0.036164.
2022-08-11 16:16:41,456 - INFO - The train loss is 0.040368. The valid loss is 0.036164.
2022-08-11 16:16:41,456 - INFO - The train loss is 0.040368. The valid loss is 0.036164.
2022-08-11 16:16:41,462 - INFO - Epoch 4/20
2022-08-11 16:16:41,462 - INFO - Epoch 4/20
2022-08-11 16:16:41,462 - INFO - Epoch 4/20
2022-08-11 16:16:41,462 - INFO - Epoch 4/20
2022-08-11 16:16:41,462 - INFO - Epoch 4/20
2022-08-11 16:17:57,315 - INFO - The train loss is 0.037650. The valid loss is 0.035466.
2022-08-11 16:17:57,315 - INFO - The train loss is 0.037650. The valid loss is 0.035466.
2022-08-11 16:17:57,315 - INFO - The train loss is 0.037650. The valid loss is 0.035466.
2022-08-11 16:17:57,315 - INFO - The train loss is 0.037650. The valid loss is 0.035466.
2022-08-11 16:17:57,315 - INFO - The train loss is 0.037650. The valid loss is 0.035466.
2022-08-11 16:17:57,322 - INFO - Epoch 5/20
2022-08-11 16:17:57,322 - INFO - Epoch 5/20
2022-08-11 16:17:57,322 - INFO - Epoch 5/20
2022-08-11 16:17:57,322 - INFO - Epoch 5/20
2022-08-11 16:17:57,322 - INFO - Epoch 5/20
2022-08-11 16:19:15,099 - INFO - The train loss is 0.037128. The valid loss is 0.034983.
2022-08-11 16:19:15,099 - INFO - The train loss is 0.037128. The valid loss is 0.034983.
2022-08-11 16:19:15,099 - INFO - The train loss is 0.037128. The valid loss is 0.034983.
2022-08-11 16:19:15,099 - INFO - The train loss is 0.037128. The valid loss is 0.034983.
2022-08-11 16:19:15,099 - INFO - The train loss is 0.037128. The valid loss is 0.034983.
2022-08-11 16:19:15,106 - INFO - Epoch 6/20
2022-08-11 16:19:15,106 - INFO - Epoch 6/20
2022-08-11 16:19:15,106 - INFO - Epoch 6/20
2022-08-11 16:19:15,106 - INFO - Epoch 6/20
2022-08-11 16:19:15,106 - INFO - Epoch 6/20
2022-08-11 16:20:33,600 - INFO - The train loss is 0.036693. The valid loss is 0.034572.
2022-08-11 16:20:33,600 - INFO - The train loss is 0.036693. The valid loss is 0.034572.
2022-08-11 16:20:33,600 - INFO - The train loss is 0.036693. The valid loss is 0.034572.
2022-08-11 16:20:33,600 - INFO - The train loss is 0.036693. The valid loss is 0.034572.
2022-08-11 16:20:33,600 - INFO - The train loss is 0.036693. The valid loss is 0.034572.
2022-08-11 16:20:33,607 - INFO - Epoch 7/20
2022-08-11 16:20:33,607 - INFO - Epoch 7/20
2022-08-11 16:20:33,607 - INFO - Epoch 7/20
2022-08-11 16:20:33,607 - INFO - Epoch 7/20
2022-08-11 16:20:33,607 - INFO - Epoch 7/20
2022-08-11 16:21:56,325 - INFO - The train loss is 0.036327. The valid loss is 0.034212.
2022-08-11 16:21:56,325 - INFO - The train loss is 0.036327. The valid loss is 0.034212.
2022-08-11 16:21:56,325 - INFO - The train loss is 0.036327. The valid loss is 0.034212.
2022-08-11 16:21:56,325 - INFO - The train loss is 0.036327. The valid loss is 0.034212.
2022-08-11 16:21:56,325 - INFO - The train loss is 0.036327. The valid loss is 0.034212.
2022-08-11 16:21:56,332 - INFO - Epoch 8/20
2022-08-11 16:21:56,332 - INFO - Epoch 8/20
2022-08-11 16:21:56,332 - INFO - Epoch 8/20
2022-08-11 16:21:56,332 - INFO - Epoch 8/20
2022-08-11 16:21:56,332 - INFO - Epoch 8/20
2022-08-11 16:23:17,979 - INFO - The train loss is 0.035976. The valid loss is 0.033886.
2022-08-11 16:23:17,979 - INFO - The train loss is 0.035976. The valid loss is 0.033886.
2022-08-11 16:23:17,979 - INFO - The train loss is 0.035976. The valid loss is 0.033886.
2022-08-11 16:23:17,979 - INFO - The train loss is 0.035976. The valid loss is 0.033886.
2022-08-11 16:23:17,979 - INFO - The train loss is 0.035976. The valid loss is 0.033886.
2022-08-11 16:23:17,988 - INFO - Epoch 9/20
2022-08-11 16:23:17,988 - INFO - Epoch 9/20
2022-08-11 16:23:17,988 - INFO - Epoch 9/20
2022-08-11 16:23:17,988 - INFO - Epoch 9/20
2022-08-11 16:23:17,988 - INFO - Epoch 9/20
2022-08-11 16:24:43,549 - INFO - The train loss is 0.035691. The valid loss is 0.033586.
2022-08-11 16:24:43,549 - INFO - The train loss is 0.035691. The valid loss is 0.033586.
2022-08-11 16:24:43,549 - INFO - The train loss is 0.035691. The valid loss is 0.033586.
2022-08-11 16:24:43,549 - INFO - The train loss is 0.035691. The valid loss is 0.033586.
2022-08-11 16:24:43,549 - INFO - The train loss is 0.035691. The valid loss is 0.033586.
2022-08-11 16:24:43,555 - INFO - Epoch 10/20
2022-08-11 16:24:43,555 - INFO - Epoch 10/20
2022-08-11 16:24:43,555 - INFO - Epoch 10/20
2022-08-11 16:24:43,555 - INFO - Epoch 10/20
2022-08-11 16:24:43,555 - INFO - Epoch 10/20
2022-08-11 16:26:07,206 - INFO - The train loss is 0.035416. The valid loss is 0.033305.
2022-08-11 16:26:07,206 - INFO - The train loss is 0.035416. The valid loss is 0.033305.
2022-08-11 16:26:07,206 - INFO - The train loss is 0.035416. The valid loss is 0.033305.
2022-08-11 16:26:07,206 - INFO - The train loss is 0.035416. The valid loss is 0.033305.
2022-08-11 16:26:07,206 - INFO - The train loss is 0.035416. The valid loss is 0.033305.
2022-08-11 16:26:07,214 - INFO - Epoch 11/20
2022-08-11 16:26:07,214 - INFO - Epoch 11/20
2022-08-11 16:26:07,214 - INFO - Epoch 11/20
2022-08-11 16:26:07,214 - INFO - Epoch 11/20
2022-08-11 16:26:07,214 - INFO - Epoch 11/20
2022-08-11 16:27:28,449 - INFO - The train loss is 0.035138. The valid loss is 0.033038.
2022-08-11 16:27:28,449 - INFO - The train loss is 0.035138. The valid loss is 0.033038.
2022-08-11 16:27:28,449 - INFO - The train loss is 0.035138. The valid loss is 0.033038.
2022-08-11 16:27:28,449 - INFO - The train loss is 0.035138. The valid loss is 0.033038.
2022-08-11 16:27:28,449 - INFO - The train loss is 0.035138. The valid loss is 0.033038.
2022-08-11 16:27:28,455 - INFO - Epoch 12/20
2022-08-11 16:27:28,455 - INFO - Epoch 12/20
2022-08-11 16:27:28,455 - INFO - Epoch 12/20
2022-08-11 16:27:28,455 - INFO - Epoch 12/20
2022-08-11 16:27:28,455 - INFO - Epoch 12/20
2022-08-11 16:28:48,224 - INFO - The train loss is 0.034920. The valid loss is 0.032783.
2022-08-11 16:28:48,224 - INFO - The train loss is 0.034920. The valid loss is 0.032783.
2022-08-11 16:28:48,224 - INFO - The train loss is 0.034920. The valid loss is 0.032783.
2022-08-11 16:28:48,224 - INFO - The train loss is 0.034920. The valid loss is 0.032783.
2022-08-11 16:28:48,224 - INFO - The train loss is 0.034920. The valid loss is 0.032783.
2022-08-11 16:28:48,231 - INFO - Epoch 13/20
2022-08-11 16:28:48,231 - INFO - Epoch 13/20
2022-08-11 16:28:48,231 - INFO - Epoch 13/20
2022-08-11 16:28:48,231 - INFO - Epoch 13/20
2022-08-11 16:28:48,231 - INFO - Epoch 13/20
2022-08-11 16:30:07,501 - INFO - The train loss is 0.034635. The valid loss is 0.032536.
2022-08-11 16:30:07,501 - INFO - The train loss is 0.034635. The valid loss is 0.032536.
2022-08-11 16:30:07,501 - INFO - The train loss is 0.034635. The valid loss is 0.032536.
2022-08-11 16:30:07,501 - INFO - The train loss is 0.034635. The valid loss is 0.032536.
2022-08-11 16:30:07,501 - INFO - The train loss is 0.034635. The valid loss is 0.032536.
2022-08-11 16:30:07,508 - INFO - Epoch 14/20
2022-08-11 16:30:07,508 - INFO - Epoch 14/20
2022-08-11 16:30:07,508 - INFO - Epoch 14/20
2022-08-11 16:30:07,508 - INFO - Epoch 14/20
2022-08-11 16:30:07,508 - INFO - Epoch 14/20
2022-08-11 16:31:26,348 - INFO - The train loss is 0.034404. The valid loss is 0.032298.
2022-08-11 16:31:26,348 - INFO - The train loss is 0.034404. The valid loss is 0.032298.
2022-08-11 16:31:26,348 - INFO - The train loss is 0.034404. The valid loss is 0.032298.
2022-08-11 16:31:26,348 - INFO - The train loss is 0.034404. The valid loss is 0.032298.
2022-08-11 16:31:26,348 - INFO - The train loss is 0.034404. The valid loss is 0.032298.
2022-08-11 16:31:26,356 - INFO - Epoch 15/20
2022-08-11 16:31:26,356 - INFO - Epoch 15/20
2022-08-11 16:31:26,356 - INFO - Epoch 15/20
2022-08-11 16:31:26,356 - INFO - Epoch 15/20
2022-08-11 16:31:26,356 - INFO - Epoch 15/20
2022-08-11 16:32:46,152 - INFO - The train loss is 0.034173. The valid loss is 0.032065.
2022-08-11 16:32:46,152 - INFO - The train loss is 0.034173. The valid loss is 0.032065.
2022-08-11 16:32:46,152 - INFO - The train loss is 0.034173. The valid loss is 0.032065.
2022-08-11 16:32:46,152 - INFO - The train loss is 0.034173. The valid loss is 0.032065.
2022-08-11 16:32:46,152 - INFO - The train loss is 0.034173. The valid loss is 0.032065.
2022-08-11 16:32:46,159 - INFO - Epoch 16/20
2022-08-11 16:32:46,159 - INFO - Epoch 16/20
2022-08-11 16:32:46,159 - INFO - Epoch 16/20
2022-08-11 16:32:46,159 - INFO - Epoch 16/20
2022-08-11 16:32:46,159 - INFO - Epoch 16/20
2022-08-11 16:34:05,419 - INFO - The train loss is 0.033945. The valid loss is 0.031839.
2022-08-11 16:34:05,419 - INFO - The train loss is 0.033945. The valid loss is 0.031839.
2022-08-11 16:34:05,419 - INFO - The train loss is 0.033945. The valid loss is 0.031839.
2022-08-11 16:34:05,419 - INFO - The train loss is 0.033945. The valid loss is 0.031839.
2022-08-11 16:34:05,419 - INFO - The train loss is 0.033945. The valid loss is 0.031839.
2022-08-11 16:34:05,426 - INFO - Epoch 17/20
2022-08-11 16:34:05,426 - INFO - Epoch 17/20
2022-08-11 16:34:05,426 - INFO - Epoch 17/20
2022-08-11 16:34:05,426 - INFO - Epoch 17/20
2022-08-11 16:34:05,426 - INFO - Epoch 17/20
2022-08-11 16:35:28,436 - INFO - The train loss is 0.033737. The valid loss is 0.031618.
2022-08-11 16:35:28,436 - INFO - The train loss is 0.033737. The valid loss is 0.031618.
2022-08-11 16:35:28,436 - INFO - The train loss is 0.033737. The valid loss is 0.031618.
2022-08-11 16:35:28,436 - INFO - The train loss is 0.033737. The valid loss is 0.031618.
2022-08-11 16:35:28,436 - INFO - The train loss is 0.033737. The valid loss is 0.031618.
2022-08-11 16:35:28,442 - INFO - Epoch 18/20
2022-08-11 16:35:28,442 - INFO - Epoch 18/20
2022-08-11 16:35:28,442 - INFO - Epoch 18/20
2022-08-11 16:35:28,442 - INFO - Epoch 18/20
2022-08-11 16:35:28,442 - INFO - Epoch 18/20
2022-08-11 16:36:47,959 - INFO - The train loss is 0.033529. The valid loss is 0.031401.
2022-08-11 16:36:47,959 - INFO - The train loss is 0.033529. The valid loss is 0.031401.
2022-08-11 16:36:47,959 - INFO - The train loss is 0.033529. The valid loss is 0.031401.
2022-08-11 16:36:47,959 - INFO - The train loss is 0.033529. The valid loss is 0.031401.
2022-08-11 16:36:47,959 - INFO - The train loss is 0.033529. The valid loss is 0.031401.
2022-08-11 16:36:47,966 - INFO - Epoch 19/20
2022-08-11 16:36:47,966 - INFO - Epoch 19/20
2022-08-11 16:36:47,966 - INFO - Epoch 19/20
2022-08-11 16:36:47,966 - INFO - Epoch 19/20
2022-08-11 16:36:47,966 - INFO - Epoch 19/20
2022-08-11 16:38:07,102 - INFO - The train loss is 0.033335. The valid loss is 0.031188.
2022-08-11 16:38:07,102 - INFO - The train loss is 0.033335. The valid loss is 0.031188.
2022-08-11 16:38:07,102 - INFO - The train loss is 0.033335. The valid loss is 0.031188.
2022-08-11 16:38:07,102 - INFO - The train loss is 0.033335. The valid loss is 0.031188.
2022-08-11 16:38:07,102 - INFO - The train loss is 0.033335. The valid loss is 0.031188.
2022-08-11 16:38:11,384 - INFO - The mean squared error of btc ['midpoint'] is [0.00148238]
2022-08-11 16:38:11,384 - INFO - The mean squared error of btc ['midpoint'] is [0.00148238]
2022-08-11 16:38:11,384 - INFO - The mean squared error of btc ['midpoint'] is [0.00148238]
2022-08-11 16:38:11,384 - INFO - The mean squared error of btc ['midpoint'] is [0.00148238]
2022-08-11 16:38:11,384 - INFO - The mean squared error of btc ['midpoint'] is [0.00148238]
2022-08-11 16:38:11,490 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20174.80498049 20173.56622598 20173.78941606 20171.97720821
 20171.43141132]
2022-08-11 16:38:11,490 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20174.80498049 20173.56622598 20173.78941606 20171.97720821
 20171.43141132]
2022-08-11 16:38:11,490 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20174.80498049 20173.56622598 20173.78941606 20171.97720821
 20171.43141132]
2022-08-11 16:38:11,490 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20174.80498049 20173.56622598 20173.78941606 20171.97720821
 20171.43141132]
2022-08-11 16:38:11,490 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20174.80498049 20173.56622598 20173.78941606 20171.97720821
 20171.43141132]
2022-08-11 16:38:11,957 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-11 16:38:11,957 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-11 16:38:11,957 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-11 16:38:11,957 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-11 16:38:11,957 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-11 16:38:11,957 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-11 16:38:12,660 - INFO - Epoch 0/20
2022-08-11 16:38:12,660 - INFO - Epoch 0/20
2022-08-11 16:38:12,660 - INFO - Epoch 0/20
2022-08-11 16:38:12,660 - INFO - Epoch 0/20
2022-08-11 16:38:12,660 - INFO - Epoch 0/20
2022-08-11 16:38:12,660 - INFO - Epoch 0/20
2022-08-11 16:39:33,782 - INFO - The train loss is 0.058583. The valid loss is 0.007122.
2022-08-11 16:39:33,782 - INFO - The train loss is 0.058583. The valid loss is 0.007122.
2022-08-11 16:39:33,782 - INFO - The train loss is 0.058583. The valid loss is 0.007122.
2022-08-11 16:39:33,782 - INFO - The train loss is 0.058583. The valid loss is 0.007122.
2022-08-11 16:39:33,782 - INFO - The train loss is 0.058583. The valid loss is 0.007122.
2022-08-11 16:39:33,782 - INFO - The train loss is 0.058583. The valid loss is 0.007122.
2022-08-11 16:39:33,790 - INFO - Epoch 1/20
2022-08-11 16:39:33,790 - INFO - Epoch 1/20
2022-08-11 16:39:33,790 - INFO - Epoch 1/20
2022-08-11 16:39:33,790 - INFO - Epoch 1/20
2022-08-11 16:39:33,790 - INFO - Epoch 1/20
2022-08-11 16:39:33,790 - INFO - Epoch 1/20
2022-08-11 16:40:57,551 - INFO - The train loss is 0.005086. The valid loss is 0.000992.
2022-08-11 16:40:57,551 - INFO - The train loss is 0.005086. The valid loss is 0.000992.
2022-08-11 16:40:57,551 - INFO - The train loss is 0.005086. The valid loss is 0.000992.
2022-08-11 16:40:57,551 - INFO - The train loss is 0.005086. The valid loss is 0.000992.
2022-08-11 16:40:57,551 - INFO - The train loss is 0.005086. The valid loss is 0.000992.
2022-08-11 16:40:57,551 - INFO - The train loss is 0.005086. The valid loss is 0.000992.
2022-08-11 16:40:57,572 - INFO - Epoch 2/20
2022-08-11 16:40:57,572 - INFO - Epoch 2/20
2022-08-11 16:40:57,572 - INFO - Epoch 2/20
2022-08-11 16:40:57,572 - INFO - Epoch 2/20
2022-08-11 16:40:57,572 - INFO - Epoch 2/20
2022-08-11 16:40:57,572 - INFO - Epoch 2/20
2022-08-11 16:42:14,854 - INFO - The train loss is 0.001850. The valid loss is 0.000889.
2022-08-11 16:42:14,854 - INFO - The train loss is 0.001850. The valid loss is 0.000889.
2022-08-11 16:42:14,854 - INFO - The train loss is 0.001850. The valid loss is 0.000889.
2022-08-11 16:42:14,854 - INFO - The train loss is 0.001850. The valid loss is 0.000889.
2022-08-11 16:42:14,854 - INFO - The train loss is 0.001850. The valid loss is 0.000889.
2022-08-11 16:42:14,854 - INFO - The train loss is 0.001850. The valid loss is 0.000889.
2022-08-11 16:42:14,870 - INFO - Epoch 3/20
2022-08-11 16:42:14,870 - INFO - Epoch 3/20
2022-08-11 16:42:14,870 - INFO - Epoch 3/20
2022-08-11 16:42:14,870 - INFO - Epoch 3/20
2022-08-11 16:42:14,870 - INFO - Epoch 3/20
2022-08-11 16:42:14,870 - INFO - Epoch 3/20
2022-08-11 16:43:32,426 - INFO - The train loss is 0.001413. The valid loss is 0.000904.
2022-08-11 16:43:32,426 - INFO - The train loss is 0.001413. The valid loss is 0.000904.
2022-08-11 16:43:32,426 - INFO - The train loss is 0.001413. The valid loss is 0.000904.
2022-08-11 16:43:32,426 - INFO - The train loss is 0.001413. The valid loss is 0.000904.
2022-08-11 16:43:32,426 - INFO - The train loss is 0.001413. The valid loss is 0.000904.
2022-08-11 16:43:32,426 - INFO - The train loss is 0.001413. The valid loss is 0.000904.
2022-08-11 16:43:32,426 - INFO - Epoch 4/20
2022-08-11 16:43:32,426 - INFO - Epoch 4/20
2022-08-11 16:43:32,426 - INFO - Epoch 4/20
2022-08-11 16:43:32,426 - INFO - Epoch 4/20
2022-08-11 16:43:32,426 - INFO - Epoch 4/20
2022-08-11 16:43:32,426 - INFO - Epoch 4/20
2022-08-11 16:44:50,097 - INFO - The train loss is 0.001308. The valid loss is 0.000890.
2022-08-11 16:44:50,097 - INFO - The train loss is 0.001308. The valid loss is 0.000890.
2022-08-11 16:44:50,097 - INFO - The train loss is 0.001308. The valid loss is 0.000890.
2022-08-11 16:44:50,097 - INFO - The train loss is 0.001308. The valid loss is 0.000890.
2022-08-11 16:44:50,097 - INFO - The train loss is 0.001308. The valid loss is 0.000890.
2022-08-11 16:44:50,097 - INFO - The train loss is 0.001308. The valid loss is 0.000890.
2022-08-11 16:44:50,097 - INFO - Epoch 5/20
2022-08-11 16:44:50,097 - INFO - Epoch 5/20
2022-08-11 16:44:50,097 - INFO - Epoch 5/20
2022-08-11 16:44:50,097 - INFO - Epoch 5/20
2022-08-11 16:44:50,097 - INFO - Epoch 5/20
2022-08-11 16:44:50,097 - INFO - Epoch 5/20
2022-08-11 16:46:07,924 - INFO - The train loss is 0.001255. The valid loss is 0.000885.
2022-08-11 16:46:07,924 - INFO - The train loss is 0.001255. The valid loss is 0.000885.
2022-08-11 16:46:07,924 - INFO - The train loss is 0.001255. The valid loss is 0.000885.
2022-08-11 16:46:07,924 - INFO - The train loss is 0.001255. The valid loss is 0.000885.
2022-08-11 16:46:07,924 - INFO - The train loss is 0.001255. The valid loss is 0.000885.
2022-08-11 16:46:07,924 - INFO - The train loss is 0.001255. The valid loss is 0.000885.
2022-08-11 16:46:07,924 - INFO - Epoch 6/20
2022-08-11 16:46:07,924 - INFO - Epoch 6/20
2022-08-11 16:46:07,924 - INFO - Epoch 6/20
2022-08-11 16:46:07,924 - INFO - Epoch 6/20
2022-08-11 16:46:07,924 - INFO - Epoch 6/20
2022-08-11 16:46:07,924 - INFO - Epoch 6/20
2022-08-11 16:47:25,752 - INFO - The train loss is 0.001215. The valid loss is 0.000872.
2022-08-11 16:47:25,752 - INFO - The train loss is 0.001215. The valid loss is 0.000872.
2022-08-11 16:47:25,752 - INFO - The train loss is 0.001215. The valid loss is 0.000872.
2022-08-11 16:47:25,752 - INFO - The train loss is 0.001215. The valid loss is 0.000872.
2022-08-11 16:47:25,752 - INFO - The train loss is 0.001215. The valid loss is 0.000872.
2022-08-11 16:47:25,752 - INFO - The train loss is 0.001215. The valid loss is 0.000872.
2022-08-11 16:47:25,772 - INFO - Epoch 7/20
2022-08-11 16:47:25,772 - INFO - Epoch 7/20
2022-08-11 16:47:25,772 - INFO - Epoch 7/20
2022-08-11 16:47:25,772 - INFO - Epoch 7/20
2022-08-11 16:47:25,772 - INFO - Epoch 7/20
2022-08-11 16:47:25,772 - INFO - Epoch 7/20
2022-08-11 16:48:45,072 - INFO - The train loss is 0.001177. The valid loss is 0.000841.
2022-08-11 16:48:45,072 - INFO - The train loss is 0.001177. The valid loss is 0.000841.
2022-08-11 16:48:45,072 - INFO - The train loss is 0.001177. The valid loss is 0.000841.
2022-08-11 16:48:45,072 - INFO - The train loss is 0.001177. The valid loss is 0.000841.
2022-08-11 16:48:45,072 - INFO - The train loss is 0.001177. The valid loss is 0.000841.
2022-08-11 16:48:45,072 - INFO - The train loss is 0.001177. The valid loss is 0.000841.
2022-08-11 16:48:45,081 - INFO - Epoch 8/20
2022-08-11 16:48:45,081 - INFO - Epoch 8/20
2022-08-11 16:48:45,081 - INFO - Epoch 8/20
2022-08-11 16:48:45,081 - INFO - Epoch 8/20
2022-08-11 16:48:45,081 - INFO - Epoch 8/20
2022-08-11 16:48:45,081 - INFO - Epoch 8/20
2022-08-11 16:50:09,724 - INFO - The train loss is 0.001141. The valid loss is 0.000808.
2022-08-11 16:50:09,724 - INFO - The train loss is 0.001141. The valid loss is 0.000808.
2022-08-11 16:50:09,724 - INFO - The train loss is 0.001141. The valid loss is 0.000808.
2022-08-11 16:50:09,724 - INFO - The train loss is 0.001141. The valid loss is 0.000808.
2022-08-11 16:50:09,724 - INFO - The train loss is 0.001141. The valid loss is 0.000808.
2022-08-11 16:50:09,724 - INFO - The train loss is 0.001141. The valid loss is 0.000808.
2022-08-11 16:50:09,740 - INFO - Epoch 9/20
2022-08-11 16:50:09,740 - INFO - Epoch 9/20
2022-08-11 16:50:09,740 - INFO - Epoch 9/20
2022-08-11 16:50:09,740 - INFO - Epoch 9/20
2022-08-11 16:50:09,740 - INFO - Epoch 9/20
2022-08-11 16:50:09,740 - INFO - Epoch 9/20
2022-08-11 16:51:25,915 - INFO - The train loss is 0.001124. The valid loss is 0.000793.
2022-08-11 16:51:25,915 - INFO - The train loss is 0.001124. The valid loss is 0.000793.
2022-08-11 16:51:25,915 - INFO - The train loss is 0.001124. The valid loss is 0.000793.
2022-08-11 16:51:25,915 - INFO - The train loss is 0.001124. The valid loss is 0.000793.
2022-08-11 16:51:25,915 - INFO - The train loss is 0.001124. The valid loss is 0.000793.
2022-08-11 16:51:25,915 - INFO - The train loss is 0.001124. The valid loss is 0.000793.
2022-08-11 16:51:25,915 - INFO - Epoch 10/20
2022-08-11 16:51:25,915 - INFO - Epoch 10/20
2022-08-11 16:51:25,915 - INFO - Epoch 10/20
2022-08-11 16:51:25,915 - INFO - Epoch 10/20
2022-08-11 16:51:25,915 - INFO - Epoch 10/20
2022-08-11 16:51:25,915 - INFO - Epoch 10/20
2022-08-11 16:52:43,461 - INFO - The train loss is 0.001099. The valid loss is 0.000796.
2022-08-11 16:52:43,461 - INFO - The train loss is 0.001099. The valid loss is 0.000796.
2022-08-11 16:52:43,461 - INFO - The train loss is 0.001099. The valid loss is 0.000796.
2022-08-11 16:52:43,461 - INFO - The train loss is 0.001099. The valid loss is 0.000796.
2022-08-11 16:52:43,461 - INFO - The train loss is 0.001099. The valid loss is 0.000796.
2022-08-11 16:52:43,461 - INFO - The train loss is 0.001099. The valid loss is 0.000796.
2022-08-11 16:52:43,477 - INFO - Epoch 11/20
2022-08-11 16:52:43,477 - INFO - Epoch 11/20
2022-08-11 16:52:43,477 - INFO - Epoch 11/20
2022-08-11 16:52:43,477 - INFO - Epoch 11/20
2022-08-11 16:52:43,477 - INFO - Epoch 11/20
2022-08-11 16:52:43,477 - INFO - Epoch 11/20
2022-08-11 16:54:05,198 - INFO - The train loss is 0.001085. The valid loss is 0.000871.
2022-08-11 16:54:05,198 - INFO - The train loss is 0.001085. The valid loss is 0.000871.
2022-08-11 16:54:05,198 - INFO - The train loss is 0.001085. The valid loss is 0.000871.
2022-08-11 16:54:05,198 - INFO - The train loss is 0.001085. The valid loss is 0.000871.
2022-08-11 16:54:05,198 - INFO - The train loss is 0.001085. The valid loss is 0.000871.
2022-08-11 16:54:05,198 - INFO - The train loss is 0.001085. The valid loss is 0.000871.
2022-08-11 16:54:05,240 - INFO - Epoch 12/20
2022-08-11 16:54:05,240 - INFO - Epoch 12/20
2022-08-11 16:54:05,240 - INFO - Epoch 12/20
2022-08-11 16:54:05,240 - INFO - Epoch 12/20
2022-08-11 16:54:05,240 - INFO - Epoch 12/20
2022-08-11 16:54:05,240 - INFO - Epoch 12/20
2022-08-11 16:55:26,439 - INFO - The train loss is 0.001061. The valid loss is 0.000777.
2022-08-11 16:55:26,439 - INFO - The train loss is 0.001061. The valid loss is 0.000777.
2022-08-11 16:55:26,439 - INFO - The train loss is 0.001061. The valid loss is 0.000777.
2022-08-11 16:55:26,439 - INFO - The train loss is 0.001061. The valid loss is 0.000777.
2022-08-11 16:55:26,439 - INFO - The train loss is 0.001061. The valid loss is 0.000777.
2022-08-11 16:55:26,439 - INFO - The train loss is 0.001061. The valid loss is 0.000777.
2022-08-11 16:55:26,445 - INFO - Epoch 13/20
2022-08-11 16:55:26,445 - INFO - Epoch 13/20
2022-08-11 16:55:26,445 - INFO - Epoch 13/20
2022-08-11 16:55:26,445 - INFO - Epoch 13/20
2022-08-11 16:55:26,445 - INFO - Epoch 13/20
2022-08-11 16:55:26,445 - INFO - Epoch 13/20
2022-08-11 16:56:54,731 - INFO - The train loss is 0.001041. The valid loss is 0.000740.
2022-08-11 16:56:54,731 - INFO - The train loss is 0.001041. The valid loss is 0.000740.
2022-08-11 16:56:54,731 - INFO - The train loss is 0.001041. The valid loss is 0.000740.
2022-08-11 16:56:54,731 - INFO - The train loss is 0.001041. The valid loss is 0.000740.
2022-08-11 16:56:54,731 - INFO - The train loss is 0.001041. The valid loss is 0.000740.
2022-08-11 16:56:54,731 - INFO - The train loss is 0.001041. The valid loss is 0.000740.
2022-08-11 16:56:54,731 - INFO - Epoch 14/20
2022-08-11 16:56:54,731 - INFO - Epoch 14/20
2022-08-11 16:56:54,731 - INFO - Epoch 14/20
2022-08-11 16:56:54,731 - INFO - Epoch 14/20
2022-08-11 16:56:54,731 - INFO - Epoch 14/20
2022-08-11 16:56:54,731 - INFO - Epoch 14/20
2022-08-11 16:58:15,102 - INFO - The train loss is 0.001022. The valid loss is 0.001106.
2022-08-11 16:58:15,102 - INFO - The train loss is 0.001022. The valid loss is 0.001106.
2022-08-11 16:58:15,102 - INFO - The train loss is 0.001022. The valid loss is 0.001106.
2022-08-11 16:58:15,102 - INFO - The train loss is 0.001022. The valid loss is 0.001106.
2022-08-11 16:58:15,102 - INFO - The train loss is 0.001022. The valid loss is 0.001106.
2022-08-11 16:58:15,102 - INFO - The train loss is 0.001022. The valid loss is 0.001106.
2022-08-11 16:58:15,117 - INFO - Epoch 15/20
2022-08-11 16:58:15,117 - INFO - Epoch 15/20
2022-08-11 16:58:15,117 - INFO - Epoch 15/20
2022-08-11 16:58:15,117 - INFO - Epoch 15/20
2022-08-11 16:58:15,117 - INFO - Epoch 15/20
2022-08-11 16:58:15,117 - INFO - Epoch 15/20
2022-08-11 16:59:42,956 - INFO - The train loss is 0.001013. The valid loss is 0.000750.
2022-08-11 16:59:42,956 - INFO - The train loss is 0.001013. The valid loss is 0.000750.
2022-08-11 16:59:42,956 - INFO - The train loss is 0.001013. The valid loss is 0.000750.
2022-08-11 16:59:42,956 - INFO - The train loss is 0.001013. The valid loss is 0.000750.
2022-08-11 16:59:42,956 - INFO - The train loss is 0.001013. The valid loss is 0.000750.
2022-08-11 16:59:42,956 - INFO - The train loss is 0.001013. The valid loss is 0.000750.
2022-08-11 16:59:42,963 - INFO - Epoch 16/20
2022-08-11 16:59:42,963 - INFO - Epoch 16/20
2022-08-11 16:59:42,963 - INFO - Epoch 16/20
2022-08-11 16:59:42,963 - INFO - Epoch 16/20
2022-08-11 16:59:42,963 - INFO - Epoch 16/20
2022-08-11 16:59:42,963 - INFO - Epoch 16/20
2022-08-11 17:01:03,783 - INFO - The train loss is 0.000985. The valid loss is 0.000843.
2022-08-11 17:01:03,783 - INFO - The train loss is 0.000985. The valid loss is 0.000843.
2022-08-11 17:01:03,783 - INFO - The train loss is 0.000985. The valid loss is 0.000843.
2022-08-11 17:01:03,783 - INFO - The train loss is 0.000985. The valid loss is 0.000843.
2022-08-11 17:01:03,783 - INFO - The train loss is 0.000985. The valid loss is 0.000843.
2022-08-11 17:01:03,783 - INFO - The train loss is 0.000985. The valid loss is 0.000843.
2022-08-11 17:01:03,783 - INFO - Epoch 17/20
2022-08-11 17:01:03,783 - INFO - Epoch 17/20
2022-08-11 17:01:03,783 - INFO - Epoch 17/20
2022-08-11 17:01:03,783 - INFO - Epoch 17/20
2022-08-11 17:01:03,783 - INFO - Epoch 17/20
2022-08-11 17:01:03,783 - INFO - Epoch 17/20
2022-08-11 17:02:20,728 - INFO - The train loss is 0.000980. The valid loss is 0.000743.
2022-08-11 17:02:20,728 - INFO - The train loss is 0.000980. The valid loss is 0.000743.
2022-08-11 17:02:20,728 - INFO - The train loss is 0.000980. The valid loss is 0.000743.
2022-08-11 17:02:20,728 - INFO - The train loss is 0.000980. The valid loss is 0.000743.
2022-08-11 17:02:20,728 - INFO - The train loss is 0.000980. The valid loss is 0.000743.
2022-08-11 17:02:20,728 - INFO - The train loss is 0.000980. The valid loss is 0.000743.
2022-08-11 17:02:20,728 - INFO - Epoch 18/20
2022-08-11 17:02:20,728 - INFO - Epoch 18/20
2022-08-11 17:02:20,728 - INFO - Epoch 18/20
2022-08-11 17:02:20,728 - INFO - Epoch 18/20
2022-08-11 17:02:20,728 - INFO - Epoch 18/20
2022-08-11 17:02:20,728 - INFO - Epoch 18/20
2022-08-11 17:03:47,414 - INFO - The train loss is 0.000968. The valid loss is 0.000748.
2022-08-11 17:03:47,414 - INFO - The train loss is 0.000968. The valid loss is 0.000748.
2022-08-11 17:03:47,414 - INFO - The train loss is 0.000968. The valid loss is 0.000748.
2022-08-11 17:03:47,414 - INFO - The train loss is 0.000968. The valid loss is 0.000748.
2022-08-11 17:03:47,414 - INFO - The train loss is 0.000968. The valid loss is 0.000748.
2022-08-11 17:03:47,414 - INFO - The train loss is 0.000968. The valid loss is 0.000748.
2022-08-11 17:03:47,420 - INFO -  The training stops early in epoch 18
2022-08-11 17:03:47,420 - INFO -  The training stops early in epoch 18
2022-08-11 17:03:47,420 - INFO -  The training stops early in epoch 18
2022-08-11 17:03:47,420 - INFO -  The training stops early in epoch 18
2022-08-11 17:03:47,420 - INFO -  The training stops early in epoch 18
2022-08-11 17:03:47,420 - INFO -  The training stops early in epoch 18
2022-08-11 17:03:53,006 - INFO - The mean squared error of btc ['midpoint'] is [0.00057643]
2022-08-11 17:03:53,006 - INFO - The mean squared error of btc ['midpoint'] is [0.00057643]
2022-08-11 17:03:53,006 - INFO - The mean squared error of btc ['midpoint'] is [0.00057643]
2022-08-11 17:03:53,006 - INFO - The mean squared error of btc ['midpoint'] is [0.00057643]
2022-08-11 17:03:53,006 - INFO - The mean squared error of btc ['midpoint'] is [0.00057643]
2022-08-11 17:03:53,006 - INFO - The mean squared error of btc ['midpoint'] is [0.00057643]
2022-08-11 17:03:53,038 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20169.56176712 20171.01896913 20171.51864974 20170.45346202
 20170.29555094]
2022-08-11 17:03:53,038 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20169.56176712 20171.01896913 20171.51864974 20170.45346202
 20170.29555094]
2022-08-11 17:03:53,038 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20169.56176712 20171.01896913 20171.51864974 20170.45346202
 20170.29555094]
2022-08-11 17:03:53,038 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20169.56176712 20171.01896913 20171.51864974 20170.45346202
 20170.29555094]
2022-08-11 17:03:53,038 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20169.56176712 20171.01896913 20171.51864974 20170.45346202
 20170.29555094]
2022-08-11 17:03:53,038 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20169.56176712 20171.01896913 20171.51864974 20170.45346202
 20170.29555094]
2022-08-14 18:43:27,677 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-14 18:43:28,113 - INFO - Epoch 0/20
2022-08-14 18:43:54,387 - INFO - The train loss is 0.612280. The valid loss is 0.056442.
2022-08-14 18:43:54,447 - INFO - Epoch 1/20
2022-08-14 18:44:18,510 - INFO - The train loss is 0.054689. The valid loss is 0.047204.
2022-08-14 18:44:18,544 - INFO - Epoch 2/20
2022-08-14 18:44:42,600 - INFO - The train loss is 0.049034. The valid loss is 0.042461.
2022-08-14 18:44:42,603 - INFO - Epoch 3/20
2022-08-14 18:45:06,955 - INFO - The train loss is 0.044918. The valid loss is 0.038689.
2022-08-14 18:45:06,958 - INFO - Epoch 4/20
2022-08-14 18:45:31,033 - INFO - The train loss is 0.041471. The valid loss is 0.035592.
2022-08-14 18:45:31,036 - INFO - Epoch 5/20
2022-08-14 18:45:55,024 - INFO - The train loss is 0.038746. The valid loss is 0.033000.
2022-08-14 18:45:55,026 - INFO - Epoch 6/20
2022-08-14 18:46:18,917 - INFO - The train loss is 0.036404. The valid loss is 0.030788.
2022-08-14 18:46:18,921 - INFO - Epoch 7/20
2022-08-14 18:46:43,040 - INFO - The train loss is 0.034328. The valid loss is 0.028873.
2022-08-14 18:46:43,043 - INFO - Epoch 8/20
2022-08-14 18:47:07,098 - INFO - The train loss is 0.032632. The valid loss is 0.027205.
2022-08-14 18:47:07,101 - INFO - Epoch 9/20
2022-08-14 18:47:31,585 - INFO - The train loss is 0.031078. The valid loss is 0.025729.
2022-08-14 18:47:31,588 - INFO - Epoch 10/20
2022-08-14 18:47:56,536 - INFO - The train loss is 0.029722. The valid loss is 0.024414.
2022-08-14 18:47:56,539 - INFO - Epoch 11/20
2022-08-14 18:48:20,782 - INFO - The train loss is 0.028529. The valid loss is 0.023237.
2022-08-14 18:48:20,785 - INFO - Epoch 12/20
2022-08-14 18:48:45,044 - INFO - The train loss is 0.027419. The valid loss is 0.022173.
2022-08-14 18:48:45,048 - INFO - Epoch 13/20
2022-08-14 18:49:09,758 - INFO - The train loss is 0.026482. The valid loss is 0.021214.
2022-08-14 18:49:09,760 - INFO - Epoch 14/20
2022-08-14 18:49:33,721 - INFO - The train loss is 0.025555. The valid loss is 0.020335.
2022-08-14 18:49:33,725 - INFO - Epoch 15/20
2022-08-14 18:49:59,800 - INFO - The train loss is 0.024734. The valid loss is 0.019532.
2022-08-14 18:49:59,803 - INFO - Epoch 16/20
2022-08-14 18:50:23,996 - INFO - The train loss is 0.024011. The valid loss is 0.018793.
2022-08-14 18:50:23,999 - INFO - Epoch 17/20
2022-08-14 18:50:48,312 - INFO - The train loss is 0.023366. The valid loss is 0.018114.
2022-08-14 18:50:48,315 - INFO - Epoch 18/20
2022-08-14 18:51:12,564 - INFO - The train loss is 0.022675. The valid loss is 0.017486.
2022-08-14 18:51:12,567 - INFO - Epoch 19/20
2022-08-14 18:51:37,084 - INFO - The train loss is 0.022088. The valid loss is 0.016903.
2022-08-14 18:51:38,825 - INFO - The mean squared error of btc ['midpoint'] is [0.00181804]
2022-08-14 18:51:38,847 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20173.71718966 20176.40013921 20174.91297975 20178.87502169
 20172.90408407]
2022-08-14 18:51:39,338 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-14 18:51:39,338 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-14 18:51:39,591 - INFO - Epoch 0/20
2022-08-14 18:51:39,591 - INFO - Epoch 0/20
2022-08-14 18:52:04,345 - INFO - The train loss is 0.033376. The valid loss is 0.002225.
2022-08-14 18:52:04,345 - INFO - The train loss is 0.033376. The valid loss is 0.002225.
2022-08-14 18:52:04,349 - INFO - Epoch 1/20
2022-08-14 18:52:04,349 - INFO - Epoch 1/20
2022-08-14 18:52:29,193 - INFO - The train loss is 0.003331. The valid loss is 0.000883.
2022-08-14 18:52:29,193 - INFO - The train loss is 0.003331. The valid loss is 0.000883.
2022-08-14 18:52:29,196 - INFO - Epoch 2/20
2022-08-14 18:52:29,196 - INFO - Epoch 2/20
2022-08-14 18:52:54,155 - INFO - The train loss is 0.001860. The valid loss is 0.001025.
2022-08-14 18:52:54,155 - INFO - The train loss is 0.001860. The valid loss is 0.001025.
2022-08-14 18:52:54,157 - INFO - Epoch 3/20
2022-08-14 18:52:54,157 - INFO - Epoch 3/20
2022-08-14 18:53:18,946 - INFO - The train loss is 0.001544. The valid loss is 0.001216.
2022-08-14 18:53:18,946 - INFO - The train loss is 0.001544. The valid loss is 0.001216.
2022-08-14 18:53:18,948 - INFO - Epoch 4/20
2022-08-14 18:53:18,948 - INFO - Epoch 4/20
2022-08-14 18:53:43,655 - INFO - The train loss is 0.001420. The valid loss is 0.001094.
2022-08-14 18:53:43,655 - INFO - The train loss is 0.001420. The valid loss is 0.001094.
2022-08-14 18:53:43,657 - INFO - Epoch 5/20
2022-08-14 18:53:43,657 - INFO - Epoch 5/20
2022-08-14 18:54:08,473 - INFO - The train loss is 0.001322. The valid loss is 0.001086.
2022-08-14 18:54:08,473 - INFO - The train loss is 0.001322. The valid loss is 0.001086.
2022-08-14 18:54:08,475 - INFO - Epoch 6/20
2022-08-14 18:54:08,475 - INFO - Epoch 6/20
2022-08-14 18:54:33,198 - INFO - The train loss is 0.001296. The valid loss is 0.000768.
2022-08-14 18:54:33,198 - INFO - The train loss is 0.001296. The valid loss is 0.000768.
2022-08-14 18:54:33,202 - INFO - Epoch 7/20
2022-08-14 18:54:33,202 - INFO - Epoch 7/20
2022-08-14 18:54:58,001 - INFO - The train loss is 0.001227. The valid loss is 0.001220.
2022-08-14 18:54:58,001 - INFO - The train loss is 0.001227. The valid loss is 0.001220.
2022-08-14 18:54:58,003 - INFO - Epoch 8/20
2022-08-14 18:54:58,003 - INFO - Epoch 8/20
2022-08-14 18:55:22,694 - INFO - The train loss is 0.001187. The valid loss is 0.000819.
2022-08-14 18:55:22,694 - INFO - The train loss is 0.001187. The valid loss is 0.000819.
2022-08-14 18:55:22,695 - INFO - Epoch 9/20
2022-08-14 18:55:22,695 - INFO - Epoch 9/20
2022-08-14 18:55:47,571 - INFO - The train loss is 0.001165. The valid loss is 0.001086.
2022-08-14 18:55:47,571 - INFO - The train loss is 0.001165. The valid loss is 0.001086.
2022-08-14 18:55:47,572 - INFO - Epoch 10/20
2022-08-14 18:55:47,572 - INFO - Epoch 10/20
2022-08-14 18:56:12,483 - INFO - The train loss is 0.001165. The valid loss is 0.001235.
2022-08-14 18:56:12,483 - INFO - The train loss is 0.001165. The valid loss is 0.001235.
2022-08-14 18:56:12,484 - INFO - Epoch 11/20
2022-08-14 18:56:12,484 - INFO - Epoch 11/20
2022-08-14 18:56:37,279 - INFO - The train loss is 0.001144. The valid loss is 0.000754.
2022-08-14 18:56:37,279 - INFO - The train loss is 0.001144. The valid loss is 0.000754.
2022-08-14 18:56:37,283 - INFO - Epoch 12/20
2022-08-14 18:56:37,283 - INFO - Epoch 12/20
2022-08-14 18:57:01,987 - INFO - The train loss is 0.001132. The valid loss is 0.000762.
2022-08-14 18:57:01,987 - INFO - The train loss is 0.001132. The valid loss is 0.000762.
2022-08-14 18:57:01,989 - INFO - Epoch 13/20
2022-08-14 18:57:01,989 - INFO - Epoch 13/20
2022-08-14 18:57:26,999 - INFO - The train loss is 0.001100. The valid loss is 0.000926.
2022-08-14 18:57:26,999 - INFO - The train loss is 0.001100. The valid loss is 0.000926.
2022-08-14 18:57:27,000 - INFO - Epoch 14/20
2022-08-14 18:57:27,000 - INFO - Epoch 14/20
2022-08-14 18:57:52,765 - INFO - The train loss is 0.001089. The valid loss is 0.000988.
2022-08-14 18:57:52,765 - INFO - The train loss is 0.001089. The valid loss is 0.000988.
2022-08-14 18:57:52,767 - INFO - Epoch 15/20
2022-08-14 18:57:52,767 - INFO - Epoch 15/20
2022-08-14 18:58:18,035 - INFO - The train loss is 0.001091. The valid loss is 0.000823.
2022-08-14 18:58:18,035 - INFO - The train loss is 0.001091. The valid loss is 0.000823.
2022-08-14 18:58:18,037 - INFO - Epoch 16/20
2022-08-14 18:58:18,037 - INFO - Epoch 16/20
2022-08-14 18:58:43,176 - INFO - The train loss is 0.001080. The valid loss is 0.000750.
2022-08-14 18:58:43,176 - INFO - The train loss is 0.001080. The valid loss is 0.000750.
2022-08-14 18:58:43,180 - INFO - Epoch 17/20
2022-08-14 18:58:43,180 - INFO - Epoch 17/20
2022-08-14 18:59:08,609 - INFO - The train loss is 0.001051. The valid loss is 0.000768.
2022-08-14 18:59:08,609 - INFO - The train loss is 0.001051. The valid loss is 0.000768.
2022-08-14 18:59:08,611 - INFO - Epoch 18/20
2022-08-14 18:59:08,611 - INFO - Epoch 18/20
2022-08-14 18:59:34,210 - INFO - The train loss is 0.001068. The valid loss is 0.000797.
2022-08-14 18:59:34,210 - INFO - The train loss is 0.001068. The valid loss is 0.000797.
2022-08-14 18:59:34,211 - INFO - Epoch 19/20
2022-08-14 18:59:34,211 - INFO - Epoch 19/20
2022-08-14 18:59:59,695 - INFO - The train loss is 0.001055. The valid loss is 0.000730.
2022-08-14 18:59:59,695 - INFO - The train loss is 0.001055. The valid loss is 0.000730.
2022-08-14 19:00:01,482 - INFO - The mean squared error of btc ['midpoint'] is [0.00059169]
2022-08-14 19:00:01,482 - INFO - The mean squared error of btc ['midpoint'] is [0.00059169]
2022-08-14 19:00:01,506 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20170.80450955 20173.70106043 20172.89913432 20171.28986622
 20171.68677107]
2022-08-14 19:00:01,506 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20170.80450955 20173.70106043 20172.89913432 20171.28986622
 20171.68677107]
2022-08-14 19:00:02,000 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-14 19:00:02,000 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-14 19:00:02,000 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-14 19:00:02,272 - INFO - Epoch 0/20
2022-08-14 19:00:02,272 - INFO - Epoch 0/20
2022-08-14 19:00:02,272 - INFO - Epoch 0/20
2022-08-14 19:01:49,125 - INFO - The train loss is 0.101593. The valid loss is 0.017274.
2022-08-14 19:01:49,125 - INFO - The train loss is 0.101593. The valid loss is 0.017274.
2022-08-14 19:01:49,125 - INFO - The train loss is 0.101593. The valid loss is 0.017274.
2022-08-14 19:01:49,156 - INFO - Epoch 1/20
2022-08-14 19:01:49,156 - INFO - Epoch 1/20
2022-08-14 19:01:49,156 - INFO - Epoch 1/20
2022-08-14 19:03:29,830 - INFO - The train loss is 0.010987. The valid loss is 0.003878.
2022-08-14 19:03:29,830 - INFO - The train loss is 0.010987. The valid loss is 0.003878.
2022-08-14 19:03:29,830 - INFO - The train loss is 0.010987. The valid loss is 0.003878.
2022-08-14 19:03:29,895 - INFO - Epoch 2/20
2022-08-14 19:03:29,895 - INFO - Epoch 2/20
2022-08-14 19:03:29,895 - INFO - Epoch 2/20
2022-08-14 19:05:12,159 - INFO - The train loss is 0.003238. The valid loss is 0.001025.
2022-08-14 19:05:12,159 - INFO - The train loss is 0.003238. The valid loss is 0.001025.
2022-08-14 19:05:12,159 - INFO - The train loss is 0.003238. The valid loss is 0.001025.
2022-08-14 19:05:12,164 - INFO - Epoch 3/20
2022-08-14 19:05:12,164 - INFO - Epoch 3/20
2022-08-14 19:05:12,164 - INFO - Epoch 3/20
2022-08-14 19:06:50,203 - INFO - The train loss is 0.001743. The valid loss is 0.000874.
2022-08-14 19:06:50,203 - INFO - The train loss is 0.001743. The valid loss is 0.000874.
2022-08-14 19:06:50,203 - INFO - The train loss is 0.001743. The valid loss is 0.000874.
2022-08-14 19:06:50,209 - INFO - Epoch 4/20
2022-08-14 19:06:50,209 - INFO - Epoch 4/20
2022-08-14 19:06:50,209 - INFO - Epoch 4/20
2022-08-14 19:08:29,397 - INFO - The train loss is 0.001449. The valid loss is 0.000837.
2022-08-14 19:08:29,397 - INFO - The train loss is 0.001449. The valid loss is 0.000837.
2022-08-14 19:08:29,397 - INFO - The train loss is 0.001449. The valid loss is 0.000837.
2022-08-14 19:08:29,402 - INFO - Epoch 5/20
2022-08-14 19:08:29,402 - INFO - Epoch 5/20
2022-08-14 19:08:29,402 - INFO - Epoch 5/20
2022-08-14 19:10:07,772 - INFO - The train loss is 0.001321. The valid loss is 0.000856.
2022-08-14 19:10:07,772 - INFO - The train loss is 0.001321. The valid loss is 0.000856.
2022-08-14 19:10:07,772 - INFO - The train loss is 0.001321. The valid loss is 0.000856.
2022-08-14 19:10:07,798 - INFO - Epoch 6/20
2022-08-14 19:10:07,798 - INFO - Epoch 6/20
2022-08-14 19:10:07,798 - INFO - Epoch 6/20
2022-08-14 19:11:44,822 - INFO - The train loss is 0.001245. The valid loss is 0.000868.
2022-08-14 19:11:44,822 - INFO - The train loss is 0.001245. The valid loss is 0.000868.
2022-08-14 19:11:44,822 - INFO - The train loss is 0.001245. The valid loss is 0.000868.
2022-08-14 19:11:44,825 - INFO - Epoch 7/20
2022-08-14 19:11:44,825 - INFO - Epoch 7/20
2022-08-14 19:11:44,825 - INFO - Epoch 7/20
2022-08-14 19:13:21,321 - INFO - The train loss is 0.001189. The valid loss is 0.000856.
2022-08-14 19:13:21,321 - INFO - The train loss is 0.001189. The valid loss is 0.000856.
2022-08-14 19:13:21,321 - INFO - The train loss is 0.001189. The valid loss is 0.000856.
2022-08-14 19:13:21,324 - INFO - Epoch 8/20
2022-08-14 19:13:21,324 - INFO - Epoch 8/20
2022-08-14 19:13:21,324 - INFO - Epoch 8/20
2022-08-14 19:14:57,681 - INFO - The train loss is 0.001159. The valid loss is 0.000878.
2022-08-14 19:14:57,681 - INFO - The train loss is 0.001159. The valid loss is 0.000878.
2022-08-14 19:14:57,681 - INFO - The train loss is 0.001159. The valid loss is 0.000878.
2022-08-14 19:14:57,683 - INFO - Epoch 9/20
2022-08-14 19:14:57,683 - INFO - Epoch 9/20
2022-08-14 19:14:57,683 - INFO - Epoch 9/20
2022-08-14 19:16:34,734 - INFO - The train loss is 0.001114. The valid loss is 0.000959.
2022-08-14 19:16:34,734 - INFO - The train loss is 0.001114. The valid loss is 0.000959.
2022-08-14 19:16:34,734 - INFO - The train loss is 0.001114. The valid loss is 0.000959.
2022-08-14 19:16:34,736 - INFO -  The training stops early in epoch 9
2022-08-14 19:16:34,736 - INFO -  The training stops early in epoch 9
2022-08-14 19:16:34,736 - INFO -  The training stops early in epoch 9
2022-08-14 19:16:38,762 - INFO - The mean squared error of btc ['midpoint'] is [0.00058853]
2022-08-14 19:16:38,762 - INFO - The mean squared error of btc ['midpoint'] is [0.00058853]
2022-08-14 19:16:38,762 - INFO - The mean squared error of btc ['midpoint'] is [0.00058853]
2022-08-14 19:16:38,787 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20168.48175236 20170.24578708 20170.63535979 20169.59748819
 20169.57718608]
2022-08-14 19:16:38,787 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20168.48175236 20170.24578708 20170.63535979 20169.59748819
 20169.57718608]
2022-08-14 19:16:38,787 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20168.48175236 20170.24578708 20170.63535979 20169.59748819
 20169.57718608]
2022-08-14 19:16:39,120 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-14 19:16:39,120 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-14 19:16:39,120 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-14 19:16:39,120 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-14 19:16:39,362 - INFO - Epoch 0/20
2022-08-14 19:16:39,362 - INFO - Epoch 0/20
2022-08-14 19:16:39,362 - INFO - Epoch 0/20
2022-08-14 19:16:39,362 - INFO - Epoch 0/20
2022-08-14 19:18:15,773 - INFO - The train loss is 1.371175. The valid loss is 1.362244.
2022-08-14 19:18:15,773 - INFO - The train loss is 1.371175. The valid loss is 1.362244.
2022-08-14 19:18:15,773 - INFO - The train loss is 1.371175. The valid loss is 1.362244.
2022-08-14 19:18:15,773 - INFO - The train loss is 1.371175. The valid loss is 1.362244.
2022-08-14 19:18:15,797 - INFO - Epoch 1/20
2022-08-14 19:18:15,797 - INFO - Epoch 1/20
2022-08-14 19:18:15,797 - INFO - Epoch 1/20
2022-08-14 19:18:15,797 - INFO - Epoch 1/20
2022-08-14 19:19:51,541 - INFO - The train loss is 1.338674. The valid loss is 1.329520.
2022-08-14 19:19:51,541 - INFO - The train loss is 1.338674. The valid loss is 1.329520.
2022-08-14 19:19:51,541 - INFO - The train loss is 1.338674. The valid loss is 1.329520.
2022-08-14 19:19:51,541 - INFO - The train loss is 1.338674. The valid loss is 1.329520.
2022-08-14 19:19:51,548 - INFO - Epoch 2/20
2022-08-14 19:19:51,548 - INFO - Epoch 2/20
2022-08-14 19:19:51,548 - INFO - Epoch 2/20
2022-08-14 19:19:51,548 - INFO - Epoch 2/20
2022-08-14 19:21:28,155 - INFO - The train loss is 1.304669. The valid loss is 1.292665.
2022-08-14 19:21:28,155 - INFO - The train loss is 1.304669. The valid loss is 1.292665.
2022-08-14 19:21:28,155 - INFO - The train loss is 1.304669. The valid loss is 1.292665.
2022-08-14 19:21:28,155 - INFO - The train loss is 1.304669. The valid loss is 1.292665.
2022-08-14 19:21:28,161 - INFO - Epoch 3/20
2022-08-14 19:21:28,161 - INFO - Epoch 3/20
2022-08-14 19:21:28,161 - INFO - Epoch 3/20
2022-08-14 19:21:28,161 - INFO - Epoch 3/20
2022-08-14 19:23:03,142 - INFO - The train loss is 1.263842. The valid loss is 1.246152.
2022-08-14 19:23:03,142 - INFO - The train loss is 1.263842. The valid loss is 1.246152.
2022-08-14 19:23:03,142 - INFO - The train loss is 1.263842. The valid loss is 1.246152.
2022-08-14 19:23:03,142 - INFO - The train loss is 1.263842. The valid loss is 1.246152.
2022-08-14 19:23:03,149 - INFO - Epoch 4/20
2022-08-14 19:23:03,149 - INFO - Epoch 4/20
2022-08-14 19:23:03,149 - INFO - Epoch 4/20
2022-08-14 19:23:03,149 - INFO - Epoch 4/20
2022-08-14 19:24:38,059 - INFO - The train loss is 1.209961. The valid loss is 1.182656.
2022-08-14 19:24:38,059 - INFO - The train loss is 1.209961. The valid loss is 1.182656.
2022-08-14 19:24:38,059 - INFO - The train loss is 1.209961. The valid loss is 1.182656.
2022-08-14 19:24:38,059 - INFO - The train loss is 1.209961. The valid loss is 1.182656.
2022-08-14 19:24:38,067 - INFO - Epoch 5/20
2022-08-14 19:24:38,067 - INFO - Epoch 5/20
2022-08-14 19:24:38,067 - INFO - Epoch 5/20
2022-08-14 19:24:38,067 - INFO - Epoch 5/20
2022-08-14 19:26:12,708 - INFO - The train loss is 1.134115. The valid loss is 1.091122.
2022-08-14 19:26:12,708 - INFO - The train loss is 1.134115. The valid loss is 1.091122.
2022-08-14 19:26:12,708 - INFO - The train loss is 1.134115. The valid loss is 1.091122.
2022-08-14 19:26:12,708 - INFO - The train loss is 1.134115. The valid loss is 1.091122.
2022-08-14 19:26:12,715 - INFO - Epoch 6/20
2022-08-14 19:26:12,715 - INFO - Epoch 6/20
2022-08-14 19:26:12,715 - INFO - Epoch 6/20
2022-08-14 19:26:12,715 - INFO - Epoch 6/20
2022-08-14 19:27:49,731 - INFO - The train loss is 1.022648. The valid loss is 0.955032.
2022-08-14 19:27:49,731 - INFO - The train loss is 1.022648. The valid loss is 0.955032.
2022-08-14 19:27:49,731 - INFO - The train loss is 1.022648. The valid loss is 0.955032.
2022-08-14 19:27:49,731 - INFO - The train loss is 1.022648. The valid loss is 0.955032.
2022-08-14 19:27:49,737 - INFO - Epoch 7/20
2022-08-14 19:27:49,737 - INFO - Epoch 7/20
2022-08-14 19:27:49,737 - INFO - Epoch 7/20
2022-08-14 19:27:49,737 - INFO - Epoch 7/20
2022-08-14 19:29:30,708 - INFO - The train loss is 0.857289. The valid loss is 0.755335.
2022-08-14 19:29:30,708 - INFO - The train loss is 0.857289. The valid loss is 0.755335.
2022-08-14 19:29:30,708 - INFO - The train loss is 0.857289. The valid loss is 0.755335.
2022-08-14 19:29:30,708 - INFO - The train loss is 0.857289. The valid loss is 0.755335.
2022-08-14 19:29:30,715 - INFO - Epoch 8/20
2022-08-14 19:29:30,715 - INFO - Epoch 8/20
2022-08-14 19:29:30,715 - INFO - Epoch 8/20
2022-08-14 19:29:30,715 - INFO - Epoch 8/20
2022-08-14 19:31:12,124 - INFO - The train loss is 0.626175. The valid loss is 0.494188.
2022-08-14 19:31:12,124 - INFO - The train loss is 0.626175. The valid loss is 0.494188.
2022-08-14 19:31:12,124 - INFO - The train loss is 0.626175. The valid loss is 0.494188.
2022-08-14 19:31:12,124 - INFO - The train loss is 0.626175. The valid loss is 0.494188.
2022-08-14 19:31:12,130 - INFO - Epoch 9/20
2022-08-14 19:31:12,130 - INFO - Epoch 9/20
2022-08-14 19:31:12,130 - INFO - Epoch 9/20
2022-08-14 19:31:12,130 - INFO - Epoch 9/20
2022-08-14 19:32:56,764 - INFO - The train loss is 0.363476. The valid loss is 0.245596.
2022-08-14 19:32:56,764 - INFO - The train loss is 0.363476. The valid loss is 0.245596.
2022-08-14 19:32:56,764 - INFO - The train loss is 0.363476. The valid loss is 0.245596.
2022-08-14 19:32:56,764 - INFO - The train loss is 0.363476. The valid loss is 0.245596.
2022-08-14 19:32:56,771 - INFO - Epoch 10/20
2022-08-14 19:32:56,771 - INFO - Epoch 10/20
2022-08-14 19:32:56,771 - INFO - Epoch 10/20
2022-08-14 19:32:56,771 - INFO - Epoch 10/20
2022-08-14 19:34:36,757 - INFO - The train loss is 0.168016. The valid loss is 0.109957.
2022-08-14 19:34:36,757 - INFO - The train loss is 0.168016. The valid loss is 0.109957.
2022-08-14 19:34:36,757 - INFO - The train loss is 0.168016. The valid loss is 0.109957.
2022-08-14 19:34:36,757 - INFO - The train loss is 0.168016. The valid loss is 0.109957.
2022-08-14 19:34:36,764 - INFO - Epoch 11/20
2022-08-14 19:34:36,764 - INFO - Epoch 11/20
2022-08-14 19:34:36,764 - INFO - Epoch 11/20
2022-08-14 19:34:36,764 - INFO - Epoch 11/20
2022-08-14 19:36:16,254 - INFO - The train loss is 0.086496. The valid loss is 0.070269.
2022-08-14 19:36:16,254 - INFO - The train loss is 0.086496. The valid loss is 0.070269.
2022-08-14 19:36:16,254 - INFO - The train loss is 0.086496. The valid loss is 0.070269.
2022-08-14 19:36:16,254 - INFO - The train loss is 0.086496. The valid loss is 0.070269.
2022-08-14 19:36:16,261 - INFO - Epoch 12/20
2022-08-14 19:36:16,261 - INFO - Epoch 12/20
2022-08-14 19:36:16,261 - INFO - Epoch 12/20
2022-08-14 19:36:16,261 - INFO - Epoch 12/20
2022-08-14 19:37:54,372 - INFO - The train loss is 0.066451. The valid loss is 0.062500.
2022-08-14 19:37:54,372 - INFO - The train loss is 0.066451. The valid loss is 0.062500.
2022-08-14 19:37:54,372 - INFO - The train loss is 0.066451. The valid loss is 0.062500.
2022-08-14 19:37:54,372 - INFO - The train loss is 0.066451. The valid loss is 0.062500.
2022-08-14 19:37:54,379 - INFO - Epoch 13/20
2022-08-14 19:37:54,379 - INFO - Epoch 13/20
2022-08-14 19:37:54,379 - INFO - Epoch 13/20
2022-08-14 19:37:54,379 - INFO - Epoch 13/20
2022-08-14 19:39:33,939 - INFO - The train loss is 0.062539. The valid loss is 0.060774.
2022-08-14 19:39:33,939 - INFO - The train loss is 0.062539. The valid loss is 0.060774.
2022-08-14 19:39:33,939 - INFO - The train loss is 0.062539. The valid loss is 0.060774.
2022-08-14 19:39:33,939 - INFO - The train loss is 0.062539. The valid loss is 0.060774.
2022-08-14 19:39:33,945 - INFO - Epoch 14/20
2022-08-14 19:39:33,945 - INFO - Epoch 14/20
2022-08-14 19:39:33,945 - INFO - Epoch 14/20
2022-08-14 19:39:33,945 - INFO - Epoch 14/20
2022-08-14 19:41:15,315 - INFO - The train loss is 0.061362. The valid loss is 0.059929.
2022-08-14 19:41:15,315 - INFO - The train loss is 0.061362. The valid loss is 0.059929.
2022-08-14 19:41:15,315 - INFO - The train loss is 0.061362. The valid loss is 0.059929.
2022-08-14 19:41:15,315 - INFO - The train loss is 0.061362. The valid loss is 0.059929.
2022-08-14 19:41:15,321 - INFO - Epoch 15/20
2022-08-14 19:41:15,321 - INFO - Epoch 15/20
2022-08-14 19:41:15,321 - INFO - Epoch 15/20
2022-08-14 19:41:15,321 - INFO - Epoch 15/20
2022-08-14 19:42:55,128 - INFO - The train loss is 0.060590. The valid loss is 0.059217.
2022-08-14 19:42:55,128 - INFO - The train loss is 0.060590. The valid loss is 0.059217.
2022-08-14 19:42:55,128 - INFO - The train loss is 0.060590. The valid loss is 0.059217.
2022-08-14 19:42:55,128 - INFO - The train loss is 0.060590. The valid loss is 0.059217.
2022-08-14 19:42:55,133 - INFO - Epoch 16/20
2022-08-14 19:42:55,133 - INFO - Epoch 16/20
2022-08-14 19:42:55,133 - INFO - Epoch 16/20
2022-08-14 19:42:55,133 - INFO - Epoch 16/20
2022-08-14 19:44:34,993 - INFO - The train loss is 0.059917. The valid loss is 0.058545.
2022-08-14 19:44:34,993 - INFO - The train loss is 0.059917. The valid loss is 0.058545.
2022-08-14 19:44:34,993 - INFO - The train loss is 0.059917. The valid loss is 0.058545.
2022-08-14 19:44:34,993 - INFO - The train loss is 0.059917. The valid loss is 0.058545.
2022-08-14 19:44:35,000 - INFO - Epoch 17/20
2022-08-14 19:44:35,000 - INFO - Epoch 17/20
2022-08-14 19:44:35,000 - INFO - Epoch 17/20
2022-08-14 19:44:35,000 - INFO - Epoch 17/20
2022-08-14 19:46:15,456 - INFO - The train loss is 0.059279. The valid loss is 0.057899.
2022-08-14 19:46:15,456 - INFO - The train loss is 0.059279. The valid loss is 0.057899.
2022-08-14 19:46:15,456 - INFO - The train loss is 0.059279. The valid loss is 0.057899.
2022-08-14 19:46:15,456 - INFO - The train loss is 0.059279. The valid loss is 0.057899.
2022-08-14 19:46:15,463 - INFO - Epoch 18/20
2022-08-14 19:46:15,463 - INFO - Epoch 18/20
2022-08-14 19:46:15,463 - INFO - Epoch 18/20
2022-08-14 19:46:15,463 - INFO - Epoch 18/20
2022-08-14 19:47:56,134 - INFO - The train loss is 0.058622. The valid loss is 0.057278.
2022-08-14 19:47:56,134 - INFO - The train loss is 0.058622. The valid loss is 0.057278.
2022-08-14 19:47:56,134 - INFO - The train loss is 0.058622. The valid loss is 0.057278.
2022-08-14 19:47:56,134 - INFO - The train loss is 0.058622. The valid loss is 0.057278.
2022-08-14 19:47:56,141 - INFO - Epoch 19/20
2022-08-14 19:47:56,141 - INFO - Epoch 19/20
2022-08-14 19:47:56,141 - INFO - Epoch 19/20
2022-08-14 19:47:56,141 - INFO - Epoch 19/20
2022-08-14 19:49:37,572 - INFO - The train loss is 0.058026. The valid loss is 0.056680.
2022-08-14 19:49:37,572 - INFO - The train loss is 0.058026. The valid loss is 0.056680.
2022-08-14 19:49:37,572 - INFO - The train loss is 0.058026. The valid loss is 0.056680.
2022-08-14 19:49:37,572 - INFO - The train loss is 0.058026. The valid loss is 0.056680.
2022-08-14 19:49:41,821 - INFO - The mean squared error of btc ['midpoint'] is [0.00678577]
2022-08-14 19:49:41,821 - INFO - The mean squared error of btc ['midpoint'] is [0.00678577]
2022-08-14 19:49:41,821 - INFO - The mean squared error of btc ['midpoint'] is [0.00678577]
2022-08-14 19:49:41,821 - INFO - The mean squared error of btc ['midpoint'] is [0.00678577]
2022-08-14 19:49:41,847 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20181.46826165 20181.37366149 20180.99423983 20181.39100411
 20181.5937441 ]
2022-08-14 19:49:41,847 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20181.46826165 20181.37366149 20180.99423983 20181.39100411
 20181.5937441 ]
2022-08-14 19:49:41,847 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20181.46826165 20181.37366149 20180.99423983 20181.39100411
 20181.5937441 ]
2022-08-14 19:49:41,847 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20181.46826165 20181.37366149 20180.99423983 20181.39100411
 20181.5937441 ]
2022-08-14 19:49:42,190 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-14 19:49:42,190 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-14 19:49:42,190 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-14 19:49:42,190 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-14 19:49:42,190 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-14 19:49:42,441 - INFO - Epoch 0/20
2022-08-14 19:49:42,441 - INFO - Epoch 0/20
2022-08-14 19:49:42,441 - INFO - Epoch 0/20
2022-08-14 19:49:42,441 - INFO - Epoch 0/20
2022-08-14 19:49:42,441 - INFO - Epoch 0/20
2022-08-14 19:51:08,835 - INFO - The train loss is 1.159923. The valid loss is 0.894096.
2022-08-14 19:51:08,835 - INFO - The train loss is 1.159923. The valid loss is 0.894096.
2022-08-14 19:51:08,835 - INFO - The train loss is 1.159923. The valid loss is 0.894096.
2022-08-14 19:51:08,835 - INFO - The train loss is 1.159923. The valid loss is 0.894096.
2022-08-14 19:51:08,835 - INFO - The train loss is 1.159923. The valid loss is 0.894096.
2022-08-14 19:51:08,890 - INFO - Epoch 1/20
2022-08-14 19:51:08,890 - INFO - Epoch 1/20
2022-08-14 19:51:08,890 - INFO - Epoch 1/20
2022-08-14 19:51:08,890 - INFO - Epoch 1/20
2022-08-14 19:51:08,890 - INFO - Epoch 1/20
2022-08-14 19:52:31,573 - INFO - The train loss is 0.563167. The valid loss is 0.251607.
2022-08-14 19:52:31,573 - INFO - The train loss is 0.563167. The valid loss is 0.251607.
2022-08-14 19:52:31,573 - INFO - The train loss is 0.563167. The valid loss is 0.251607.
2022-08-14 19:52:31,573 - INFO - The train loss is 0.563167. The valid loss is 0.251607.
2022-08-14 19:52:31,573 - INFO - The train loss is 0.563167. The valid loss is 0.251607.
2022-08-14 19:52:31,629 - INFO - Epoch 2/20
2022-08-14 19:52:31,629 - INFO - Epoch 2/20
2022-08-14 19:52:31,629 - INFO - Epoch 2/20
2022-08-14 19:52:31,629 - INFO - Epoch 2/20
2022-08-14 19:52:31,629 - INFO - Epoch 2/20
2022-08-14 19:53:53,894 - INFO - The train loss is 0.110686. The valid loss is 0.044569.
2022-08-14 19:53:53,894 - INFO - The train loss is 0.110686. The valid loss is 0.044569.
2022-08-14 19:53:53,894 - INFO - The train loss is 0.110686. The valid loss is 0.044569.
2022-08-14 19:53:53,894 - INFO - The train loss is 0.110686. The valid loss is 0.044569.
2022-08-14 19:53:53,894 - INFO - The train loss is 0.110686. The valid loss is 0.044569.
2022-08-14 19:53:53,900 - INFO - Epoch 3/20
2022-08-14 19:53:53,900 - INFO - Epoch 3/20
2022-08-14 19:53:53,900 - INFO - Epoch 3/20
2022-08-14 19:53:53,900 - INFO - Epoch 3/20
2022-08-14 19:53:53,900 - INFO - Epoch 3/20
2022-08-14 19:55:15,628 - INFO - The train loss is 0.039901. The valid loss is 0.036016.
2022-08-14 19:55:15,628 - INFO - The train loss is 0.039901. The valid loss is 0.036016.
2022-08-14 19:55:15,628 - INFO - The train loss is 0.039901. The valid loss is 0.036016.
2022-08-14 19:55:15,628 - INFO - The train loss is 0.039901. The valid loss is 0.036016.
2022-08-14 19:55:15,628 - INFO - The train loss is 0.039901. The valid loss is 0.036016.
2022-08-14 19:55:15,634 - INFO - Epoch 4/20
2022-08-14 19:55:15,634 - INFO - Epoch 4/20
2022-08-14 19:55:15,634 - INFO - Epoch 4/20
2022-08-14 19:55:15,634 - INFO - Epoch 4/20
2022-08-14 19:55:15,634 - INFO - Epoch 4/20
2022-08-14 19:56:37,853 - INFO - The train loss is 0.037536. The valid loss is 0.035565.
2022-08-14 19:56:37,853 - INFO - The train loss is 0.037536. The valid loss is 0.035565.
2022-08-14 19:56:37,853 - INFO - The train loss is 0.037536. The valid loss is 0.035565.
2022-08-14 19:56:37,853 - INFO - The train loss is 0.037536. The valid loss is 0.035565.
2022-08-14 19:56:37,853 - INFO - The train loss is 0.037536. The valid loss is 0.035565.
2022-08-14 19:56:37,860 - INFO - Epoch 5/20
2022-08-14 19:56:37,860 - INFO - Epoch 5/20
2022-08-14 19:56:37,860 - INFO - Epoch 5/20
2022-08-14 19:56:37,860 - INFO - Epoch 5/20
2022-08-14 19:56:37,860 - INFO - Epoch 5/20
2022-08-14 19:58:00,111 - INFO - The train loss is 0.037213. The valid loss is 0.035241.
2022-08-14 19:58:00,111 - INFO - The train loss is 0.037213. The valid loss is 0.035241.
2022-08-14 19:58:00,111 - INFO - The train loss is 0.037213. The valid loss is 0.035241.
2022-08-14 19:58:00,111 - INFO - The train loss is 0.037213. The valid loss is 0.035241.
2022-08-14 19:58:00,111 - INFO - The train loss is 0.037213. The valid loss is 0.035241.
2022-08-14 19:58:00,118 - INFO - Epoch 6/20
2022-08-14 19:58:00,118 - INFO - Epoch 6/20
2022-08-14 19:58:00,118 - INFO - Epoch 6/20
2022-08-14 19:58:00,118 - INFO - Epoch 6/20
2022-08-14 19:58:00,118 - INFO - Epoch 6/20
2022-08-14 19:59:21,624 - INFO - The train loss is 0.036848. The valid loss is 0.034937.
2022-08-14 19:59:21,624 - INFO - The train loss is 0.036848. The valid loss is 0.034937.
2022-08-14 19:59:21,624 - INFO - The train loss is 0.036848. The valid loss is 0.034937.
2022-08-14 19:59:21,624 - INFO - The train loss is 0.036848. The valid loss is 0.034937.
2022-08-14 19:59:21,624 - INFO - The train loss is 0.036848. The valid loss is 0.034937.
2022-08-14 19:59:21,631 - INFO - Epoch 7/20
2022-08-14 19:59:21,631 - INFO - Epoch 7/20
2022-08-14 19:59:21,631 - INFO - Epoch 7/20
2022-08-14 19:59:21,631 - INFO - Epoch 7/20
2022-08-14 19:59:21,631 - INFO - Epoch 7/20
2022-08-14 20:00:44,312 - INFO - The train loss is 0.036602. The valid loss is 0.034648.
2022-08-14 20:00:44,312 - INFO - The train loss is 0.036602. The valid loss is 0.034648.
2022-08-14 20:00:44,312 - INFO - The train loss is 0.036602. The valid loss is 0.034648.
2022-08-14 20:00:44,312 - INFO - The train loss is 0.036602. The valid loss is 0.034648.
2022-08-14 20:00:44,312 - INFO - The train loss is 0.036602. The valid loss is 0.034648.
2022-08-14 20:00:44,332 - INFO - Epoch 8/20
2022-08-14 20:00:44,332 - INFO - Epoch 8/20
2022-08-14 20:00:44,332 - INFO - Epoch 8/20
2022-08-14 20:00:44,332 - INFO - Epoch 8/20
2022-08-14 20:00:44,332 - INFO - Epoch 8/20
2022-08-14 20:02:06,769 - INFO - The train loss is 0.036310. The valid loss is 0.034371.
2022-08-14 20:02:06,769 - INFO - The train loss is 0.036310. The valid loss is 0.034371.
2022-08-14 20:02:06,769 - INFO - The train loss is 0.036310. The valid loss is 0.034371.
2022-08-14 20:02:06,769 - INFO - The train loss is 0.036310. The valid loss is 0.034371.
2022-08-14 20:02:06,769 - INFO - The train loss is 0.036310. The valid loss is 0.034371.
2022-08-14 20:02:06,776 - INFO - Epoch 9/20
2022-08-14 20:02:06,776 - INFO - Epoch 9/20
2022-08-14 20:02:06,776 - INFO - Epoch 9/20
2022-08-14 20:02:06,776 - INFO - Epoch 9/20
2022-08-14 20:02:06,776 - INFO - Epoch 9/20
2022-08-14 20:03:31,024 - INFO - The train loss is 0.036067. The valid loss is 0.034105.
2022-08-14 20:03:31,024 - INFO - The train loss is 0.036067. The valid loss is 0.034105.
2022-08-14 20:03:31,024 - INFO - The train loss is 0.036067. The valid loss is 0.034105.
2022-08-14 20:03:31,024 - INFO - The train loss is 0.036067. The valid loss is 0.034105.
2022-08-14 20:03:31,024 - INFO - The train loss is 0.036067. The valid loss is 0.034105.
2022-08-14 20:03:31,031 - INFO - Epoch 10/20
2022-08-14 20:03:31,031 - INFO - Epoch 10/20
2022-08-14 20:03:31,031 - INFO - Epoch 10/20
2022-08-14 20:03:31,031 - INFO - Epoch 10/20
2022-08-14 20:03:31,031 - INFO - Epoch 10/20
2022-08-14 20:04:54,672 - INFO - The train loss is 0.035813. The valid loss is 0.033848.
2022-08-14 20:04:54,672 - INFO - The train loss is 0.035813. The valid loss is 0.033848.
2022-08-14 20:04:54,672 - INFO - The train loss is 0.035813. The valid loss is 0.033848.
2022-08-14 20:04:54,672 - INFO - The train loss is 0.035813. The valid loss is 0.033848.
2022-08-14 20:04:54,672 - INFO - The train loss is 0.035813. The valid loss is 0.033848.
2022-08-14 20:04:54,680 - INFO - Epoch 11/20
2022-08-14 20:04:54,680 - INFO - Epoch 11/20
2022-08-14 20:04:54,680 - INFO - Epoch 11/20
2022-08-14 20:04:54,680 - INFO - Epoch 11/20
2022-08-14 20:04:54,680 - INFO - Epoch 11/20
2022-08-14 20:06:17,860 - INFO - The train loss is 0.035583. The valid loss is 0.033599.
2022-08-14 20:06:17,860 - INFO - The train loss is 0.035583. The valid loss is 0.033599.
2022-08-14 20:06:17,860 - INFO - The train loss is 0.035583. The valid loss is 0.033599.
2022-08-14 20:06:17,860 - INFO - The train loss is 0.035583. The valid loss is 0.033599.
2022-08-14 20:06:17,860 - INFO - The train loss is 0.035583. The valid loss is 0.033599.
2022-08-14 20:06:17,868 - INFO - Epoch 12/20
2022-08-14 20:06:17,868 - INFO - Epoch 12/20
2022-08-14 20:06:17,868 - INFO - Epoch 12/20
2022-08-14 20:06:17,868 - INFO - Epoch 12/20
2022-08-14 20:06:17,868 - INFO - Epoch 12/20
2022-08-14 20:07:40,724 - INFO - The train loss is 0.035335. The valid loss is 0.033355.
2022-08-14 20:07:40,724 - INFO - The train loss is 0.035335. The valid loss is 0.033355.
2022-08-14 20:07:40,724 - INFO - The train loss is 0.035335. The valid loss is 0.033355.
2022-08-14 20:07:40,724 - INFO - The train loss is 0.035335. The valid loss is 0.033355.
2022-08-14 20:07:40,724 - INFO - The train loss is 0.035335. The valid loss is 0.033355.
2022-08-14 20:07:40,730 - INFO - Epoch 13/20
2022-08-14 20:07:40,730 - INFO - Epoch 13/20
2022-08-14 20:07:40,730 - INFO - Epoch 13/20
2022-08-14 20:07:40,730 - INFO - Epoch 13/20
2022-08-14 20:07:40,730 - INFO - Epoch 13/20
2022-08-14 20:09:02,626 - INFO - The train loss is 0.035128. The valid loss is 0.033116.
2022-08-14 20:09:02,626 - INFO - The train loss is 0.035128. The valid loss is 0.033116.
2022-08-14 20:09:02,626 - INFO - The train loss is 0.035128. The valid loss is 0.033116.
2022-08-14 20:09:02,626 - INFO - The train loss is 0.035128. The valid loss is 0.033116.
2022-08-14 20:09:02,626 - INFO - The train loss is 0.035128. The valid loss is 0.033116.
2022-08-14 20:09:02,633 - INFO - Epoch 14/20
2022-08-14 20:09:02,633 - INFO - Epoch 14/20
2022-08-14 20:09:02,633 - INFO - Epoch 14/20
2022-08-14 20:09:02,633 - INFO - Epoch 14/20
2022-08-14 20:09:02,633 - INFO - Epoch 14/20
2022-08-14 20:10:24,917 - INFO - The train loss is 0.034860. The valid loss is 0.032883.
2022-08-14 20:10:24,917 - INFO - The train loss is 0.034860. The valid loss is 0.032883.
2022-08-14 20:10:24,917 - INFO - The train loss is 0.034860. The valid loss is 0.032883.
2022-08-14 20:10:24,917 - INFO - The train loss is 0.034860. The valid loss is 0.032883.
2022-08-14 20:10:24,917 - INFO - The train loss is 0.034860. The valid loss is 0.032883.
2022-08-14 20:10:24,923 - INFO - Epoch 15/20
2022-08-14 20:10:24,923 - INFO - Epoch 15/20
2022-08-14 20:10:24,923 - INFO - Epoch 15/20
2022-08-14 20:10:24,923 - INFO - Epoch 15/20
2022-08-14 20:10:24,923 - INFO - Epoch 15/20
2022-08-14 20:11:47,262 - INFO - The train loss is 0.034628. The valid loss is 0.032654.
2022-08-14 20:11:47,262 - INFO - The train loss is 0.034628. The valid loss is 0.032654.
2022-08-14 20:11:47,262 - INFO - The train loss is 0.034628. The valid loss is 0.032654.
2022-08-14 20:11:47,262 - INFO - The train loss is 0.034628. The valid loss is 0.032654.
2022-08-14 20:11:47,262 - INFO - The train loss is 0.034628. The valid loss is 0.032654.
2022-08-14 20:11:47,269 - INFO - Epoch 16/20
2022-08-14 20:11:47,269 - INFO - Epoch 16/20
2022-08-14 20:11:47,269 - INFO - Epoch 16/20
2022-08-14 20:11:47,269 - INFO - Epoch 16/20
2022-08-14 20:11:47,269 - INFO - Epoch 16/20
2022-08-14 20:13:09,851 - INFO - The train loss is 0.034433. The valid loss is 0.032430.
2022-08-14 20:13:09,851 - INFO - The train loss is 0.034433. The valid loss is 0.032430.
2022-08-14 20:13:09,851 - INFO - The train loss is 0.034433. The valid loss is 0.032430.
2022-08-14 20:13:09,851 - INFO - The train loss is 0.034433. The valid loss is 0.032430.
2022-08-14 20:13:09,851 - INFO - The train loss is 0.034433. The valid loss is 0.032430.
2022-08-14 20:13:09,857 - INFO - Epoch 17/20
2022-08-14 20:13:09,857 - INFO - Epoch 17/20
2022-08-14 20:13:09,857 - INFO - Epoch 17/20
2022-08-14 20:13:09,857 - INFO - Epoch 17/20
2022-08-14 20:13:09,857 - INFO - Epoch 17/20
2022-08-14 20:14:32,118 - INFO - The train loss is 0.034216. The valid loss is 0.032209.
2022-08-14 20:14:32,118 - INFO - The train loss is 0.034216. The valid loss is 0.032209.
2022-08-14 20:14:32,118 - INFO - The train loss is 0.034216. The valid loss is 0.032209.
2022-08-14 20:14:32,118 - INFO - The train loss is 0.034216. The valid loss is 0.032209.
2022-08-14 20:14:32,118 - INFO - The train loss is 0.034216. The valid loss is 0.032209.
2022-08-14 20:14:32,125 - INFO - Epoch 18/20
2022-08-14 20:14:32,125 - INFO - Epoch 18/20
2022-08-14 20:14:32,125 - INFO - Epoch 18/20
2022-08-14 20:14:32,125 - INFO - Epoch 18/20
2022-08-14 20:14:32,125 - INFO - Epoch 18/20
2022-08-14 20:15:55,057 - INFO - The train loss is 0.033994. The valid loss is 0.031991.
2022-08-14 20:15:55,057 - INFO - The train loss is 0.033994. The valid loss is 0.031991.
2022-08-14 20:15:55,057 - INFO - The train loss is 0.033994. The valid loss is 0.031991.
2022-08-14 20:15:55,057 - INFO - The train loss is 0.033994. The valid loss is 0.031991.
2022-08-14 20:15:55,057 - INFO - The train loss is 0.033994. The valid loss is 0.031991.
2022-08-14 20:15:55,065 - INFO - Epoch 19/20
2022-08-14 20:15:55,065 - INFO - Epoch 19/20
2022-08-14 20:15:55,065 - INFO - Epoch 19/20
2022-08-14 20:15:55,065 - INFO - Epoch 19/20
2022-08-14 20:15:55,065 - INFO - Epoch 19/20
2022-08-14 20:17:18,717 - INFO - The train loss is 0.033792. The valid loss is 0.031778.
2022-08-14 20:17:18,717 - INFO - The train loss is 0.033792. The valid loss is 0.031778.
2022-08-14 20:17:18,717 - INFO - The train loss is 0.033792. The valid loss is 0.031778.
2022-08-14 20:17:18,717 - INFO - The train loss is 0.033792. The valid loss is 0.031778.
2022-08-14 20:17:18,717 - INFO - The train loss is 0.033792. The valid loss is 0.031778.
2022-08-14 20:17:23,331 - INFO - The mean squared error of btc ['midpoint'] is [0.00148168]
2022-08-14 20:17:23,331 - INFO - The mean squared error of btc ['midpoint'] is [0.00148168]
2022-08-14 20:17:23,331 - INFO - The mean squared error of btc ['midpoint'] is [0.00148168]
2022-08-14 20:17:23,331 - INFO - The mean squared error of btc ['midpoint'] is [0.00148168]
2022-08-14 20:17:23,331 - INFO - The mean squared error of btc ['midpoint'] is [0.00148168]
2022-08-14 20:17:23,359 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20174.54083105 20174.16590042 20174.2359146  20173.72729633
 20173.74389168]
2022-08-14 20:17:23,359 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20174.54083105 20174.16590042 20174.2359146  20173.72729633
 20173.74389168]
2022-08-14 20:17:23,359 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20174.54083105 20174.16590042 20174.2359146  20173.72729633
 20173.74389168]
2022-08-14 20:17:23,359 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20174.54083105 20174.16590042 20174.2359146  20173.72729633
 20173.74389168]
2022-08-14 20:17:23,359 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20174.54083105 20174.16590042 20174.2359146  20173.72729633
 20173.74389168]
2022-08-14 20:17:23,686 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-14 20:17:23,686 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-14 20:17:23,686 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-14 20:17:23,686 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-14 20:17:23,686 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-14 20:17:23,686 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'GRU'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-14 20:17:23,926 - INFO - Epoch 0/20
2022-08-14 20:17:23,926 - INFO - Epoch 0/20
2022-08-14 20:17:23,926 - INFO - Epoch 0/20
2022-08-14 20:17:23,926 - INFO - Epoch 0/20
2022-08-14 20:17:23,926 - INFO - Epoch 0/20
2022-08-14 20:17:23,926 - INFO - Epoch 0/20
2022-08-14 20:18:47,349 - INFO - The train loss is 0.057980. The valid loss is 0.007933.
2022-08-14 20:18:47,349 - INFO - The train loss is 0.057980. The valid loss is 0.007933.
2022-08-14 20:18:47,349 - INFO - The train loss is 0.057980. The valid loss is 0.007933.
2022-08-14 20:18:47,349 - INFO - The train loss is 0.057980. The valid loss is 0.007933.
2022-08-14 20:18:47,349 - INFO - The train loss is 0.057980. The valid loss is 0.007933.
2022-08-14 20:18:47,349 - INFO - The train loss is 0.057980. The valid loss is 0.007933.
2022-08-14 20:18:47,357 - INFO - Epoch 1/20
2022-08-14 20:18:47,357 - INFO - Epoch 1/20
2022-08-14 20:18:47,357 - INFO - Epoch 1/20
2022-08-14 20:18:47,357 - INFO - Epoch 1/20
2022-08-14 20:18:47,357 - INFO - Epoch 1/20
2022-08-14 20:18:47,357 - INFO - Epoch 1/20
2022-08-14 20:20:13,892 - INFO - The train loss is 0.005602. The valid loss is 0.001136.
2022-08-14 20:20:13,892 - INFO - The train loss is 0.005602. The valid loss is 0.001136.
2022-08-14 20:20:13,892 - INFO - The train loss is 0.005602. The valid loss is 0.001136.
2022-08-14 20:20:13,892 - INFO - The train loss is 0.005602. The valid loss is 0.001136.
2022-08-14 20:20:13,892 - INFO - The train loss is 0.005602. The valid loss is 0.001136.
2022-08-14 20:20:13,892 - INFO - The train loss is 0.005602. The valid loss is 0.001136.
2022-08-14 20:20:13,904 - INFO - Epoch 2/20
2022-08-14 20:20:13,904 - INFO - Epoch 2/20
2022-08-14 20:20:13,904 - INFO - Epoch 2/20
2022-08-14 20:20:13,904 - INFO - Epoch 2/20
2022-08-14 20:20:13,904 - INFO - Epoch 2/20
2022-08-14 20:20:13,904 - INFO - Epoch 2/20
2022-08-14 20:21:38,445 - INFO - The train loss is 0.001845. The valid loss is 0.000970.
2022-08-14 20:21:38,445 - INFO - The train loss is 0.001845. The valid loss is 0.000970.
2022-08-14 20:21:38,445 - INFO - The train loss is 0.001845. The valid loss is 0.000970.
2022-08-14 20:21:38,445 - INFO - The train loss is 0.001845. The valid loss is 0.000970.
2022-08-14 20:21:38,445 - INFO - The train loss is 0.001845. The valid loss is 0.000970.
2022-08-14 20:21:38,445 - INFO - The train loss is 0.001845. The valid loss is 0.000970.
2022-08-14 20:21:38,453 - INFO - Epoch 3/20
2022-08-14 20:21:38,453 - INFO - Epoch 3/20
2022-08-14 20:21:38,453 - INFO - Epoch 3/20
2022-08-14 20:21:38,453 - INFO - Epoch 3/20
2022-08-14 20:21:38,453 - INFO - Epoch 3/20
2022-08-14 20:21:38,453 - INFO - Epoch 3/20
2022-08-14 20:23:01,711 - INFO - The train loss is 0.001415. The valid loss is 0.000839.
2022-08-14 20:23:01,711 - INFO - The train loss is 0.001415. The valid loss is 0.000839.
2022-08-14 20:23:01,711 - INFO - The train loss is 0.001415. The valid loss is 0.000839.
2022-08-14 20:23:01,711 - INFO - The train loss is 0.001415. The valid loss is 0.000839.
2022-08-14 20:23:01,711 - INFO - The train loss is 0.001415. The valid loss is 0.000839.
2022-08-14 20:23:01,711 - INFO - The train loss is 0.001415. The valid loss is 0.000839.
2022-08-14 20:23:01,718 - INFO - Epoch 4/20
2022-08-14 20:23:01,718 - INFO - Epoch 4/20
2022-08-14 20:23:01,718 - INFO - Epoch 4/20
2022-08-14 20:23:01,718 - INFO - Epoch 4/20
2022-08-14 20:23:01,718 - INFO - Epoch 4/20
2022-08-14 20:23:01,718 - INFO - Epoch 4/20
2022-08-14 20:24:24,732 - INFO - The train loss is 0.001297. The valid loss is 0.000821.
2022-08-14 20:24:24,732 - INFO - The train loss is 0.001297. The valid loss is 0.000821.
2022-08-14 20:24:24,732 - INFO - The train loss is 0.001297. The valid loss is 0.000821.
2022-08-14 20:24:24,732 - INFO - The train loss is 0.001297. The valid loss is 0.000821.
2022-08-14 20:24:24,732 - INFO - The train loss is 0.001297. The valid loss is 0.000821.
2022-08-14 20:24:24,732 - INFO - The train loss is 0.001297. The valid loss is 0.000821.
2022-08-14 20:24:24,740 - INFO - Epoch 5/20
2022-08-14 20:24:24,740 - INFO - Epoch 5/20
2022-08-14 20:24:24,740 - INFO - Epoch 5/20
2022-08-14 20:24:24,740 - INFO - Epoch 5/20
2022-08-14 20:24:24,740 - INFO - Epoch 5/20
2022-08-14 20:24:24,740 - INFO - Epoch 5/20
2022-08-14 20:25:46,991 - INFO - The train loss is 0.001245. The valid loss is 0.001005.
2022-08-14 20:25:46,991 - INFO - The train loss is 0.001245. The valid loss is 0.001005.
2022-08-14 20:25:46,991 - INFO - The train loss is 0.001245. The valid loss is 0.001005.
2022-08-14 20:25:46,991 - INFO - The train loss is 0.001245. The valid loss is 0.001005.
2022-08-14 20:25:46,991 - INFO - The train loss is 0.001245. The valid loss is 0.001005.
2022-08-14 20:25:46,991 - INFO - The train loss is 0.001245. The valid loss is 0.001005.
2022-08-14 20:25:46,995 - INFO - Epoch 6/20
2022-08-14 20:25:46,995 - INFO - Epoch 6/20
2022-08-14 20:25:46,995 - INFO - Epoch 6/20
2022-08-14 20:25:46,995 - INFO - Epoch 6/20
2022-08-14 20:25:46,995 - INFO - Epoch 6/20
2022-08-14 20:25:46,995 - INFO - Epoch 6/20
2022-08-14 20:27:10,826 - INFO - The train loss is 0.001203. The valid loss is 0.000928.
2022-08-14 20:27:10,826 - INFO - The train loss is 0.001203. The valid loss is 0.000928.
2022-08-14 20:27:10,826 - INFO - The train loss is 0.001203. The valid loss is 0.000928.
2022-08-14 20:27:10,826 - INFO - The train loss is 0.001203. The valid loss is 0.000928.
2022-08-14 20:27:10,826 - INFO - The train loss is 0.001203. The valid loss is 0.000928.
2022-08-14 20:27:10,826 - INFO - The train loss is 0.001203. The valid loss is 0.000928.
2022-08-14 20:27:10,834 - INFO - Epoch 7/20
2022-08-14 20:27:10,834 - INFO - Epoch 7/20
2022-08-14 20:27:10,834 - INFO - Epoch 7/20
2022-08-14 20:27:10,834 - INFO - Epoch 7/20
2022-08-14 20:27:10,834 - INFO - Epoch 7/20
2022-08-14 20:27:10,834 - INFO - Epoch 7/20
2022-08-14 20:28:38,186 - INFO - The train loss is 0.001168. The valid loss is 0.001106.
2022-08-14 20:28:38,186 - INFO - The train loss is 0.001168. The valid loss is 0.001106.
2022-08-14 20:28:38,186 - INFO - The train loss is 0.001168. The valid loss is 0.001106.
2022-08-14 20:28:38,186 - INFO - The train loss is 0.001168. The valid loss is 0.001106.
2022-08-14 20:28:38,186 - INFO - The train loss is 0.001168. The valid loss is 0.001106.
2022-08-14 20:28:38,186 - INFO - The train loss is 0.001168. The valid loss is 0.001106.
2022-08-14 20:28:38,191 - INFO - Epoch 8/20
2022-08-14 20:28:38,191 - INFO - Epoch 8/20
2022-08-14 20:28:38,191 - INFO - Epoch 8/20
2022-08-14 20:28:38,191 - INFO - Epoch 8/20
2022-08-14 20:28:38,191 - INFO - Epoch 8/20
2022-08-14 20:28:38,191 - INFO - Epoch 8/20
2022-08-14 20:30:02,134 - INFO - The train loss is 0.001147. The valid loss is 0.001020.
2022-08-14 20:30:02,134 - INFO - The train loss is 0.001147. The valid loss is 0.001020.
2022-08-14 20:30:02,134 - INFO - The train loss is 0.001147. The valid loss is 0.001020.
2022-08-14 20:30:02,134 - INFO - The train loss is 0.001147. The valid loss is 0.001020.
2022-08-14 20:30:02,134 - INFO - The train loss is 0.001147. The valid loss is 0.001020.
2022-08-14 20:30:02,134 - INFO - The train loss is 0.001147. The valid loss is 0.001020.
2022-08-14 20:30:02,139 - INFO - Epoch 9/20
2022-08-14 20:30:02,139 - INFO - Epoch 9/20
2022-08-14 20:30:02,139 - INFO - Epoch 9/20
2022-08-14 20:30:02,139 - INFO - Epoch 9/20
2022-08-14 20:30:02,139 - INFO - Epoch 9/20
2022-08-14 20:30:02,139 - INFO - Epoch 9/20
2022-08-14 20:31:23,659 - INFO - The train loss is 0.001120. The valid loss is 0.000916.
2022-08-14 20:31:23,659 - INFO - The train loss is 0.001120. The valid loss is 0.000916.
2022-08-14 20:31:23,659 - INFO - The train loss is 0.001120. The valid loss is 0.000916.
2022-08-14 20:31:23,659 - INFO - The train loss is 0.001120. The valid loss is 0.000916.
2022-08-14 20:31:23,659 - INFO - The train loss is 0.001120. The valid loss is 0.000916.
2022-08-14 20:31:23,659 - INFO - The train loss is 0.001120. The valid loss is 0.000916.
2022-08-14 20:31:23,663 - INFO -  The training stops early in epoch 9
2022-08-14 20:31:23,663 - INFO -  The training stops early in epoch 9
2022-08-14 20:31:23,663 - INFO -  The training stops early in epoch 9
2022-08-14 20:31:23,663 - INFO -  The training stops early in epoch 9
2022-08-14 20:31:23,663 - INFO -  The training stops early in epoch 9
2022-08-14 20:31:23,663 - INFO -  The training stops early in epoch 9
2022-08-14 20:31:28,076 - INFO - The mean squared error of btc ['midpoint'] is [0.00062466]
2022-08-14 20:31:28,076 - INFO - The mean squared error of btc ['midpoint'] is [0.00062466]
2022-08-14 20:31:28,076 - INFO - The mean squared error of btc ['midpoint'] is [0.00062466]
2022-08-14 20:31:28,076 - INFO - The mean squared error of btc ['midpoint'] is [0.00062466]
2022-08-14 20:31:28,076 - INFO - The mean squared error of btc ['midpoint'] is [0.00062466]
2022-08-14 20:31:28,076 - INFO - The mean squared error of btc ['midpoint'] is [0.00062466]
2022-08-14 20:31:28,105 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20169.991182   20170.67586784 20170.87886678 20170.49271229
 20170.33932182]
2022-08-14 20:31:28,105 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20169.991182   20170.67586784 20170.87886678 20170.49271229
 20170.33932182]
2022-08-14 20:31:28,105 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20169.991182   20170.67586784 20170.87886678 20170.49271229
 20170.33932182]
2022-08-14 20:31:28,105 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20169.991182   20170.67586784 20170.87886678 20170.49271229
 20170.33932182]
2022-08-14 20:31:28,105 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20169.991182   20170.67586784 20170.87886678 20170.49271229
 20170.33932182]
2022-08-14 20:31:28,105 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20169.991182   20170.67586784 20170.87886678 20170.49271229
 20170.33932182]
2022-08-15 01:21:23,864 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-15 01:21:24,267 - INFO - Epoch 0/20
2022-08-15 01:22:47,871 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-15 01:22:47,871 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-15 01:22:48,133 - INFO - Epoch 0/20
2022-08-15 01:22:48,133 - INFO - Epoch 0/20
2022-08-15 01:23:13,062 - INFO - The train loss is 0.883896. The valid loss is 0.202301.
2022-08-15 01:23:13,062 - INFO - The train loss is 0.883896. The valid loss is 0.202301.
2022-08-15 01:23:13,169 - INFO - Epoch 1/20
2022-08-15 01:23:13,169 - INFO - Epoch 1/20
2022-08-15 01:23:37,084 - INFO - The train loss is 0.069529. The valid loss is 0.044132.
2022-08-15 01:23:37,084 - INFO - The train loss is 0.069529. The valid loss is 0.044132.
2022-08-15 01:23:37,187 - INFO - Epoch 2/20
2022-08-15 01:23:37,187 - INFO - Epoch 2/20
2022-08-15 01:24:01,177 - INFO - The train loss is 0.045825. The valid loss is 0.038763.
2022-08-15 01:24:01,177 - INFO - The train loss is 0.045825. The valid loss is 0.038763.
2022-08-15 01:24:01,181 - INFO - Epoch 3/20
2022-08-15 01:24:01,181 - INFO - Epoch 3/20
2022-08-15 01:24:25,461 - INFO - The train loss is 0.041551. The valid loss is 0.035208.
2022-08-15 01:24:25,461 - INFO - The train loss is 0.041551. The valid loss is 0.035208.
2022-08-15 01:24:25,465 - INFO - Epoch 4/20
2022-08-15 01:24:25,465 - INFO - Epoch 4/20
2022-08-15 01:24:49,710 - INFO - The train loss is 0.038489. The valid loss is 0.032485.
2022-08-15 01:24:49,710 - INFO - The train loss is 0.038489. The valid loss is 0.032485.
2022-08-15 01:24:49,713 - INFO - Epoch 5/20
2022-08-15 01:24:49,713 - INFO - Epoch 5/20
2022-08-15 01:30:23,909 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-15 01:30:23,909 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-15 01:30:23,909 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'SGD'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-15 01:30:24,170 - INFO - Epoch 0/20
2022-08-15 01:30:24,170 - INFO - Epoch 0/20
2022-08-15 01:30:24,170 - INFO - Epoch 0/20
2022-08-15 01:30:49,549 - INFO - The train loss is 0.828184. The valid loss is 0.109296.
2022-08-15 01:30:49,549 - INFO - The train loss is 0.828184. The valid loss is 0.109296.
2022-08-15 01:30:49,549 - INFO - The train loss is 0.828184. The valid loss is 0.109296.
2022-08-15 01:30:49,555 - INFO - Epoch 1/20
2022-08-15 01:30:49,555 - INFO - Epoch 1/20
2022-08-15 01:30:49,555 - INFO - Epoch 1/20
2022-08-15 01:31:13,417 - INFO - The train loss is 0.056088. The valid loss is 0.042690.
2022-08-15 01:31:13,417 - INFO - The train loss is 0.056088. The valid loss is 0.042690.
2022-08-15 01:31:13,417 - INFO - The train loss is 0.056088. The valid loss is 0.042690.
2022-08-15 01:31:13,422 - INFO - Epoch 2/20
2022-08-15 01:31:13,422 - INFO - Epoch 2/20
2022-08-15 01:31:13,422 - INFO - Epoch 2/20
2022-08-15 01:31:37,550 - INFO - The train loss is 0.044727. The valid loss is 0.037601.
2022-08-15 01:31:37,550 - INFO - The train loss is 0.044727. The valid loss is 0.037601.
2022-08-15 01:31:37,550 - INFO - The train loss is 0.044727. The valid loss is 0.037601.
2022-08-15 01:31:37,556 - INFO - Epoch 3/20
2022-08-15 01:31:37,556 - INFO - Epoch 3/20
2022-08-15 01:31:37,556 - INFO - Epoch 3/20
2022-08-15 01:32:01,792 - INFO - The train loss is 0.040568. The valid loss is 0.033994.
2022-08-15 01:32:01,792 - INFO - The train loss is 0.040568. The valid loss is 0.033994.
2022-08-15 01:32:01,792 - INFO - The train loss is 0.040568. The valid loss is 0.033994.
2022-08-15 01:32:01,798 - INFO - Epoch 4/20
2022-08-15 01:32:01,798 - INFO - Epoch 4/20
2022-08-15 01:32:01,798 - INFO - Epoch 4/20
2022-08-15 01:32:28,220 - INFO - The train loss is 0.037378. The valid loss is 0.031201.
2022-08-15 01:32:28,220 - INFO - The train loss is 0.037378. The valid loss is 0.031201.
2022-08-15 01:32:28,220 - INFO - The train loss is 0.037378. The valid loss is 0.031201.
2022-08-15 01:32:28,225 - INFO - Epoch 5/20
2022-08-15 01:32:28,225 - INFO - Epoch 5/20
2022-08-15 01:32:28,225 - INFO - Epoch 5/20
2022-08-15 01:32:54,772 - INFO - The train loss is 0.034882. The valid loss is 0.028926.
2022-08-15 01:32:54,772 - INFO - The train loss is 0.034882. The valid loss is 0.028926.
2022-08-15 01:32:54,772 - INFO - The train loss is 0.034882. The valid loss is 0.028926.
2022-08-15 01:32:54,777 - INFO - Epoch 6/20
2022-08-15 01:32:54,777 - INFO - Epoch 6/20
2022-08-15 01:32:54,777 - INFO - Epoch 6/20
2022-08-15 01:33:19,281 - INFO - The train loss is 0.032875. The valid loss is 0.027019.
2022-08-15 01:33:19,281 - INFO - The train loss is 0.032875. The valid loss is 0.027019.
2022-08-15 01:33:19,281 - INFO - The train loss is 0.032875. The valid loss is 0.027019.
2022-08-15 01:33:19,286 - INFO - Epoch 7/20
2022-08-15 01:33:19,286 - INFO - Epoch 7/20
2022-08-15 01:33:19,286 - INFO - Epoch 7/20
2022-08-15 01:33:43,625 - INFO - The train loss is 0.031124. The valid loss is 0.025398.
2022-08-15 01:33:43,625 - INFO - The train loss is 0.031124. The valid loss is 0.025398.
2022-08-15 01:33:43,625 - INFO - The train loss is 0.031124. The valid loss is 0.025398.
2022-08-15 01:33:43,630 - INFO - Epoch 8/20
2022-08-15 01:33:43,630 - INFO - Epoch 8/20
2022-08-15 01:33:43,630 - INFO - Epoch 8/20
2022-08-15 01:34:07,892 - INFO - The train loss is 0.029665. The valid loss is 0.023986.
2022-08-15 01:34:07,892 - INFO - The train loss is 0.029665. The valid loss is 0.023986.
2022-08-15 01:34:07,892 - INFO - The train loss is 0.029665. The valid loss is 0.023986.
2022-08-15 01:34:07,895 - INFO - Epoch 9/20
2022-08-15 01:34:07,895 - INFO - Epoch 9/20
2022-08-15 01:34:07,895 - INFO - Epoch 9/20
2022-08-15 01:34:32,121 - INFO - The train loss is 0.028349. The valid loss is 0.022744.
2022-08-15 01:34:32,121 - INFO - The train loss is 0.028349. The valid loss is 0.022744.
2022-08-15 01:34:32,121 - INFO - The train loss is 0.028349. The valid loss is 0.022744.
2022-08-15 01:34:32,126 - INFO - Epoch 10/20
2022-08-15 01:34:32,126 - INFO - Epoch 10/20
2022-08-15 01:34:32,126 - INFO - Epoch 10/20
2022-08-15 01:34:57,651 - INFO - The train loss is 0.027192. The valid loss is 0.021640.
2022-08-15 01:34:57,651 - INFO - The train loss is 0.027192. The valid loss is 0.021640.
2022-08-15 01:34:57,651 - INFO - The train loss is 0.027192. The valid loss is 0.021640.
2022-08-15 01:34:57,656 - INFO - Epoch 11/20
2022-08-15 01:34:57,656 - INFO - Epoch 11/20
2022-08-15 01:34:57,656 - INFO - Epoch 11/20
2022-08-15 01:35:21,412 - INFO - The train loss is 0.026213. The valid loss is 0.020648.
2022-08-15 01:35:21,412 - INFO - The train loss is 0.026213. The valid loss is 0.020648.
2022-08-15 01:35:21,412 - INFO - The train loss is 0.026213. The valid loss is 0.020648.
2022-08-15 01:35:21,417 - INFO - Epoch 12/20
2022-08-15 01:35:21,417 - INFO - Epoch 12/20
2022-08-15 01:35:21,417 - INFO - Epoch 12/20
2022-08-15 01:35:46,052 - INFO - The train loss is 0.025287. The valid loss is 0.019755.
2022-08-15 01:35:46,052 - INFO - The train loss is 0.025287. The valid loss is 0.019755.
2022-08-15 01:35:46,052 - INFO - The train loss is 0.025287. The valid loss is 0.019755.
2022-08-15 01:35:46,057 - INFO - Epoch 13/20
2022-08-15 01:35:46,057 - INFO - Epoch 13/20
2022-08-15 01:35:46,057 - INFO - Epoch 13/20
2022-08-15 01:36:10,434 - INFO - The train loss is 0.024442. The valid loss is 0.018936.
2022-08-15 01:36:10,434 - INFO - The train loss is 0.024442. The valid loss is 0.018936.
2022-08-15 01:36:10,434 - INFO - The train loss is 0.024442. The valid loss is 0.018936.
2022-08-15 01:36:10,438 - INFO - Epoch 14/20
2022-08-15 01:36:10,438 - INFO - Epoch 14/20
2022-08-15 01:36:10,438 - INFO - Epoch 14/20
2022-08-15 01:36:34,422 - INFO - The train loss is 0.023686. The valid loss is 0.018189.
2022-08-15 01:36:34,422 - INFO - The train loss is 0.023686. The valid loss is 0.018189.
2022-08-15 01:36:34,422 - INFO - The train loss is 0.023686. The valid loss is 0.018189.
2022-08-15 01:36:34,426 - INFO - Epoch 15/20
2022-08-15 01:36:34,426 - INFO - Epoch 15/20
2022-08-15 01:36:34,426 - INFO - Epoch 15/20
2022-08-15 01:36:58,879 - INFO - The train loss is 0.022983. The valid loss is 0.017499.
2022-08-15 01:36:58,879 - INFO - The train loss is 0.022983. The valid loss is 0.017499.
2022-08-15 01:36:58,879 - INFO - The train loss is 0.022983. The valid loss is 0.017499.
2022-08-15 01:36:58,884 - INFO - Epoch 16/20
2022-08-15 01:36:58,884 - INFO - Epoch 16/20
2022-08-15 01:36:58,884 - INFO - Epoch 16/20
2022-08-15 01:37:22,983 - INFO - The train loss is 0.022358. The valid loss is 0.016864.
2022-08-15 01:37:22,983 - INFO - The train loss is 0.022358. The valid loss is 0.016864.
2022-08-15 01:37:22,983 - INFO - The train loss is 0.022358. The valid loss is 0.016864.
2022-08-15 01:37:22,988 - INFO - Epoch 17/20
2022-08-15 01:37:22,988 - INFO - Epoch 17/20
2022-08-15 01:37:22,988 - INFO - Epoch 17/20
2022-08-15 01:37:47,440 - INFO - The train loss is 0.021769. The valid loss is 0.016271.
2022-08-15 01:37:47,440 - INFO - The train loss is 0.021769. The valid loss is 0.016271.
2022-08-15 01:37:47,440 - INFO - The train loss is 0.021769. The valid loss is 0.016271.
2022-08-15 01:37:47,445 - INFO - Epoch 18/20
2022-08-15 01:37:47,445 - INFO - Epoch 18/20
2022-08-15 01:37:47,445 - INFO - Epoch 18/20
2022-08-15 01:38:11,625 - INFO - The train loss is 0.021186. The valid loss is 0.015721.
2022-08-15 01:38:11,625 - INFO - The train loss is 0.021186. The valid loss is 0.015721.
2022-08-15 01:38:11,625 - INFO - The train loss is 0.021186. The valid loss is 0.015721.
2022-08-15 01:38:11,629 - INFO - Epoch 19/20
2022-08-15 01:38:11,629 - INFO - Epoch 19/20
2022-08-15 01:38:11,629 - INFO - Epoch 19/20
2022-08-15 01:38:35,813 - INFO - The train loss is 0.020694. The valid loss is 0.015207.
2022-08-15 01:38:35,813 - INFO - The train loss is 0.020694. The valid loss is 0.015207.
2022-08-15 01:38:35,813 - INFO - The train loss is 0.020694. The valid loss is 0.015207.
2022-08-15 01:38:37,583 - INFO - The mean squared error of btc ['midpoint'] is [0.00166743]
2022-08-15 01:38:37,583 - INFO - The mean squared error of btc ['midpoint'] is [0.00166743]
2022-08-15 01:38:37,583 - INFO - The mean squared error of btc ['midpoint'] is [0.00166743]
2022-08-15 01:38:37,606 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20173.91520186 20172.76768109 20175.47142107 20175.92838881
 20175.87132241]
2022-08-15 01:38:37,606 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20173.91520186 20172.76768109 20175.47142107 20175.92838881
 20175.87132241]
2022-08-15 01:38:37,606 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20173.91520186 20172.76768109 20175.47142107 20175.92838881
 20175.87132241]
2022-08-15 01:38:38,098 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-15 01:38:38,098 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-15 01:38:38,098 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-15 01:38:38,098 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'RNN'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-15 01:38:38,385 - INFO - Epoch 0/20
2022-08-15 01:38:38,385 - INFO - Epoch 0/20
2022-08-15 01:38:38,385 - INFO - Epoch 0/20
2022-08-15 01:38:38,385 - INFO - Epoch 0/20
2022-08-15 01:39:03,399 - INFO - The train loss is 0.033014. The valid loss is 0.001700.
2022-08-15 01:39:03,399 - INFO - The train loss is 0.033014. The valid loss is 0.001700.
2022-08-15 01:39:03,399 - INFO - The train loss is 0.033014. The valid loss is 0.001700.
2022-08-15 01:39:03,399 - INFO - The train loss is 0.033014. The valid loss is 0.001700.
2022-08-15 01:39:03,405 - INFO - Epoch 1/20
2022-08-15 01:39:03,405 - INFO - Epoch 1/20
2022-08-15 01:39:03,405 - INFO - Epoch 1/20
2022-08-15 01:39:03,405 - INFO - Epoch 1/20
2022-08-15 01:39:27,879 - INFO - The train loss is 0.002969. The valid loss is 0.000919.
2022-08-15 01:39:27,879 - INFO - The train loss is 0.002969. The valid loss is 0.000919.
2022-08-15 01:39:27,879 - INFO - The train loss is 0.002969. The valid loss is 0.000919.
2022-08-15 01:39:27,879 - INFO - The train loss is 0.002969. The valid loss is 0.000919.
2022-08-15 01:39:27,884 - INFO - Epoch 2/20
2022-08-15 01:39:27,884 - INFO - Epoch 2/20
2022-08-15 01:39:27,884 - INFO - Epoch 2/20
2022-08-15 01:39:27,884 - INFO - Epoch 2/20
2022-08-15 01:39:52,714 - INFO - The train loss is 0.001841. The valid loss is 0.000792.
2022-08-15 01:39:52,714 - INFO - The train loss is 0.001841. The valid loss is 0.000792.
2022-08-15 01:39:52,714 - INFO - The train loss is 0.001841. The valid loss is 0.000792.
2022-08-15 01:39:52,714 - INFO - The train loss is 0.001841. The valid loss is 0.000792.
2022-08-15 01:39:52,720 - INFO - Epoch 3/20
2022-08-15 01:39:52,720 - INFO - Epoch 3/20
2022-08-15 01:39:52,720 - INFO - Epoch 3/20
2022-08-15 01:39:52,720 - INFO - Epoch 3/20
2022-08-15 01:40:17,657 - INFO - The train loss is 0.001516. The valid loss is 0.000940.
2022-08-15 01:40:17,657 - INFO - The train loss is 0.001516. The valid loss is 0.000940.
2022-08-15 01:40:17,657 - INFO - The train loss is 0.001516. The valid loss is 0.000940.
2022-08-15 01:40:17,657 - INFO - The train loss is 0.001516. The valid loss is 0.000940.
2022-08-15 01:40:17,661 - INFO - Epoch 4/20
2022-08-15 01:40:17,661 - INFO - Epoch 4/20
2022-08-15 01:40:17,661 - INFO - Epoch 4/20
2022-08-15 01:40:17,661 - INFO - Epoch 4/20
2022-08-15 01:40:42,501 - INFO - The train loss is 0.001465. The valid loss is 0.000899.
2022-08-15 01:40:42,501 - INFO - The train loss is 0.001465. The valid loss is 0.000899.
2022-08-15 01:40:42,501 - INFO - The train loss is 0.001465. The valid loss is 0.000899.
2022-08-15 01:40:42,501 - INFO - The train loss is 0.001465. The valid loss is 0.000899.
2022-08-15 01:40:42,504 - INFO - Epoch 5/20
2022-08-15 01:40:42,504 - INFO - Epoch 5/20
2022-08-15 01:40:42,504 - INFO - Epoch 5/20
2022-08-15 01:40:42,504 - INFO - Epoch 5/20
2022-08-15 01:41:07,538 - INFO - The train loss is 0.001294. The valid loss is 0.000892.
2022-08-15 01:41:07,538 - INFO - The train loss is 0.001294. The valid loss is 0.000892.
2022-08-15 01:41:07,538 - INFO - The train loss is 0.001294. The valid loss is 0.000892.
2022-08-15 01:41:07,538 - INFO - The train loss is 0.001294. The valid loss is 0.000892.
2022-08-15 01:41:07,542 - INFO - Epoch 6/20
2022-08-15 01:41:07,542 - INFO - Epoch 6/20
2022-08-15 01:41:07,542 - INFO - Epoch 6/20
2022-08-15 01:41:07,542 - INFO - Epoch 6/20
2022-08-15 01:41:32,314 - INFO - The train loss is 0.001253. The valid loss is 0.001196.
2022-08-15 01:41:32,314 - INFO - The train loss is 0.001253. The valid loss is 0.001196.
2022-08-15 01:41:32,314 - INFO - The train loss is 0.001253. The valid loss is 0.001196.
2022-08-15 01:41:32,314 - INFO - The train loss is 0.001253. The valid loss is 0.001196.
2022-08-15 01:41:32,318 - INFO - Epoch 7/20
2022-08-15 01:41:32,318 - INFO - Epoch 7/20
2022-08-15 01:41:32,318 - INFO - Epoch 7/20
2022-08-15 01:41:32,318 - INFO - Epoch 7/20
2022-08-15 01:41:57,454 - INFO - The train loss is 0.001214. The valid loss is 0.000812.
2022-08-15 01:41:57,454 - INFO - The train loss is 0.001214. The valid loss is 0.000812.
2022-08-15 01:41:57,454 - INFO - The train loss is 0.001214. The valid loss is 0.000812.
2022-08-15 01:41:57,454 - INFO - The train loss is 0.001214. The valid loss is 0.000812.
2022-08-15 01:41:57,457 - INFO -  The training stops early in epoch 7
2022-08-15 01:41:57,457 - INFO -  The training stops early in epoch 7
2022-08-15 01:41:57,457 - INFO -  The training stops early in epoch 7
2022-08-15 01:41:57,457 - INFO -  The training stops early in epoch 7
2022-08-15 01:41:59,053 - INFO - The mean squared error of btc ['midpoint'] is [0.00061159]
2022-08-15 01:41:59,053 - INFO - The mean squared error of btc ['midpoint'] is [0.00061159]
2022-08-15 01:41:59,053 - INFO - The mean squared error of btc ['midpoint'] is [0.00061159]
2022-08-15 01:41:59,053 - INFO - The mean squared error of btc ['midpoint'] is [0.00061159]
2022-08-15 01:41:59,079 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20166.3439782  20169.77724033 20168.84295834 20168.18144532
 20167.78905369]
2022-08-15 01:41:59,079 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20166.3439782  20169.77724033 20168.84295834 20168.18144532
 20167.78905369]
2022-08-15 01:41:59,079 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20166.3439782  20169.77724033 20168.84295834 20168.18144532
 20167.78905369]
2022-08-15 01:41:59,079 - INFO - The predicted btc midpoint for the next 5 day(s) is: [20166.3439782  20169.77724033 20168.84295834 20168.18144532
 20167.78905369]
2022-08-15 01:41:59,569 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-15 01:41:59,569 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-15 01:41:59,569 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-15 01:41:59,569 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-15 01:41:59,569 - INFO - 
Config:
'add_train': False
'batch_size': 64
'continue_flag': ''
'debug_mode': False
'debug_num': 500
'do_continue_train': False
'do_figure_save': True
'do_log_print_to_screen': True
'do_log_save_to_file': True
'do_predict': True
'do_train': True
'do_train_visualized': False
'dropout_rate': 0.2
'epoch': 20
'feature_columns': [1, 2, 3, 4]
'figure_save_path': './figure/'
'hidden_size': 128
'input_size': 4
'label_columns': [1]
'label_in_feature_index': [0]
'learning_rate': 0.0003
'log_save_path': './log/'
'lstm_layers': 2
'model_name': 'model_pytorch.pth'
'model_save_path': './checkpoint/pytorch/'
'model_type': 'LSTM'
'optimizer': 'Adam'
'output_size': 1
'patience': 5
'predict_day': 5
'random_seed': 42
'shuffle_train_data': True
'time_step': 60
'train_data_path': './data/btc_data.csv'
'train_data_rate': 0.7
'use_cuda': False
'used_frame': 'pytorch'
'valid_data_rate': 0.1
2022-08-15 01:41:59,846 - INFO - Epoch 0/20
2022-08-15 01:41:59,846 - INFO - Epoch 0/20
2022-08-15 01:41:59,846 - INFO - Epoch 0/20
2022-08-15 01:41:59,846 - INFO - Epoch 0/20
2022-08-15 01:41:59,846 - INFO - Epoch 0/20
2022-08-15 01:43:43,275 - INFO - The train loss is 0.101381. The valid loss is 0.018029.
2022-08-15 01:43:43,275 - INFO - The train loss is 0.101381. The valid loss is 0.018029.
2022-08-15 01:43:43,275 - INFO - The train loss is 0.101381. The valid loss is 0.018029.
2022-08-15 01:43:43,275 - INFO - The train loss is 0.101381. The valid loss is 0.018029.
2022-08-15 01:43:43,275 - INFO - The train loss is 0.101381. The valid loss is 0.018029.
2022-08-15 01:43:43,305 - INFO - Epoch 1/20
2022-08-15 01:43:43,305 - INFO - Epoch 1/20
2022-08-15 01:43:43,305 - INFO - Epoch 1/20
2022-08-15 01:43:43,305 - INFO - Epoch 1/20
2022-08-15 01:43:43,305 - INFO - Epoch 1/20
2022-08-15 01:45:22,683 - INFO - The train loss is 0.011962. The valid loss is 0.004596.
2022-08-15 01:45:22,683 - INFO - The train loss is 0.011962. The valid loss is 0.004596.
2022-08-15 01:45:22,683 - INFO - The train loss is 0.011962. The valid loss is 0.004596.
2022-08-15 01:45:22,683 - INFO - The train loss is 0.011962. The valid loss is 0.004596.
2022-08-15 01:45:22,683 - INFO - The train loss is 0.011962. The valid loss is 0.004596.
2022-08-15 01:45:22,691 - INFO - Epoch 2/20
2022-08-15 01:45:22,691 - INFO - Epoch 2/20
2022-08-15 01:45:22,691 - INFO - Epoch 2/20
2022-08-15 01:45:22,691 - INFO - Epoch 2/20
2022-08-15 01:45:22,691 - INFO - Epoch 2/20
